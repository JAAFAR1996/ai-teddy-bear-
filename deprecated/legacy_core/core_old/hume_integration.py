#!/usr/bin/env python3
"""
ğŸ¤ HUME AI Integration Script
Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ HUME AI: Batch Ùˆ Stream
"""

import os
import asyncio
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from database import db_manager

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª HUME AI
try:
    from hume import HumeClient, AsyncHumeClient
    HUME_AVAILABLE = True
    print("âœ… HUME AI SDK loaded successfully")
except ImportError:
    HUME_AVAILABLE = False
    print("âŒ HUME AI SDK not available. Install with: pip install hume")

class HumeIntegration:
    """
    ğŸ­ HUME AI Integration Class
    ÙŠØ¯Ø¹Ù… Ù†Ù…ÙˆØ°Ø¬ÙŠ Batch Ùˆ Stream Ù„Ù„ØªØ­Ù„ÙŠÙ„
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("HUME_API_KEY")
        
        if not self.api_key:
            raise ValueError("âŒ HUME API Key not found! Set HUME_API_KEY environment variable")
        
        print(f"ğŸ”‘ HUME API Key loaded: {self.api_key[:8]}...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
        if HUME_AVAILABLE:
            self.client = HumeClient(api_key=self.api_key)
            self.async_client = AsyncHumeClient(api_key=self.api_key)
            print("âœ… HUME Clients initialized")
        else:
            self.client = None
            self.async_client = None
            print("âš ï¸ HUME Clients not available")
    
    # ==================== BATCH MODE ====================
    
    def analyze_batch(self, file_paths: List[str], udid: str = "TEST_ESP32", child_name: str = "Ø·ÙÙ„ Ø§Ø®ØªØ¨Ø§Ø±", child_age: int = 6) -> Dict[str, Any]:
        """
        ğŸ”„ Ù†Ù…Ø· Batch - ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (HUME v0.9.0) Ù…Ø¹ Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Args:
            file_paths: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
            udid: Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù‡Ø§Ø²
            child_name: Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„
            child_age: Ø¹Ù…Ø± Ø§Ù„Ø·ÙÙ„
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù JSON ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if not HUME_AVAILABLE or not self.client:
            return {"error": "HUME SDK not available"}
        
        # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        session_record = None
        
        try:
            print("ğŸ”„ Starting Batch Analysis...")
            print(f"ğŸ“ Files to analyze: {len(file_paths)}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
            valid_files = []
            for file_path in file_paths:
                if Path(file_path).exists():
                    valid_files.append(file_path)
                    print(f"  âœ… {file_path}")
                else:
                    print(f"  âŒ File not found: {file_path}")
            
            if not valid_files:
                return {"error": "No valid files found"}
            
            # ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            session_record = db_manager.save_session(
                udid=udid,
                child_name=child_name,
                child_age=child_age,
                mode="batch",
                audio_file=valid_files[0] if valid_files else None
            )
            
            print("ğŸ“¤ Submitting batch job to HUME...")
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ (ÙˆØ§Ø¬Ù‡Ø© HUME v0.9.0)
            job = self.client.expression_measurement.batch.submit_job(
                urls=valid_files,
                configs=[
                    {"prosody": {}},  # ØªØ­Ù„ÙŠÙ„ Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª
                    {"face": {}}      # ØªØ­Ù„ÙŠÙ„ ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„ÙˆØ¬Ù‡
                ]
            )
            
            print(f"ğŸ“‹ Job ID: {job.job_id}")
            print("â³ Waiting for analysis to complete...")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            job = self.client.expression_measurement.batch.get_job_details(job.job_id)
            
            while job.state not in ["COMPLETED", "FAILED"]:
                print("â³ Still processing...")
                import time
                time.sleep(5)
                job = self.client.expression_measurement.batch.get_job_details(job.job_id)
            
            if job.state == "FAILED":
                return {
                    "status": "error",
                    "mode": "batch",
                    "error": "HUME job failed"
                }
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            print("ğŸ“¥ Downloading predictions...")
            predictions = self.client.expression_measurement.batch.get_job_predictions(job.job_id)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            emotions_data = self._extract_emotions_from_predictions(predictions)
            
            if emotions_data and session_record:
                print("ğŸ’¾ Saving emotions to database...")
                db_manager.save_emotions(session_record.id, emotions_data)
                db_manager.update_session_status(session_record.id, "success")
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù
            output_file = "batch_predictions.json"
            with open(output_file, 'w') as f:
                json.dump(predictions, f, indent=2)
            
            print("âœ… Batch analysis completed successfully!")
            
            return {
                "status": "success",
                "mode": "batch",
                "session_id": session_record.id if session_record else None,
                "files_analyzed": len(valid_files),
                "output_file": output_file,
                "job_id": job.job_id,
                "emotions_saved": len(emotions_data) if emotions_data else 0,
                "results": predictions
            }
            
        except Exception as e:
            print(f"âŒ Batch analysis failed: {e}")
            
            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if session_record:
                db_manager.update_session_status(session_record.id, "error", str(e))
            
            return {
                "status": "error",
                "mode": "batch",
                "session_id": session_record.id if session_record else None,
                "error": str(e)
            }
    
    # ==================== STREAM MODE ====================
    
    async def analyze_stream(self, audio_path: str, udid: str = "TEST_ESP32", child_name: str = "Ø·ÙÙ„ Ø§Ø®ØªØ¨Ø§Ø±", child_age: int = 6) -> Dict[str, Any]:
        """
        âš¡ Ù†Ù…Ø· Stream - ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±ÙŠ Ù„Ù…Ù„Ù ÙˆØ§Ø­Ø¯ (HUME v0.9.0) Ù…Ø¹ Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Args:
            audio_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
            udid: Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù‡Ø§Ø²
            child_name: Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„
            child_age: Ø¹Ù…Ø± Ø§Ù„Ø·ÙÙ„
            
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆØ±ÙŠ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if not HUME_AVAILABLE or not self.async_client:
            return {"error": "HUME SDK not available"}
        
        # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        session_record = None
        
        try:
            print("âš¡ Starting Stream Analysis...")
            print(f"ğŸµ Audio file: {audio_path}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not Path(audio_path).exists():
                return {
                    "status": "error",
                    "mode": "stream",
                    "error": f"File not found: {audio_path}"
                }
            
            # ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            session_record = db_manager.save_session(
                udid=udid,
                child_name=child_name,
                child_age=child_age,
                mode="stream",
                audio_file=audio_path
            )
            
            print("ğŸ”— Connecting to HUME Stream...")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ø¬Ù‡Ø© HUME v0.9.0 Ù„Ù„Ù€ Stream
            socket = await self.async_client.expression_measurement.stream.connect(
                config={"prosody": {}}  # ØªØ­Ù„ÙŠÙ„ Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª ÙÙ‚Ø·
            )
            
            print("ğŸ“¤ Sending audio file...")
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡
            with open(audio_path, 'rb') as audio_file:
                audio_data = audio_file.read()
                result = await socket.send_bytes(audio_data)
            
            await socket.close()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            emotions_data = self._extract_emotions_from_predictions(result)
            
            if emotions_data and session_record:
                print("ğŸ’¾ Saving emotions to database...")
                db_manager.save_emotions(session_record.id, emotions_data)
                db_manager.update_session_status(session_record.id, "success")
            
            print("âœ… Stream analysis completed!")
            
            return {
                "status": "success", 
                "mode": "stream",
                "session_id": session_record.id if session_record else None,
                "file": audio_path,
                "emotions_saved": len(emotions_data) if emotions_data else 0,
                "results": result
            }
                
        except Exception as e:
            print(f"âŒ Stream analysis failed: {e}")
            
            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if session_record:
                db_manager.update_session_status(session_record.id, "error", str(e))
            
            return {
                "status": "error",
                "mode": "stream",
                "session_id": session_record.id if session_record else None,
                "error": str(e)
            }
    
    # ==================== HELPER METHODS ====================
    
    def _extract_emotions_from_predictions(self, predictions: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ğŸ­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ù†ØªØ§Ø¦Ø¬ HUME Ù„Ø­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        
        Args:
            predictions: Ù†ØªØ§Ø¦Ø¬ HUME AI
            
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨ØµÙŠØºØ© [{"name": "Joy", "score": 0.85, "confidence": 0.92}, ...]
        """
        emotions_data = []
        
        try:
            # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Batch
            if isinstance(predictions, list) and predictions:
                # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù ÙƒÙ…Ø«Ø§Ù„
                first_file = predictions[0]
                
                if "models" in first_file and "prosody" in first_file["models"]:
                    prosody = first_file["models"]["prosody"]
                    
                    if "grouped_predictions" in prosody and prosody["grouped_predictions"]:
                        grouped = prosody["grouped_predictions"][0]
                        
                        if "predictions" in grouped:
                            for prediction in grouped["predictions"]:
                                emotion_data = {
                                    "name": prediction.get("name", "unknown"),
                                    "score": float(prediction.get("score", 0.0)),
                                    "confidence": float(prediction.get("confidence", 0.0)) if prediction.get("confidence") else None
                                }
                                emotions_data.append(emotion_data)
                                
            # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Stream 
            elif isinstance(predictions, dict):
                if "prosody" in predictions:
                    prosody_data = predictions["prosody"]
                    
                    if "predictions" in prosody_data:
                        for prediction in prosody_data["predictions"]:
                            emotion_data = {
                                "name": prediction.get("name", "unknown"),
                                "score": float(prediction.get("score", 0.0)),
                                "confidence": float(prediction.get("confidence", 0.0)) if prediction.get("confidence") else None
                            }
                            emotions_data.append(emotion_data)
            
            print(f"ğŸ­ Extracted {len(emotions_data)} emotions from predictions")
            
        except Exception as e:
            print(f"âŒ Error extracting emotions: {e}")
            
        return emotions_data
    
    def extract_emotions_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            if results.get("mode") == "stream":
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†ØªØ§Ø¦Ø¬ Stream
                stream_results = results.get("results", {})
                
                if "prosody" in stream_results:
                    prosody_data = stream_results["prosody"]
                    emotions = {}
                    
                    for prediction in prosody_data.get("predictions", []):
                        emotion_name = prediction.get("name", "unknown")
                        emotion_score = prediction.get("score", 0.0)
                        emotions[emotion_name] = emotion_score
                    
                    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø­Ø³Ø¨ Ø§Ù„Ù‚ÙˆØ©
                    sorted_emotions = sorted(emotions.items(), key=lambda x: x[1], reverse=True)
                    
                    return {
                        "dominant_emotion": sorted_emotions[0] if sorted_emotions else ("neutral", 0.0),
                        "all_emotions": emotions,
                        "top_3_emotions": sorted_emotions[:3]
                    }
            
            elif results.get("mode") == "batch":
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†ØªØ§Ø¦Ø¬ Batch (Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹)
                batch_results = results.get("results", [])
                
                if batch_results:
                    # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù ÙƒÙ…Ø«Ø§Ù„
                    first_file = batch_results[0]
                    
                    if "models" in first_file:
                        models = first_file["models"]
                        
                        summary = {
                            "files_count": len(batch_results),
                            "analysis_types": list(models.keys())
                        }
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Prosody Ø¥Ù† ÙˆØ¬Ø¯Øª
                        if "prosody" in models:
                            prosody = models["prosody"]
                            if "grouped_predictions" in prosody:
                                grouped = prosody["grouped_predictions"]
                                if grouped:
                                    predictions = grouped[0].get("predictions", [])
                                    emotions = {p["name"]: p["score"] for p in predictions}
                                    sorted_emotions = sorted(emotions.items(), key=lambda x: x[1], reverse=True)
                                    
                                    summary.update({
                                        "dominant_emotion": sorted_emotions[0] if sorted_emotions else ("neutral", 0.0),
                                        "all_emotions": emotions,
                                        "top_3_emotions": sorted_emotions[:3]
                                    })
                        
                        return summary
            
            return {"error": "Could not extract emotion summary"}
            
        except Exception as e:
            return {"error": f"Summary extraction failed: {e}"}
    
    def create_sample_files(self):
        """
        ğŸµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        """
        try:
            import numpy as np
            import soundfile as sf
            
            print("ğŸµ Creating sample audio files...")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            sample_rate = 16000
            duration = 3
            
            samples = [
                ("sample_happy.wav", 440),    # Ù†ØºÙ…Ø© Ø³Ø¹ÙŠØ¯Ø©
                ("sample_sad.wav", 220),      # Ù†ØºÙ…Ø© Ø­Ø²ÙŠÙ†Ø©
                ("sample_excited.wav", 660)   # Ù†ØºÙ…Ø© Ù…ØªØ­Ù…Ø³Ø©
            ]
            
            created_files = []
            
            for filename, frequency in samples:
                t = np.linspace(0, duration, sample_rate * duration)
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø© Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©
                audio = 0.3 * np.sin(2 * np.pi * frequency * t)
                
                # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„ØªØ´ÙˆÙŠØ´ Ù„Ø¬Ø¹Ù„Ù‡Ø§ Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
                noise = 0.05 * np.random.random(len(audio))
                audio = audio + noise
                
                sf.write(filename, audio, sample_rate)
                created_files.append(filename)
                print(f"  âœ… Created: {filename}")
            
            return created_files
            
        except Exception as e:
            print(f"âŒ Failed to create sample files: {e}")
            return []


# ==================== TESTING FUNCTIONS ====================

async def test_stream_mode():
    """
    ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Stream
    """
    print("\n" + "="*50)
    print("ğŸ§ª TESTING STREAM MODE")
    print("="*50)
    
    try:
        hume = HumeIntegration()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_files = hume.create_sample_files()
        
        if sample_files:
            audio_file = sample_files[0]  # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù
            
            # ØªØ­Ù„ÙŠÙ„ Stream
            result = await hume.analyze_stream(audio_file)
            
            print(f"\nğŸ“Š Stream Results:")
            print(f"Status: {result.get('status')}")
            
            if result.get('status') == 'success':
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                print(f"\nğŸ­ Emotions Summary:")
                print(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                print(f"Error: {result.get('error')}")
            
            return result
        else:
            print("âŒ No sample files available for testing")
            
    except Exception as e:
        print(f"âŒ Stream test failed: {e}")

def test_batch_mode():
    """
    ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Batch
    """
    print("\n" + "="*50)
    print("ğŸ§ª TESTING BATCH MODE")
    print("="*50)
    
    try:
        hume = HumeIntegration()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        sample_files = hume.create_sample_files()
        
        if sample_files:
            # ØªØ­Ù„ÙŠÙ„ Batch
            result = hume.analyze_batch(sample_files)
            
            print(f"\nğŸ“Š Batch Results:")
            print(f"Status: {result.get('status')}")
            print(f"Files analyzed: {result.get('files_analyzed')}")
            
            if result.get('status') == 'success':
                print(f"Output file: {result.get('output_file')}")
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                print(f"\nğŸ­ Emotions Summary:")
                print(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                print(f"Error: {result.get('error')}")
            
            return result
        else:
            print("âŒ No sample files available for testing")
            
    except Exception as e:
        print(f"âŒ Batch test failed: {e}")

async def run_all_tests():
    """
    ğŸ§ª ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    """
    print("ğŸ¤ HUME AI Integration Testing")
    print("="*60)
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† API Key
    api_key = os.getenv("HUME_API_KEY")
    if not api_key:
        print("âŒ HUME_API_KEY not set!")
        print("ğŸ’¡ Set it with: export HUME_API_KEY='xmkFxYNrKdHjhY6RiEA0JT46C2xAo4YsdiujXqtg5fd1C99Q'")
        return
    
    print(f"ğŸ”‘ API Key: {api_key[:8]}...")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Stream Mode
    await test_stream_mode()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Batch Mode
    test_batch_mode()
    
    print("\n" + "="*60)
    print("âœ… All tests completed!")
    print("ğŸ“ Check 'batch_predictions.json' for detailed results")

if __name__ == "__main__":
    # ØªØ¹ÙŠÙŠÙ† API Key Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    if not os.getenv("HUME_API_KEY"):
        os.environ["HUME_API_KEY"] = "xmkFxYNrKdHjhY6RiEA0JT46C2xAo4YsdiujXqtg5fd1C99Q"
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    asyncio.run(run_all_tests()) 