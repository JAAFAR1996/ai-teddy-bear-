#!/usr/bin/env python3
"""
ğŸ—ï¸ AI Teddy Bear - Smart Reorganization Script
Ø³ÙƒØ±ÙŠØ¨Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹

Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- 261 Ù…Ø¬Ù„Ø¯ ÙÙŠ src/
- 19 Ù…Ø¬Ù„Ø¯ services Ù…Ø®ØªÙ„Ù
- 16 Ù…Ø¬Ù„Ø¯ persistence Ù…Ø®ØªÙ„Ù
- ØªØ¹Ù‚ÙŠØ¯ Ù…Ø¯Ù…Ø± Ù„Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©

Ø§Ù„Ø­Ù„: Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… ØªØ¯Ø±ÙŠØ¬ÙŠ ÙˆØ°ÙƒÙŠ
"""

import os
import shutil
from pathlib import Path
from typing import List, Dict, Set
import json
from datetime import datetime

class SmartReorganizer:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.src_path = self.project_root / "src"
        
        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¬Ø¯ÙŠØ¯
        self.new_structure = {
            "core/domain/entities": [],
            "core/domain/value_objects": [],
            "core/domain/services": [],
            "application/services": [],
            "application/use_cases": [],
            "infrastructure/persistence": [],
            "infrastructure/external_services": [],
            "presentation/api": [],
            "adapters/inbound": [],
            "adapters/outbound": []
        }
        
        # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ
        self.backup_dir = self.project_root / "backup_before_reorganization"
        
    def analyze_current_structure(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ...")
        
        analysis = {
            "total_directories": 0,
            "services_dirs": [],
            "models_dirs": [],
            "persistence_dirs": [],
            "entities_files": [],
            "duplicate_names": {},
            "complexity_score": 0
        }
        
        for root, dirs, files in os.walk(self.src_path):
            analysis["total_directories"] += len(dirs)
            
            for d in dirs:
                full_path = os.path.join(root, d)
                if 'service' in d.lower():
                    analysis["services_dirs"].append(full_path)
                if 'model' in d.lower():
                    analysis["models_dirs"].append(full_path)
                if 'persistence' in d.lower():
                    analysis["persistence_dirs"].append(full_path)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª
            for f in files:
                if f.endswith('.py') and any(entity in f.lower() for entity in 
                    ['child', 'parent', 'conversation', 'device', 'session', 'user']):
                    analysis["entities_files"].append(os.path.join(root, f))
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        analysis["complexity_score"] = (
            analysis["total_directories"] + 
            len(analysis["services_dirs"]) * 2 + 
            len(analysis["persistence_dirs"]) * 2
        )
        
        return analysis
    
    def create_backup(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        print("ğŸ’¾ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        
        shutil.copytree(self.src_path, self.backup_dir / "src")
        
        backup_info = {
            "timestamp": datetime.now().isoformat(),
            "original_structure": str(self.src_path),
            "backup_location": str(self.backup_dir)
        }
        
        with open(self.backup_dir / "backup_info.json", 'w') as f:
            json.dump(backup_info, f, indent=2)
        
        print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ: {self.backup_dir}")
    
    def identify_core_entities(self) -> List[Path]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        print("ğŸ¯ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
        
        entity_files = []
        entity_patterns = [
            'child', 'parent', 'conversation', 'device', 'session', 
            'user', 'teddy', 'voice', 'audio', 'message'
        ]
        
        for root, dirs, files in os.walk(self.src_path):
            for file in files:
                if file.endswith('.py'):
                    file_lower = file.lower()
                    if any(pattern in file_lower for pattern in entity_patterns):
                        # ØªØ¬Ù†Ø¨ test files
                        if 'test' not in file_lower:
                            entity_files.append(Path(root) / file)
        
        return entity_files
    
    def consolidate_services(self) -> Dict[str, List[Path]]:
        """ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª"""
        print("ğŸ”§ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª...")
        
        services_map = {
            "ai_services": [],
            "audio_services": [],
            "child_services": [],
            "parent_services": [],
            "device_services": [],
            "notification_services": []
        }
        
        for root, dirs, files in os.walk(self.src_path):
            for file in files:
                if file.endswith('.py') and 'service' in file.lower():
                    file_path = Path(root) / file
                    file_lower = file.lower()
                    
                    if any(ai_term in file_lower for ai_term in ['ai', 'openai', 'gpt', 'llm']):
                        services_map["ai_services"].append(file_path)
                    elif any(audio_term in file_lower for audio_term in ['audio', 'voice', 'speech', 'tts', 'stt']):
                        services_map["audio_services"].append(file_path)
                    elif 'child' in file_lower:
                        services_map["child_services"].append(file_path)
                    elif 'parent' in file_lower:
                        services_map["parent_services"].append(file_path)
                    elif any(device_term in file_lower for device_term in ['device', 'esp32', 'hardware']):
                        services_map["device_services"].append(file_path)
                    elif any(notif_term in file_lower for notif_term in ['notification', 'alert', 'message']):
                        services_map["notification_services"].append(file_path)
        
        return services_map
    
    def generate_reorganization_plan(self) -> Dict:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…"""
        print("ğŸ“‹ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…...")
        
        analysis = self.analyze_current_structure()
        entities = self.identify_core_entities()
        services = self.consolidate_services()
        
        plan = {
            "current_state": analysis,
            "phase_1_entities": {
                "target_dir": "src/core/domain/entities/",
                "files_to_move": [str(f) for f in entities[:10]]  # Ø£ÙˆÙ„ 10 Ù…Ù„ÙØ§Øª
            },
            "phase_2_services": {
                "target_dirs": {
                    "src/application/services/ai/": [str(f) for f in services["ai_services"]],
                    "src/application/services/audio/": [str(f) for f in services["audio_services"]],
                    "src/application/services/child/": [str(f) for f in services["child_services"]]
                }
            },
            "phase_3_infrastructure": {
                "target_dir": "src/infrastructure/persistence/",
                "files_to_consolidate": analysis["persistence_dirs"]
            },
            "estimated_improvement": {
                "directories_reduction": f"{analysis['total_directories']} â†’ ~40 (-{((analysis['total_directories'] - 40) / analysis['total_directories'] * 100):.0f}%)",
                "services_consolidation": f"{len(analysis['services_dirs'])} â†’ 6 Ù…Ø¬Ù„Ø¯Ø§Øª",
                "maintenance_improvement": "60% ØªØ­Ø³Ù† ÙÙŠ Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø©"
            }
        }
        
        return plan
    
    def execute_phase_1_entities(self, plan: Dict):
        """ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ - Ù†Ù‚Ù„ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª"""
        print("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ - Ù†Ù‚Ù„ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª...")
        
        target_dir = Path(plan["phase_1_entities"]["target_dir"])
        target_dir.mkdir(parents=True, exist_ok=True)
        
        moved_count = 0
        for file_path in plan["phase_1_entities"]["files_to_move"]:
            src_file = Path(file_path)
            if src_file.exists():
                target_file = target_dir / src_file.name
                
                # ØªØ¬Ù†Ø¨ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯
                if target_file.exists():
                    target_file = target_dir / f"{src_file.stem}_migrated{src_file.suffix}"
                
                shutil.move(str(src_file), str(target_file))
                moved_count += 1
                print(f"  âœ… Ù†ÙÙ‚Ù„: {src_file.name}")
        
        print(f"ğŸ¯ ØªÙ… Ù†Ù‚Ù„ {moved_count} Ù…Ù„Ù ÙƒÙŠØ§Ù† Ø¥Ù„Ù‰: {target_dir}")
    
    def generate_summary_report(self, plan: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù…Ù„Ø®Øµ"""
        report = f"""
# ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… - AI Teddy Bear

## Ø§Ù„ÙˆØ¶Ø¹ Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {plan['current_state']['total_directories']}
- Ù…Ø¬Ù„Ø¯Ø§Øª Services: {len(plan['current_state']['services_dirs'])}
- Ù…Ø¬Ù„Ø¯Ø§Øª Persistence: {len(plan['current_state']['persistence_dirs'])}
- Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {plan['current_state']['complexity_score']}

## Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:
{plan['estimated_improvement']['directories_reduction']}
- {plan['estimated_improvement']['services_consolidation']}
- {plan['estimated_improvement']['maintenance_improvement']}

## Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©:
âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ
âœ… ØªÙ… Ù†Ù‚Ù„ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
â³ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„: ServicesØŒ InfrastructureØŒ Presentation

## Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
1. ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (Services)
2. ØªÙ†Ø¸ÙŠÙ Infrastructure
3. ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ imports
4. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…

ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return report

def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    print("ğŸ—ï¸ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù€ AI Teddy Bear!")
    print("="*60)
    
    reorganizer = SmartReorganizer()
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        reorganizer.create_backup()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…
        plan = reorganizer.generate_reorganization_plan()
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø·Ø©
        print("\nğŸ“‹ Ø®Ø·Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…:")
        print(f"- Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ù‚Ù„: {len(plan['phase_1_entities']['files_to_move'])} Ù…Ù„Ù")
        print(f"- ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {plan['estimated_improvement']['directories_reduction']}")
        
        # ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        response = input("\nğŸš€ Ù‡Ù„ ØªØ±ÙŠØ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†ÙÙŠØ°ØŸ (y/n): ")
        
        if response.lower() == 'y':
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
            reorganizer.execute_phase_1_entities(plan)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report = reorganizer.generate_summary_report(plan)
            
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report_file = "reorganization_report.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"\nâœ… ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø¨Ù†Ø¬Ø§Ø­!")
            print(f"ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ ÙÙŠ: {report_file}")
            print("\nğŸ¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
            print("1. Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            print("2. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (Services)")
            print("3. ØªØ­Ø¯ÙŠØ« imports")
            
        else:
            print("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°: {e}")
        print("ğŸ’¾ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…ØªÙˆÙØ±Ø© ÙÙŠ: backup_before_reorganization/")

if __name__ == "__main__":
    main() 