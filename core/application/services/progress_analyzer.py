"""
ğŸ§  Progress Analyzer Service - Task 7 Implementation
ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø·ÙÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLP ÙˆLLM Ù…Ø¹ Chain-of-Thought prompting
"""

from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import json
import asyncio
from dataclasses import dataclass, asdict
import logging

# Import LLM service
try:
    import openai
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False

@dataclass
class ProgressMetrics:
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    child_id: int
    analysis_date: datetime
    total_unique_words: int
    new_words_this_period: List[str]
    vocabulary_complexity_score: float
    reading_level_equivalent: str
    emotional_intelligence_score: float
    cognitive_development_score: float
    social_skills_score: float
    learning_velocity: float
    developmental_concerns: List[str]
    intervention_recommendations: List[str]
    urgency_level: int

@dataclass 
class LLMRecommendation:
    """ØªÙˆØµÙŠØ© Ù…ÙˆÙ„Ø¯Ø© Ø¨ÙˆØ§Ø³Ø·Ø© LLM"""
    category: str
    recommendation: str
    reasoning: str
    expected_impact: str
    implementation_steps: List[str]
    success_metrics: List[str]
    priority_level: int

class ProgressAnalyzer:
    """Ø®Ø¯Ù…Ø© ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø·ÙÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    def __init__(self, database_service=None, config=None):
        self.db = database_service
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self._init_llm_client()
    
    def _init_llm_client(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ LLM"""
        if LLM_AVAILABLE and self.config.get('openai_api_key'):
            self.openai_client = openai.OpenAI(api_key=self.config['openai_api_key'])
            self.logger.info("âœ… OpenAI client initialized")
        else:
            self.logger.warning("âš ï¸ LLM client not available")
    
    async def analyze_progress(self, child_id: int) -> ProgressMetrics:
        """
        ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„Ø·ÙÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLP Ù…ØªÙ‚Ø¯Ù…
        """
        self.logger.info(f"ğŸ§  Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø¯Ù… Ù„Ù„Ø·ÙÙ„ {child_id}")
        
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ (Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        interactions = await self._get_interactions(child_id, start_date, end_date)
        
        if not interactions:
            return self._create_empty_metrics(child_id)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª ÙˆØ§Ù„Ù†ØµÙˆØµ
        vocabulary_analysis = self._analyze_vocabulary(interactions)
        emotional_analysis = self._analyze_emotions(interactions)
        cognitive_analysis = self._analyze_cognitive_skills(interactions)
        social_analysis = self._analyze_social_skills(interactions)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®Ø§ÙˆÙ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
        concerns = self._identify_concerns(vocabulary_analysis, emotional_analysis, cognitive_analysis)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚Ø¯Ù…
        metrics = ProgressMetrics(
            child_id=child_id,
            analysis_date=datetime.now(),
            total_unique_words=vocabulary_analysis['unique_words'],
            new_words_this_period=vocabulary_analysis['new_words'],
            vocabulary_complexity_score=vocabulary_analysis['complexity_score'],
            reading_level_equivalent=vocabulary_analysis['reading_level'],
            emotional_intelligence_score=emotional_analysis['ei_score'],
            cognitive_development_score=cognitive_analysis['cognitive_score'],
            social_skills_score=social_analysis['social_score'],
            learning_velocity=vocabulary_analysis['learning_velocity'],
            developmental_concerns=concerns['concerns'],
            intervention_recommendations=concerns['interventions'],
            urgency_level=concerns['urgency_level']
        )
        
        self.logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø¯Ù… Ù„Ù„Ø·ÙÙ„ {child_id}")
        return metrics
    
    async def generate_llm_recommendations(
        self, 
        child_id: int,
        metrics: ProgressMetrics
    ) -> List[LLMRecommendation]:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù…Ø®ØµØµØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù…Ø¹ Chain-of-Thought prompting
        """
        if not LLM_AVAILABLE or not hasattr(self, 'openai_client'):
            return self._generate_fallback_recommendations(metrics)
        
        # Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·ÙÙ„
        child_info = await self._get_child_info(child_id)
        
        # ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù„ÙƒÙ„ ÙØ¦Ø©
        categories = ["emotional", "cognitive", "social"]
        recommendations = []
        
        for category in categories:
            try:
                recommendation = await self._generate_category_recommendation(
                    category, metrics, child_info
                )
                if recommendation:
                    recommendations.append(recommendation)
            except Exception as e:
                self.logger.error(f"ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ© {category}: {e}")
        
        return recommendations[:3]
    
    async def _generate_category_recommendation(
        self,
        category: str,
        metrics: ProgressMetrics,
        child_info: Dict[str, Any]
    ) -> Optional[LLMRecommendation]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ© Ù„ÙØ¦Ø© Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Chain-of-Thought"""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Chain-of-Thought prompt
        prompt = self._create_cot_prompt(category, metrics, child_info)
        
        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model="gpt-4-turbo-preview",
                messages=[
                    {
                        "role": "system",
                        "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø·ÙÙ„. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ù„ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ù…Ø®ØµØµØ©."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1000,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            return self._parse_llm_response(category, response.choices[0].message.content)
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI Ù„Ù„ÙØ¦Ø© {category}: {e}")
            return None
    
    def _create_cot_prompt(
        self, 
        category: str, 
        metrics: ProgressMetrics, 
        child_info: Dict[str, Any]
    ) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Chain-of-Thought prompt"""
        
        child_name = child_info.get('name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        child_age = child_info.get('age', 5)
        
        prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø·ÙÙ„. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·ÙÙ„ ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ© Ù…Ø®ØµØµØ©.

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·ÙÙ„:
- Ø§Ù„Ø§Ø³Ù…: {child_name}
- Ø§Ù„Ø¹Ù…Ø±: {child_age} Ø³Ù†ÙˆØ§Øª
- Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {category}

Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©: {metrics.total_unique_words}
- Ø¯Ø±Ø¬Ø© ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª: {metrics.vocabulary_complexity_score:.2f}
- Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©: {metrics.reading_level_equivalent}
- Ø¯Ø±Ø¬Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ: {metrics.emotional_intelligence_score:.2f}
- Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ: {metrics.cognitive_development_score:.2f}
- Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©: {metrics.social_skills_score:.2f}

Ø§Ù„Ù…Ø®Ø§ÙˆÙ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: {', '.join(metrics.developmental_concerns) if metrics.developmental_concerns else 'Ù„Ø§ ØªÙˆØ¬Ø¯'}

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©:

Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ
Ù…Ø§ Ù‡ÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„Ø¶Ø¹Ù ÙÙŠ Ù…Ø¬Ø§Ù„ {category} Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ

Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„ØªØ·ÙˆÙŠØ±ÙŠ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø·ÙÙ„ Ø¹Ù…Ø±Ù‡ {child_age} Ø³Ù†ÙˆØ§ØªØŸ

Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
Ù…Ø§ Ù‡ÙŠ Ø£ÙØ¶Ù„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„ØªØ­Ù‚ÙŠÙ‚ Ù‡Ø°Ø§ Ø§Ù„Ù‡Ø¯ÙØŸ

Ø§Ù„Ø®Ø·ÙˆØ© 4: ØªØµÙ…ÙŠÙ… Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† ØªØ·Ø¨ÙŠÙ‚ Ù‡Ø°Ù‡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©ØŸ

Ø§Ù„Ø®Ø·ÙˆØ© 5: Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­
ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù‚ÙŠØ§Ø³ Ù†Ø¬Ø§Ø­ Ù‡Ø°Ù‡ Ø§Ù„ØªÙˆØµÙŠØ©ØŸ

Ù‚Ø¯Ù… Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON:
{{
    "category": "{category}",
    "recommendation": "Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
    "reasoning": "Ø³Ø¨Ø¨ Ù‡Ø°Ù‡ Ø§Ù„ØªÙˆØµÙŠØ©",
    "expected_impact": "Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹",
    "implementation_steps": ["Ø®Ø·ÙˆØ© 1", "Ø®Ø·ÙˆØ© 2", "Ø®Ø·ÙˆØ© 3"],
    "success_metrics": ["Ù…Ø¹ÙŠØ§Ø± 1", "Ù…Ø¹ÙŠØ§Ø± 2"],
    "priority_level": 3
}}
"""
        return prompt
    
    def _parse_llm_response(self, category: str, response: str) -> LLMRecommendation:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© LLM"""
        try:
            data = json.loads(response)
            return LLMRecommendation(
                category=data.get('category', category),
                recommendation=data.get('recommendation', ''),
                reasoning=data.get('reasoning', ''),
                expected_impact=data.get('expected_impact', ''),
                implementation_steps=data.get('implementation_steps', []),
                success_metrics=data.get('success_metrics', []),
                priority_level=data.get('priority_level', 3)
            )
        except json.JSONDecodeError:
            # Fallback parsing
            return LLMRecommendation(
                category=category,
                recommendation=response[:150] if response else "ØªÙˆØµÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©",
                reasoning="ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…",
                expected_impact="ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ø­Ø¯Ø¯",
                implementation_steps=["Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚", "Ù‚ÙŠØ§Ø³ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"],
                success_metrics=["ØªØ­Ø³Ù† Ù…Ù„Ø­ÙˆØ¸"],
                priority_level=3
            )
    
    async def generate_and_store_report(self, child_id: int) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ÙˆØ­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ø¯Ù…
        metrics = await self.analyze_progress(child_id)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        recommendations = await self.generate_llm_recommendations(child_id, metrics)
        
        # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        report_id = await self._store_report(metrics, recommendations)
        
        return {
            'report_id': report_id,
            'metrics': asdict(metrics),
            'recommendations': [asdict(rec) for rec in recommendations],
            'generated_at': datetime.now().isoformat()
        }
    
    async def _store_report(
        self, 
        metrics: ProgressMetrics, 
        recommendations: List[LLMRecommendation]
    ) -> str:
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not self.db:
            raise Exception("Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")
        
        try:
            report_id = await self.db.execute(
                """
                INSERT INTO parent_reports 
                (child_id, generated_at, metrics, recommendations, analysis_version)
                VALUES (?, ?, ?, ?, ?)
                """,
                (
                    metrics.child_id,
                    metrics.analysis_date.isoformat(),
                    json.dumps(asdict(metrics)),
                    json.dumps([asdict(rec) for rec in recommendations]),
                    'Task7_v1.0'
                )
            )
            
            self.logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ø±Ù‚Ù…: {report_id}")
            return str(report_id)
            
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
            raise
    
    # Helper methods for analysis
    
    def _analyze_vocabulary(self, interactions: List[Dict]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª ÙˆØ§Ù„Ù†ØµÙˆØµ"""
        texts = [i.get('message', '') for i in interactions if i.get('message')]
        all_text = ' '.join(texts)
        
        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„Ù…ÙØ±Ø¯Ø§Øª
        words = all_text.lower().split()
        unique_words = list(set(words))
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        complexity_score = min(1.0, len(unique_words) / 50.0)
        
        # ØªÙ‚Ø¯ÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©
        if complexity_score < 0.3:
            reading_level = "Ù…Ø¨ØªØ¯Ø¦"
        elif complexity_score < 0.6:
            reading_level = "Ù…ØªÙˆØ³Ø·"
        else:
            reading_level = "Ù…ØªÙ‚Ø¯Ù…"
        
        return {
            'unique_words': len(unique_words),
            'new_words': unique_words[-5:] if len(unique_words) > 5 else unique_words,
            'complexity_score': complexity_score,
            'reading_level': reading_level,
            'learning_velocity': len(unique_words) / 7  # ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø§Ù„ÙŠÙˆÙ…
        }
    
    def _analyze_emotions(self, interactions: List[Dict]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ"""
        emotion_keywords = ['happy', 'sad', 'angry', 'excited', 'worried', 'calm']
        texts = [i.get('message', '') for i in interactions if i.get('message')]
        
        emotion_count = 0
        for text in texts:
            for emotion in emotion_keywords:
                if emotion.lower() in text.lower():
                    emotion_count += 1
        
        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ
        ei_score = min(1.0, emotion_count / max(1, len(texts)))
        
        return {
            'ei_score': ei_score,
            'emotion_expressions': emotion_count
        }
    
    def _analyze_cognitive_skills(self, interactions: List[Dict]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©"""
        texts = [i.get('message', '') for i in interactions if i.get('message')]
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ
        cognitive_indicators = ['why', 'how', 'what if', 'because', 'Ù„Ù…Ø§Ø°Ø§', 'ÙƒÙŠÙ']
        cognitive_count = 0
        
        for text in texts:
            for indicator in cognitive_indicators:
                if indicator.lower() in text.lower():
                    cognitive_count += 1
        
        cognitive_score = min(1.0, cognitive_count / max(1, len(texts)))
        
        return {
            'cognitive_score': cognitive_score,
            'thinking_indicators': cognitive_count
        }
    
    def _analyze_social_skills(self, interactions: List[Dict]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©"""
        texts = [i.get('message', '') for i in interactions if i.get('message')]
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
        social_indicators = ['please', 'thank you', 'sorry', 'share', 'help']
        social_count = 0
        
        for text in texts:
            for indicator in social_indicators:
                if indicator.lower() in text.lower():
                    social_count += 1
        
        social_score = min(1.0, social_count / max(1, len(texts)))
        
        return {
            'social_score': social_score,
            'social_expressions': social_count
        }
    
    def _identify_concerns(self, vocab_analysis, emotional_analysis, cognitive_analysis) -> Dict[str, Any]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®Ø§ÙˆÙ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª"""
        concerns = []
        interventions = []
        urgency_level = 0
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        if vocab_analysis['complexity_score'] < 0.3:
            concerns.append("Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© ÙÙŠ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª")
            interventions.append("Ø²ÙŠØ§Ø¯Ø© Ø£Ù†Ø´Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„Ø­Ø¯ÙŠØ«")
            urgency_level = max(urgency_level, 2)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        if emotional_analysis['ei_score'] < 0.3:
            concerns.append("Ù‚Ù„Ø© Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø§Ù„Ø¹Ø§Ø·ÙÙŠ")
            interventions.append("Ø£Ù†Ø´Ø·Ø© ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
            urgency_level = max(urgency_level, 1)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©
        if cognitive_analysis['cognitive_score'] < 0.3:
            concerns.append("Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù†Ù‚Ø¯ÙŠ")
            interventions.append("Ø£Ù†Ø´Ø·Ø© ØªØ·ÙˆÙŠØ± Ø§Ù„ØªÙÙƒÙŠØ±")
            urgency_level = max(urgency_level, 1)
        
        return {
            'concerns': concerns,
            'interventions': interventions,
            'urgency_level': urgency_level
        }
    
    def _create_empty_metrics(self, child_id: int) -> ProgressMetrics:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§ÙŠÙŠØ³ ÙØ§Ø±ØºØ©"""
        return ProgressMetrics(
            child_id=child_id,
            analysis_date=datetime.now(),
            total_unique_words=0,
            new_words_this_period=[],
            vocabulary_complexity_score=0.0,
            reading_level_equivalent="ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
            emotional_intelligence_score=0.0,
            cognitive_development_score=0.0,
            social_skills_score=0.0,
            learning_velocity=0.0,
            developmental_concerns=["Ø¹Ø¯Ù… ØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©"],
            intervention_recommendations=["Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„"],
            urgency_level=0
        )
    
    def _generate_fallback_recommendations(self, metrics: ProgressMetrics) -> List[LLMRecommendation]:
        """ØªÙˆØµÙŠØ§Øª Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        recommendations = []
        
        if metrics.vocabulary_complexity_score < 0.5:
            recommendations.append(LLMRecommendation(
                category="learning",
                recommendation="Ø²ÙŠØ§Ø¯Ø© Ø£Ù†Ø´Ø·Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
                reasoning="Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª ØªØ­ØªØ§Ø¬ ØªØ·ÙˆÙŠØ±",
                expected_impact="ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ± ÙˆØ§Ù„ÙÙ‡Ù…",
                implementation_steps=["Ù‚Ø±Ø§Ø¡Ø© ÙŠÙˆÙ…ÙŠØ©", "Ù…Ø­Ø§Ø¯Ø«Ø§Øª ØªÙØ§Ø¹Ù„ÙŠØ©"],
                success_metrics=["Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª"],
                priority_level=4
            ))
        
        if metrics.emotional_intelligence_score < 0.5:
            recommendations.append(LLMRecommendation(
                category="emotional",
                recommendation="Ø£Ù†Ø´Ø·Ø© ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ",
                reasoning="Ù‚Ù„Ø© Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø§Ù„Ø¹Ø§Ø·ÙÙŠ",
                expected_impact="ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
                implementation_steps=["Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", "Ù‚ØµØµ Ø¹Ø§Ø·ÙÙŠØ©"],
                success_metrics=["ØªØ¹Ø¨ÙŠØ± Ø£ÙØ¶Ù„ Ø¹Ù† Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"],
                priority_level=3
            ))
        
        return recommendations[:3]
    
    async def _get_interactions(self, child_id: int, start_date: datetime, end_date: datetime) -> List[Dict]:
        """Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not self.db:
            return []
        
        try:
            interactions = await self.db.fetch_all(
                """
                SELECT * FROM conversations 
                WHERE child_id = ? AND created_at BETWEEN ? AND ?
                ORDER BY created_at DESC
                """,
                (child_id, start_date.isoformat(), end_date.isoformat())
            )
            return [dict(row) for row in interactions]
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª: {e}")
            return []
    
    async def _get_child_info(self, child_id: int) -> Dict[str, Any]:
        """Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·ÙÙ„"""
        if not self.db:
            return {'name': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'age': 5}
        
        try:
            child = await self.db.fetch_one(
                "SELECT * FROM children WHERE id = ?", (child_id,)
            )
            return dict(child) if child else {'name': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'age': 5}
        except Exception as e:
            self.logger.error(f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·ÙÙ„: {e}")
            return {'name': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'age': 5} 