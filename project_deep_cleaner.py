#!/usr/bin/env python3
"""
AI Teddy Bear Project Deep Cleaner
Ø£Ø¯Ø§Ø© ØªÙ†Ø¸ÙŠÙ Ø¹Ù…ÙŠÙ‚Ø© ÙˆØ´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
"""

import os
import shutil
import hashlib
import json
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set, Tuple
from collections import defaultdict
import ast

class ProjectDeepCleaner:
    """Ù…Ù†Ø¸Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„Ø´Ø§Ù…Ù„"""
    
    def __init__(self, dry_run: bool = True):
        self.dry_run = dry_run
        self.project_root = Path(".")
        self.backup_dir = Path(f"backup_before_cleaning_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        
        # Ù‚Ø±Ø§Ø¡Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        self.analysis_report = self._load_analysis_report()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.stats = {
            'files_deleted': 0,
            'files_moved': 0,
            'files_merged': 0,
            'security_fixed': 0,
            'imports_updated': 0,
            'errors': []
        }
        
        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù„Ù„imports
        self.import_mappings = {}
        
    def _load_analysis_report(self) -> Dict:
        """ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        try:
            with open('cleanup_analysis_report.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
            return {}
    
    def clean_project(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"""
        print("ğŸ§¹ Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù…ÙŠÙ‚...")
        print(f"ğŸ“¦ ÙˆØ¶Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„: {'ØªØ¬Ø±ÙŠØ¨ÙŠ (Dry Run)' if self.dry_run else 'Ø­Ù‚ÙŠÙ‚ÙŠ'}")
        
        if not self.dry_run:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            self._create_backup()
        
        # 1. Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ù…Ø§Ù…Ø© ÙˆØ§Ù„ÙØ§Ø±ØºØ©
        print("\nğŸ—‘ï¸ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©...")
        self._delete_trash_files()
        
        # 2. Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        print("\nğŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©...")
        self._merge_duplicate_files()
        
        # 3. Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„ØµØ­ÙŠØ­Ø©
        print("\nğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‡ÙŠÙƒÙ„...")
        self._reorganize_structure()
        
        # 4. Ø¥ØµÙ„Ø§Ø­ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§Ù†
        print("\nğŸ” Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§Ù†...")
        self._fix_security_issues()
        
        # 5. ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ imports
        print("\nğŸ”— Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: ØªØ­Ø¯ÙŠØ« imports...")
        self._update_all_imports()
        
        # 6. ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ
        print("\nâœ¨ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ...")
        self._final_cleanup()
        
        # 7. Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")
        self._generate_final_report()
        
    def _create_backup(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        print(f"ğŸ“¦ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ: {self.backup_dir}")
        
        # Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙ‚Ø·
        important_patterns = [
            "**/*.py",
            "**/*.json",
            "**/*.yaml",
            "**/*.yml",
            "**/*.md",
            "**/requirements*.txt",
            "**/Dockerfile*",
            "**/.env*"
        ]
        
        self.backup_dir.mkdir(exist_ok=True)
        
        for pattern in important_patterns:
            for file_path in self.project_root.glob(pattern):
                if '.git' not in str(file_path) and '__pycache__' not in str(file_path):
                    relative_path = file_path.relative_to(self.project_root)
                    backup_path = self.backup_dir / relative_path
                    backup_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, backup_path)
    
    def _delete_trash_files(self):
        """Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ù…Ø§Ù…Ø© ÙˆØ§Ù„ÙØ§Ø±ØºØ©"""
        trash_files = self.analysis_report.get('trash_files', [])
        
        # Ø¥Ø¶Ø§ÙØ© Ø£Ù†Ù…Ø§Ø· Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø­Ø°Ù
        additional_patterns = [
            "**/__pycache__/**",
            "**/*.pyc",
            "**/*.pyo",
            "**/*.pyd",
            "**/.pytest_cache/**",
            "**/.mypy_cache/**",
            "**/*.egg-info/**",
            "**/dist/**",
            "**/build/**",
            "**/.coverage",
            "**/.DS_Store",
            "**/Thumbs.db",
            "**/*_old.py",
            "**/*_backup.py",
            "**/*_temp.py",
            "**/*_copy.py"
        ]
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø­Ø°Ù
        for pattern in additional_patterns:
            for file_path in self.project_root.glob(pattern):
                trash_files.append(str(file_path))
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ©
        for py_file in self.project_root.glob("**/*.py"):
            try:
                if py_file.stat().st_size == 0:
                    trash_files.append(str(py_file))
                else:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        # Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø£Ùˆ pass
                        if not content or content == 'pass' or all(
                            line.strip().startswith('#') or not line.strip() 
                            for line in content.splitlines()
                        ):
                            trash_files.append(str(py_file))
            except:
                pass
        
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª
        trash_files = list(set(trash_files))  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        
        for file_path in trash_files:
            try:
                path = Path(file_path)
                if path.exists():
                    if self.dry_run:
                        print(f"   [DRY RUN] Ø³ÙŠØªÙ… Ø­Ø°Ù: {file_path}")
                    else:
                        if path.is_file():
                            path.unlink()
                        else:
                            shutil.rmtree(path)
                        print(f"   âœ… ØªÙ… Ø­Ø°Ù: {file_path}")
                    self.stats['files_deleted'] += 1
            except Exception as e:
                self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù {file_path}: {e}")
    
    def _merge_duplicate_files(self):
        """Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
        duplicates = self.analysis_report.get('duplicates', [])
        
        for dup_group in duplicates:
            if dup_group['type'] == 'exact' and dup_group['count'] > 1:
                files = dup_group['files']
                
                # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù„Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡
                best_file = self._select_best_file(files)
                
                # Ø­Ø°Ù Ø§Ù„Ø¨Ù‚ÙŠØ© ÙˆØªØ­Ø¯ÙŠØ« imports
                for file_path in files:
                    if file_path != best_file:
                        # ØªØ­Ø¯ÙŠØ« Ø®Ø±ÙŠØ·Ø© imports
                        old_import = self._path_to_import(file_path)
                        new_import = self._path_to_import(best_file)
                        self.import_mappings[old_import] = new_import
                        
                        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù
                        try:
                            if self.dry_run:
                                print(f"   [DRY RUN] Ø¯Ù…Ø¬: {file_path} -> {best_file}")
                            else:
                                Path(file_path).unlink()
                                print(f"   âœ… Ø¯Ù…Ø¬: {file_path} -> {best_file}")
                            self.stats['files_merged'] += 1
                        except Exception as e:
                            self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ø¯Ù…Ø¬ {file_path}: {e}")
    
    def _select_best_file(self, files: List[str]) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù…Ù† Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª"""
        scores = {}
        
        for file_path in files:
            score = 0
            
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ src/
            if file_path.startswith('src/'):
                score += 10
            
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø®Ø§Ø±Ø¬ backup
            if 'backup' not in file_path:
                score += 5
            
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„ØµØ­ÙŠØ­Ø©
            if any(correct in file_path for correct in [
                'core/domain', 'core/services', 'infrastructure',
                'api/endpoints', 'tests/'
            ]):
                score += 3
            
            # ØªÙØ¶ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØµÙÙŠØ©
            if not file_path.endswith('__init__.py'):
                score += 2
            
            scores[file_path] = score
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ù„Ù Ø¨Ø£Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø·
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def _reorganize_structure(self):
        """Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        moves = self.analysis_report.get('suggested_moves', [])
        
        # Ø¥Ø¶Ø§ÙØ© Ù‚ÙˆØ§Ø¹Ø¯ Ù†Ù‚Ù„ Ø¥Ø¶Ø§ÙÙŠØ©
        additional_rules = {
            'esp32/': 'hardware/esp32/',
            'chaos/': 'src/testing/chaos/',
            'api/': 'src/api/',
            'configs/': 'config/',
            'scripts/migration/': 'tools/migration/',
            'scripts/': 'tools/scripts/',
            'observability/': 'src/infrastructure/monitoring/',
            'monitoring/': 'src/infrastructure/monitoring/',
            'deployments/': 'deploy/',
            'frontend/': 'src/presentation/web/'
        }
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        for old_prefix, new_prefix in additional_rules.items():
            for file_path in self.project_root.glob(f"{old_prefix}**/*.py"):
                relative_path = str(file_path.relative_to(self.project_root))
                new_path = relative_path.replace(old_prefix, new_prefix, 1)
                
                if relative_path != new_path:
                    moves.append({
                        'from': relative_path,
                        'to': new_path,
                        'reason': 'Better organization'
                    })
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ù†Ù‚Ù„
        for move in moves:
            old_path = Path(move['from'])
            new_path = Path(move['to'])
            
            if old_path.exists():
                try:
                    # ØªØ­Ø¯ÙŠØ« Ø®Ø±ÙŠØ·Ø© imports
                    old_import = self._path_to_import(str(old_path))
                    new_import = self._path_to_import(str(new_path))
                    self.import_mappings[old_import] = new_import
                    
                    if self.dry_run:
                        print(f"   [DRY RUN] Ù†Ù‚Ù„: {old_path} -> {new_path}")
                    else:
                        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù‡Ø¯Ù
                        new_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        # Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù
                        shutil.move(str(old_path), str(new_path))
                        print(f"   âœ… Ù†Ù‚Ù„: {old_path} -> {new_path}")
                    
                    self.stats['files_moved'] += 1
                    
                except Exception as e:
                    self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ù†Ù‚Ù„ {old_path}: {e}")
    
    def _fix_security_issues(self):
        """Ø¥ØµÙ„Ø§Ø­ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§Ù†"""
        security_issues = self.analysis_report.get('security_issues', [])
        
        for issue in security_issues:
            file_path = Path(issue['file'])
            issue_type = issue['issue']
            
            if file_path.exists() and file_path.suffix == '.py':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    original_content = content
                    
                    # Ø¥ØµÙ„Ø§Ø­ eval/exec
                    if 'eval/exec usage' in issue_type:
                        content = re.sub(r'\beval\s*\(', '# SECURITY_FIXED: eval(', content)
                        content = re.sub(r'\bexec\s*\(', '# SECURITY_FIXED: exec(', content)
                    
                    # Ø¥ØµÙ„Ø§Ø­ hardcoded secrets
                    if 'hardcoded secrets' in issue_type:
                        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø´ÙØ±Ø© Ø¨Ù…ØªØºÙŠØ±Ø§Øª Ø¨ÙŠØ¦Ø©
                        content = re.sub(
                            r'(password|token|secret|api_key)\s*=\s*["\']([^"\']+)["\']',
                            r'\1 = os.getenv("\1_ENV", "REDACTED")',
                            content,
                            flags=re.IGNORECASE
                        )
                        
                        # Ø¥Ø¶Ø§ÙØ© import os Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                        if 'os.getenv' in content and 'import os' not in content:
                            content = 'import os\n' + content
                    
                    if content != original_content:
                        if self.dry_run:
                            print(f"   [DRY RUN] Ø¥ØµÙ„Ø§Ø­ Ø£Ù…Ø§Ù†: {file_path}")
                        else:
                            with open(file_path, 'w', encoding='utf-8') as f:
                                f.write(content)
                            print(f"   âœ… Ø¥ØµÙ„Ø§Ø­ Ø£Ù…Ø§Ù†: {file_path}")
                        self.stats['security_fixed'] += 1
                        
                except Exception as e:
                    self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ø¥ØµÙ„Ø§Ø­ Ø£Ù…Ø§Ù† {file_path}: {e}")
    
    def _update_all_imports(self):
        """ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ imports ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        if not self.import_mappings:
            print("   â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ imports ØªØ­ØªØ§Ø¬ ØªØ­Ø¯ÙŠØ«")
            return
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python
        for py_file in self.project_root.glob("**/*.py"):
            if '.git' in str(py_file) or '__pycache__' in str(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                original_content = content
                
                # ØªØ­Ø¯ÙŠØ« imports
                for old_import, new_import in self.import_mappings.items():
                    # import statements
                    content = re.sub(
                        f'\\bimport\\s+{re.escape(old_import)}\\b',
                        f'import {new_import}',
                        content
                    )
                    
                    # from ... import statements
                    content = re.sub(
                        f'\\bfrom\\s+{re.escape(old_import)}\\b',
                        f'from {new_import}',
                        content
                    )
                
                if content != original_content:
                    if self.dry_run:
                        print(f"   [DRY RUN] ØªØ­Ø¯ÙŠØ« imports ÙÙŠ: {py_file}")
                    else:
                        with open(py_file, 'w', encoding='utf-8') as f:
                            f.write(content)
                        print(f"   âœ… ØªØ­Ø¯ÙŠØ« imports ÙÙŠ: {py_file}")
                    self.stats['imports_updated'] += 1
                    
            except Exception as e:
                self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« imports {py_file}: {e}")
    
    def _path_to_import(self, file_path: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ import path"""
        # Ø¥Ø²Ø§Ù„Ø© .py
        import_path = file_path.replace('.py', '')
        
        # ØªØ­ÙˆÙŠÙ„ / Ø¥Ù„Ù‰ .
        import_path = import_path.replace('/', '.').replace('\\', '.')
        
        # Ø¥Ø²Ø§Ù„Ø© src. Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
        if import_path.startswith('src.'):
            import_path = import_path[4:]
        
        return import_path
    
    def _final_cleanup(self):
        """ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ"""
        # Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
        for root, dirs, files in os.walk(self.project_root, topdown=False):
            for dir_name in dirs:
                dir_path = Path(root) / dir_name
                if not any(dir_path.iterdir()) and '.git' not in str(dir_path):
                    try:
                        if self.dry_run:
                            print(f"   [DRY RUN] Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ ÙØ§Ø±Øº: {dir_path}")
                        else:
                            dir_path.rmdir()
                            print(f"   âœ… Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ ÙØ§Ø±Øº: {dir_path}")
                    except:
                        pass
        
        # ØªÙ†Ø¸ÙŠÙ __init__.py Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        self._cleanup_init_files()
    
    def _cleanup_init_files(self):
        """ØªÙ†Ø¸ÙŠÙ Ù…Ù„ÙØ§Øª __init__.py Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ __init__.py
        init_files = list(self.project_root.glob("**/__init__.py"))
        
        for init_file in init_files:
            try:
                # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Python Ø£Ø®Ø±Ù‰
                parent_dir = init_file.parent
                other_py_files = [
                    f for f in parent_dir.glob("*.py") 
                    if f.name != "__init__.py"
                ]
                
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ù…Ù„ÙØ§Øª Python Ø£Ø®Ø±Ù‰ØŒ Ø§Ø­Ø°Ù __init__.py
                if not other_py_files and not any(parent_dir.glob("*/")):
                    if self.dry_run:
                        print(f"   [DRY RUN] Ø­Ø°Ù __init__.py Ø²Ø§Ø¦Ø¯: {init_file}")
                    else:
                        init_file.unlink()
                        print(f"   âœ… Ø­Ø°Ù __init__.py Ø²Ø§Ø¦Ø¯: {init_file}")
                    self.stats['files_deleted'] += 1
                    
            except Exception as e:
                self.stats['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ {init_file}: {e}")
    
    def _generate_final_report(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        report = f"""# ğŸ“Š ØªÙ‚Ø±ÙŠØ± ØªÙ†Ø¸ÙŠÙ Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear

## ğŸ“… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ
- **Ø§Ù„ØªØ§Ø±ÙŠØ®**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
- **ÙˆØ¶Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„**: {'ØªØ¬Ø±ÙŠØ¨ÙŠ (Dry Run)' if self.dry_run else 'Ø­Ù‚ÙŠÙ‚ÙŠ'}
- **Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ**: {self.backup_dir if not self.dry_run else 'N/A'}

## ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©

### âœ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø¬Ø²Ø©
- **Ù…Ù„ÙØ§Øª Ù…Ø­Ø°ÙˆÙØ©**: {self.stats['files_deleted']}
- **Ù…Ù„ÙØ§Øª Ù…Ù†Ù‚ÙˆÙ„Ø©**: {self.stats['files_moved']}
- **Ù…Ù„ÙØ§Øª Ù…Ø¯Ù…ÙˆØ¬Ø©**: {self.stats['files_merged']}
- **Ù…Ø´Ø§ÙƒÙ„ Ø£Ù…Ø§Ù† Ù…ÙØµÙ„Ø­Ø©**: {self.stats['security_fixed']}
- **imports Ù…Ø­Ø¯Ø«Ø©**: {self.stats['imports_updated']}

### âŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ({len(self.stats['errors'])})
"""
        
        for error in self.stats['errors'][:10]:
            report += f"- {error}\n"
        
        if len(self.stats['errors']) > 10:
            report += f"\n... Ùˆ {len(self.stats['errors']) - 10} Ø®Ø·Ø£ Ø¢Ø®Ø±\n"
        
        report += f"""
## ğŸ¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

1. **Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª**: ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† ÙƒÙ„ Ø´ÙŠØ¡ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
2. **ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª**: `python -m pytest`
3. **ØªØ­Ø¯ÙŠØ« requirements.txt**: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
4. **ØªØ´ØºÙŠÙ„ linters**: `black .` Ùˆ `isort .` Ùˆ `flake8 .`
5. **Commit Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª**: `git add -A && git commit -m "Major project cleanup"`

## ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§ÙØ©

1. Ø§Ø³ØªØ®Ø¯Ù… pre-commit hooks
2. Ø§ØªØ¨Ø¹ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡
3. Ù„Ø§ ØªÙƒØ±Ø± Ø§Ù„ÙƒÙˆØ¯ - Ø§Ø³ØªØ®Ø¯Ù… DRY principle
4. Ø§Ø­Ø°Ù Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙŠØª ÙÙˆØ±Ø§Ù‹
5. Ø§ÙƒØªØ¨ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù„ÙƒÙ„ Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©

---
ØªÙ… Ø¨ÙˆØ§Ø³Ø·Ø©: AI Teddy Bear Deep Cleaner ğŸ§¹
"""
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_path = f"cleanup_report_{'dry_run' if self.dry_run else 'final'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {report_path}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ
        print("\n" + "="*50)
        print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:")
        print(f"   ğŸ—‘ï¸ Ù…Ù„ÙØ§Øª Ù…Ø­Ø°ÙˆÙØ©: {self.stats['files_deleted']}")
        print(f"   ğŸ“‚ Ù…Ù„ÙØ§Øª Ù…Ù†Ù‚ÙˆÙ„Ø©: {self.stats['files_moved']}")
        print(f"   ğŸ”„ Ù…Ù„ÙØ§Øª Ù…Ø¯Ù…ÙˆØ¬Ø©: {self.stats['files_merged']}")
        print(f"   ğŸ” Ù…Ø´Ø§ÙƒÙ„ Ø£Ù…Ø§Ù† Ù…ÙØµÙ„Ø­Ø©: {self.stats['security_fixed']}")
        print(f"   ğŸ”— imports Ù…Ø­Ø¯Ø«Ø©: {self.stats['imports_updated']}")
        
        if self.stats['errors']:
            print(f"   âŒ Ø£Ø®Ø·Ø§Ø¡: {len(self.stats['errors'])}")
        else:
            print("   âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡!")
        
        print("="*50)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="AI Teddy Bear Project Deep Cleaner")
    parser.add_argument(
        '--execute', 
        action='store_true',
        help='ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙØ¹Ù„ÙŠØ§Ù‹ (Ø¨Ø¯ÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø®ÙŠØ§Ø± Ø³ÙŠØ¹Ù…Ù„ ÙÙŠ ÙˆØ¶Ø¹ ØªØ¬Ø±ÙŠØ¨ÙŠ)'
    )
    
    args = parser.parse_args()
    
    cleaner = ProjectDeepCleaner(dry_run=not args.execute)
    cleaner.clean_project() 