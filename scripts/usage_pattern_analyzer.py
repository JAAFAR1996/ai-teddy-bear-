#!/usr/bin/env python3
"""
Usage Pattern Analyzer
Ø£Ø¯Ø§Ø© ÙØ­Øµ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ ÙŠØ­ØªØ§Ø¬Ù‡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
"""

import ast
import os
import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set, Tuple


class UsagePatternAnalyzer:
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.usage_data = {
            "timestamp": datetime.now().isoformat(),
            "file_references": defaultdict(list),  # Ù…Ù† ÙŠØ³ØªÙˆØ±Ø¯ Ù…Ù†
            "import_patterns": defaultdict(set),  # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
            "actual_usage": {},  # Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ
            "unused_files": [],  # Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
            "critical_files": [],  # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø±Ø¬Ø©
            "merge_recommendations": {},  # ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¯Ù…Ø¬
        }

    def scan_all_python_files(self) -> List[Path]:
        """ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        python_files = []

        # ÙØ­Øµ src/ Ùˆ api/ Ùˆ frontend/ Ùˆ tests/
        scan_dirs = ["src", "api", "frontend", "tests", "scripts"]

        for scan_dir in scan_dirs:
            dir_path = self.base_path / scan_dir
            if dir_path.exists():
                python_files.extend(dir_path.rglob("*.py"))

        return python_files

    def extract_imports_from_file(self, file_path: Path) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ù† Ù…Ù„Ù Python"""
        imports_data = {
            "file_path": str(file_path),
            "imports": [],
            "from_imports": [],
            "relative_imports": [],
            "service_imports": [],
        }

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… regex Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
            import_patterns = [
                r"^import\s+([^\s#]+)",  # import module
                r"^from\s+([^\s]+)\s+import\s+([^#]+)",  # from module import something
            ]

            lines = content.split("\n")
            for line_num, line in enumerate(lines, 1):
                line = line.strip()

                # import statements
                if line.startswith("import "):
                    match = re.match(r"^import\s+([^\s#]+)", line)
                    if match:
                        module = match.group(1)
                        imports_data["imports"].append(
                            {"module": module, "line": line_num, "full_line": line}
                        )

                # from ... import statements
                elif line.startswith("from "):
                    match = re.match(r"^from\s+([^\s]+)\s+import\s+([^#]+)", line)
                    if match:
                        module = match.group(1)
                        imports = match.group(2).strip()
                        imports_data["from_imports"].append(
                            {
                                "module": module,
                                "imports": imports,
                                "line": line_num,
                                "full_line": line,
                            }
                        )

                        # ÙØ­Øµ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
                        if "service" in module.lower() or "service" in imports.lower():
                            imports_data["service_imports"].append(
                                {"module": module, "imports": imports, "line": line_num}
                            )

        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {file_path}: {e}")

        return imports_data

    def analyze_service_usage_patterns(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø§Øª"""
        print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø§Øª...")

        # ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„Ø©
        deprecated_services = self.base_path / "deprecated" / "services"
        if not deprecated_services.exists():
            print("âŒ Ù…Ø¬Ù„Ø¯ deprecated/services ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
            return {}

        # Ø¬Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        service_files = {}
        for group_dir in deprecated_services.iterdir():
            if group_dir.is_dir():
                for service_file in group_dir.glob("*.py"):
                    service_name = service_file.stem
                    service_files[service_name] = {
                        "path": str(service_file),
                        "group": group_dir.name,
                        "references": [],
                        "usage_count": 0,
                    }

        print(f"  ğŸ“„ Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {len(service_files)}")

        # ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹
        python_files = self.scan_all_python_files()
        print(f"  ğŸ“ Ù…Ù„ÙØ§Øª Python Ù„Ù„ÙØ­Øµ: {len(python_files)}")

        for py_file in python_files:
            imports_data = self.extract_imports_from_file(py_file)

            # ÙØ­Øµ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ù„ÙƒÙ„ Ø®Ø¯Ù…Ø©
            for service_name, service_info in service_files.items():
                file_content = ""
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        file_content = f.read()
                except:
                    continue

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø®Ø¯Ù…Ø©
                references_found = []

                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
                for imp in imports_data["imports"] + imports_data["from_imports"]:
                    if service_name.lower() in str(imp).lower():
                        references_found.append(
                            {
                                "type": "import",
                                "line": imp.get("line", 0),
                                "content": imp.get("full_line", str(imp)),
                            }
                        )

                # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø§Ù…
                if service_name in file_content:
                    lines = file_content.split("\n")
                    for line_num, line in enumerate(lines, 1):
                        if service_name in line and not line.strip().startswith("#"):
                            references_found.append(
                                {
                                    "type": "usage",
                                    "line": line_num,
                                    "content": line.strip()[:100],  # Ø£ÙˆÙ„ 100 Ø­Ø±Ù
                                }
                            )

                if references_found:
                    service_files[service_name]["references"].append(
                        {"file": str(py_file), "references": references_found}
                    )
                    service_files[service_name]["usage_count"] += len(references_found)

        return service_files

    def classify_services_by_usage(self, service_usage: Dict) -> Dict:
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        print("ğŸ“Š ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…...")

        classification = {
            "heavily_used": [],  # Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¨ÙƒØ«Ø±Ø© (5+ Ù…Ø±Ø§Ø¬Ø¹)
            "moderately_used": [],  # Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…ØªÙˆØ³Ø· (2-4 Ù…Ø±Ø§Ø¬Ø¹)
            "lightly_used": [],  # Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹ (1 Ù…Ø±Ø¬Ø¹)
            "unused": [],  # ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© (0 Ù…Ø±Ø§Ø¬Ø¹)
            "test_only": [],  # Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙ‚Ø·
        }

        for service_name, service_data in service_usage.items():
            usage_count = service_data["usage_count"]
            references = service_data["references"]

            # ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙ‚Ø·
            test_only = True
            for ref in references:
                if "test" not in ref["file"].lower():
                    test_only = False
                    break

            if usage_count == 0:
                classification["unused"].append(service_name)
            elif test_only and usage_count > 0:
                classification["test_only"].append(service_name)
            elif usage_count >= 5:
                classification["heavily_used"].append(service_name)
            elif usage_count >= 2:
                classification["moderately_used"].append(service_name)
            else:
                classification["lightly_used"].append(service_name)

        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        for category, services in classification.items():
            if services:
                print(f"  {category}: {len(services)} Ø®Ø¯Ù…Ø§Øª")
                for service in services[:3]:  # Ø£ÙˆÙ„ 3 ÙÙ‚Ø·
                    usage_count = service_usage[service]["usage_count"]
                    print(f"    - {service} ({usage_count} Ù…Ø±Ø§Ø¬Ø¹)")
                if len(services) > 3:
                    print(f"    ... Ùˆ{len(services) - 3} Ø£Ø®Ø±Ù‰")

        return classification

    def generate_smart_merge_recommendations(
        self, service_usage: Dict, classification: Dict
    ) -> Dict:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø¯Ù…Ø¬ Ø°ÙƒÙŠØ©"""
        print("ğŸ¯ Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ...")

        recommendations = {
            "primary_services": {},  # Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø©
            "merge_into_primary": {},  # Ù…Ø§ ÙŠÙØ¯Ù…Ø¬ ÙÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            "move_to_correct_location": {},  # Ù…Ø§ ÙŠÙÙ†Ù‚Ù„ Ù„Ù„Ù…ÙƒØ§Ù† Ø§Ù„ØµØ­ÙŠØ­
            "safe_to_delete": [],  # Ø¢Ù…Ù† Ù„Ù„Ø­Ø°Ù
            "needs_review": [],  # ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©
        }

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
        groups = defaultdict(list)
        for service_name, service_data in service_usage.items():
            group = service_data["group"]
            groups[group].append((service_name, service_data))

        for group_name, group_services in groups.items():
            print(f"\nğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø©: {group_name}")

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
            sorted_services = sorted(
                group_services, key=lambda x: x[1]["usage_count"], reverse=True
            )

            if not sorted_services:
                continue

            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Ù‹)
            primary_service_name, primary_service_data = sorted_services[0]

            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©ØŒ Ø§Ø¨Ø­Ø« Ø¹Ù† Ø¨Ø¯ÙŠÙ„
            if primary_service_data["usage_count"] == 0:
                # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø®Ø¯Ù…Ø© Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
                used_services = [s for s in sorted_services if s[1]["usage_count"] > 0]
                if used_services:
                    primary_service_name, primary_service_data = used_services[0]
                else:
                    # ÙƒÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© - Ø§Ø®ØªØ± Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯Ø©
                    pass

            recommendations["primary_services"][group_name] = {
                "service": primary_service_name,
                "usage_count": primary_service_data["usage_count"],
                "path": primary_service_data["path"],
            }

            print(
                f"  ğŸ¯ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {primary_service_name} ({primary_service_data['usage_count']} Ù…Ø±Ø§Ø¬Ø¹)"
            )

            # ØªØµÙ†ÙŠÙ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
            for service_name, service_data in sorted_services[1:]:
                if service_data["usage_count"] == 0:
                    recommendations["safe_to_delete"].append(
                        {
                            "service": service_name,
                            "group": group_name,
                            "reason": "ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹",
                        }
                    )
                    print(f"    ğŸ—‘ï¸  Ù„Ù„Ø­Ø°Ù: {service_name} (ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…)")

                elif service_data["usage_count"] <= 2:
                    recommendations["merge_into_primary"].setdefault(
                        group_name, []
                    ).append(
                        {
                            "service": service_name,
                            "usage_count": service_data["usage_count"],
                            "reason": "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ù„ÙŠÙ„ØŒ ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬Ù‡",
                        }
                    )
                    print(
                        f"    ğŸ”„ Ù„Ù„Ø¯Ù…Ø¬: {service_name} ({service_data['usage_count']} Ù…Ø±Ø§Ø¬Ø¹)"
                    )

                else:
                    recommendations["needs_review"].append(
                        {
                            "service": service_name,
                            "group": group_name,
                            "usage_count": service_data["usage_count"],
                            "reason": "Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ«ÙŠØ±ØŒ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙŠØ¯ÙˆÙŠØ©",
                        }
                    )
                    print(
                        f"    ğŸ“ Ù…Ø±Ø§Ø¬Ø¹Ø©: {service_name} ({service_data['usage_count']} Ù…Ø±Ø§Ø¬Ø¹)"
                    )

        return recommendations

    def execute_usage_based_organization(self, recommendations: Dict) -> Dict:
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        print("\nğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…...")

        results = {
            "files_deleted": 0,
            "files_merged": 0,
            "files_moved": 0,
            "primary_services_kept": 0,
            "errors": [],
        }

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        unused_dir = self.base_path / "deleted" / "unused_services"
        unused_dir.mkdir(parents=True, exist_ok=True)

        try:
            # 1. Ù†Ù‚Ù„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„Ø­Ø°Ù
            for item in recommendations["safe_to_delete"]:
                service_name = item["service"]
                group_name = item["group"]

                source_path = (
                    self.base_path
                    / "deprecated"
                    / "services"
                    / group_name
                    / f"{service_name}.py"
                )
                if source_path.exists():
                    target_path = unused_dir / f"{service_name}.py"
                    source_path.rename(target_path)
                    results["files_deleted"] += 1
                    print(f"  ğŸ—‘ï¸  Ù†Ù‚Ù„ Ù„Ù„Ø­Ø°Ù: {service_name}")

            # 2. Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…ÙƒØ§Ù†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­
            for group_name, primary_info in recommendations["primary_services"].items():
                service_name = primary_info["service"]

                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„ØµØ­ÙŠØ­ Ø­Ø³Ø¨ Clean Architecture
                target_location = self._get_clean_architecture_location(group_name)
                source_path = (
                    self.base_path
                    / "deprecated"
                    / "services"
                    / group_name
                    / f"{service_name}.py"
                )
                target_path = self.base_path / target_location / f"{service_name}.py"

                if source_path.exists():
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    source_path.rename(target_path)
                    results["primary_services_kept"] += 1
                    print(f"  âœ… Ø§Ø­ØªÙØ¸ Ø¨Ù€: {service_name} â†’ {target_location}")

            # 3. Ø¯Ù…Ø¬ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… (Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ø§Ø­Ù‚Ø©)
            for group_name, merge_list in recommendations["merge_into_primary"].items():
                for item in merge_list:
                    service_name = item["service"]
                    # TODO: Ø¯Ù…Ø¬ ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰
                    print(f"  ğŸ”„ Ø³ÙŠØªÙ… Ø¯Ù…Ø¬: {service_name} (TODO)")
                    results["files_merged"] += 1

        except Exception as e:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…: {str(e)}"
            results["errors"].append(error_msg)
            print(f"âŒ {error_msg}")

        return results

    def _get_clean_architecture_location(self, group_name: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„ØµØ­ÙŠØ­ ÙÙŠ Clean Architecture"""
        locations = {
            "ai_services": "src/application/services/ai",
            "audio_services": "src/application/services/core",
            "cache_services": "src/infrastructure/services/data",
            "monitoring_services": "src/infrastructure/services/monitoring",
        }
        return locations.get(group_name, "src/application/services/core")

    def generate_usage_analysis_report(
        self,
        service_usage: Dict,
        classification: Dict,
        recommendations: Dict,
        results: Dict,
    ) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        report = f"""
# ğŸ“Š ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù„Ø®Ø¯Ù…Ø§Øª
**Ø§Ù„ØªØ§Ø±ÙŠØ®**: {timestamp}
**Ø§Ù„Ù…Ø­Ù„Ù„**: UsagePatternAnalyzer v1.0

## ğŸ¯ Ø§Ù„Ù‡Ø¯Ù
ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ÙŠØ­ØªØ§Ø¬Ù‡Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙØ¹Ù„Ø§Ù‹ ÙˆØ§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ.

## ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

### ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø¯Ù…Ø§Øª:
- **Ù…Ø³ØªØ®Ø¯Ù…Ø© Ø¨ÙƒØ«Ø±Ø©** (5+ Ù…Ø±Ø§Ø¬Ø¹): {len(classification['heavily_used'])} Ø®Ø¯Ù…Ø§Øª
- **Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…ØªÙˆØ³Ø·** (2-4 Ù…Ø±Ø§Ø¬Ø¹): {len(classification['moderately_used'])} Ø®Ø¯Ù…Ø§Øª  
- **Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹** (1 Ù…Ø±Ø¬Ø¹): {len(classification['lightly_used'])} Ø®Ø¯Ù…Ø§Øª
- **ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©**: {len(classification['unused'])} Ø®Ø¯Ù…Ø§Øª
- **Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙ‚Ø·**: {len(classification['test_only'])} Ø®Ø¯Ù…Ø§Øª

## ğŸ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ

"""

        # Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§
        report += f"""
### âœ… Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§
"""
        for group, primary in recommendations["primary_services"].items():
            report += f"""
#### {group.replace('_', ' ').title()}
- **Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©**: `{primary['service']}`
- **Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹**: {primary['usage_count']}
- **Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯**: `{self._get_clean_architecture_location(group)}/{primary['service']}.py`
"""

        # Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
        if recommendations["safe_to_delete"]:
            report += f"""
### ğŸ—‘ï¸ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ© (ØºÙŠØ± Ù…Ø³ØªØ®Ø¯Ù…Ø©)
"""
            for item in recommendations["safe_to_delete"]:
                report += f"- `{item['service']}` ({item['reason']})\n"

        # Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©
        if recommendations["merge_into_primary"]:
            report += f"""
### ğŸ”„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ù„Ù„Ø¯Ù…Ø¬
"""
            for group, merge_list in recommendations["merge_into_primary"].items():
                report += f"""
#### {group.replace('_', ' ').title()}
"""
                for item in merge_list:
                    report += f"- `{item['service']}` ({item['usage_count']} Ù…Ø±Ø§Ø¬Ø¹) - {item['reason']}\n"

        # Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©
        if recommendations["needs_review"]:
            report += f"""
### ğŸ“ Ø®Ø¯Ù…Ø§Øª ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙŠØ¯ÙˆÙŠØ©
"""
            for item in recommendations["needs_review"]:
                report += f"- `{item['service']}` ÙÙŠ {item['group']} ({item['usage_count']} Ù…Ø±Ø§Ø¬Ø¹)\n"

        report += f"""
## ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†ÙÙŠØ°
- **Ù…Ù„ÙØ§Øª Ù…Ø­Ø°ÙˆÙØ©**: {results['files_deleted']}
- **Ø®Ø¯Ù…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§**: {results['primary_services_kept']}
- **Ù…Ù„ÙØ§Øª Ù…Ø¯Ù…ÙˆØ¬Ø©**: {results['files_merged']}
- **Ø£Ø®Ø·Ø§Ø¡**: {len(results['errors'])}

## ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©

### âœ… Ù…Ø§ ØªÙ… ØªØ­Ù‚ÙŠÙ‚Ù‡:
1. **Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙ‚Ø·** - ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙØ¹Ù„Ø§Ù‹
2. **Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©** - ØªÙˆÙÙŠØ± Ù…Ø³Ø§Ø­Ø© ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
3. **Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø­Ø³Ø¨ Clean Architecture** - ÙƒÙ„ Ø®Ø¯Ù…Ø© ÙÙŠ Ù…ÙƒØ§Ù†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­
4. **Ù‚Ø±Ø§Ø±Ø§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª** - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ

### ğŸ“‹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
1. **Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©** - ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰
2. **ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹** - Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù„Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
3. **Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„** - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ù…Ù„ ÙƒÙ„ Ø´ÙŠØ¡ Ø¨Ø¹Ø¯ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
4. **ØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©** - ÙƒØªØ§Ø¨Ø© ÙˆØ«Ø§Ø¦Ù‚ Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©

---
**ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø©**: UsagePatternAnalyzer v1.0
**Ø§Ù„ØªÙˆÙ‚ÙŠØª**: {timestamp}
"""

        return report

    def run_complete_usage_analysis(self) -> Dict:
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"""
        print("=" * 60)
        print("ğŸ“Š  USAGE PATTERN ANALYZER")
        print("ğŸ¯  ANALYZING ACTUAL PROJECT NEEDS")
        print("=" * 60)

        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        service_usage = self.analyze_service_usage_patterns()

        # ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        classification = self.classify_services_by_usage(service_usage)

        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¯Ù…Ø¬
        recommendations = self.generate_smart_merge_recommendations(
            service_usage, classification
        )

        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¸ÙŠÙ…
        results = self.execute_usage_based_organization(recommendations)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_content = self.generate_usage_analysis_report(
            service_usage, classification, recommendations, results
        )
        report_path = (
            self.base_path / "deleted" / "reports" / "USAGE_PATTERN_ANALYSIS.md"
        )
        report_path.parent.mkdir(parents=True, exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(f"\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
        print(f"ğŸ“‹ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {report_path}")
        print(f"ğŸ“Š Ø®Ø¯Ù…Ø§Øª Ù…Ø­Ø°ÙˆÙØ©: {results['files_deleted']}")
        print(f"âœ… Ø®Ø¯Ù…Ø§Øª Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§: {results['primary_services_kept']}")

        return {
            "service_usage": service_usage,
            "classification": classification,
            "recommendations": recommendations,
            "results": results,
        }


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    analyzer = UsagePatternAnalyzer()

    try:
        analysis = analyzer.run_complete_usage_analysis()
        print(f"\nâœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
