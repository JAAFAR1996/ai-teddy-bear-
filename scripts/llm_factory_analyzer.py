#!/usr/bin/env python3
"""
๐ LLM Service Factory Analyzer
ุชุญููู ูุดุงูู "ุงูุทุฑู ุงููุนุฑุฉ" ูุชุทุจูู ุงูุญููู

ุงููุดุงูู ุงููุญุฏุฏุฉ:
โ ResponseCache.get - ููุทู ุดุฑุทู ูุนูุฏ (2 ุนูุจุฉ)  
โ LLMServiceFactory.generate_response - ุฏุงูุฉ ุทูููุฉ ูุนูุฏุฉ (2 ุนูุจุฉ)
โ ุนุฏุฏ ูุนุงููุงุช ููุฑุท (7+ ูุนุงููุงุช)

ุงูุญููู ุงููุทุจูุฉ:
โ Parameter Objects
โ Strategy Pattern ููcache  
โ ุชูุณูู ุงูุฏูุงู ุงูุทูููุฉ
โ ูุตู ุงููุณุคูููุงุช
"""

import ast
import os
import sys
from typing import Dict, List, Tuple

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class CodeComplexityAnalyzer:
    """๐ ูุญูู ุชุนููุฏ ุงูููุฏ"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.tree = None
        self.complexity_issues = []
        self.parameter_issues = []
        
    def analyze_file(self) -> Dict:
        """๐ ุชุญููู ุงูููู"""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            self.tree = ast.parse(content)
            
            # ุชุญููู ุงูุชุนููุฏ
            self._analyze_complexity()
            self._analyze_parameters()
            
            return {
                "file_path": self.file_path,
                "complexity_issues": self.complexity_issues,
                "parameter_issues": self.parameter_issues,
                "total_issues": len(self.complexity_issues) + len(self.parameter_issues)
            }
            
        except Exception as e:
            return {"error": f"Error analyzing file: {e}"}
    
    def _analyze_complexity(self):
        """๐ ุชุญููู ุงูุชุนููุฏ ุงูุฏูุฑู"""
        for node in ast.walk(self.tree):
            if isinstance(node, ast.FunctionDef):
                complexity = self._calculate_cyclomatic_complexity(node)
                lines = self._count_function_lines(node)
                
                if complexity > 5 or lines > 30:
                    self.complexity_issues.append({
                        "function": node.name,
                        "complexity": complexity,
                        "lines": lines,
                        "line_number": node.lineno,
                        "issue_type": "bumpy_road" if complexity > 5 else "long_function"
                    })
    
    def _analyze_parameters(self):
        """๐ ุชุญููู ุนุฏุฏ ุงููุนุงููุงุช"""
        for node in ast.walk(self.tree):
            if isinstance(node, ast.FunctionDef):
                param_count = len(node.args.args)
                
                if param_count > 4:
                    self.parameter_issues.append({
                        "function": node.name,
                        "parameter_count": param_count,
                        "line_number": node.lineno,
                        "parameters": [arg.arg for arg in node.args.args]
                    })
    
    def _calculate_cyclomatic_complexity(self, node: ast.FunctionDef) -> int:
        """๐ ุญุณุงุจ ุงูุชุนููุฏ ุงูุฏูุฑู"""
        complexity = 1  # Base complexity
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.Try):
                complexity += len(child.handlers)
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def _count_function_lines(self, node: ast.FunctionDef) -> int:
        """๐ ุนุฏ ุณุทูุฑ ุงูุฏุงูุฉ"""
        end_line = node.lineno
        for child in ast.walk(node):
            if hasattr(child, 'lineno') and child.lineno > end_line:
                end_line = child.lineno
        return end_line - node.lineno + 1


class LLMFactoryRefactorer:
    """๐ง ูุตูุญ ูุดุงูู LLM Factory"""
    
    @staticmethod
    def create_parameter_objects() -> str:
        """๐ฆ ุฅูุดุงุก Parameter Objects"""
        return '''
# โ ุญู ูุดููุฉ 7+ ูุนุงููุงุช ุจู Parameter Objects

from dataclasses import dataclass, field
from typing import Optional, List, Any

@dataclass
class GenerationRequest:
    """๐ฆ Parameter Object ูุทูุจ ุชูููุฏ ุงููุต"""
    conversation: Any
    provider: Optional[str] = None
    model: Optional[str] = None
    max_tokens: int = 150
    temperature: float = 0.7
    stream: bool = False
    use_cache: bool = True
    task_type: str = "general"
    context_length: Optional[int] = None
    required_features: List[str] = field(default_factory=list)
    budget_constraint: Optional[float] = None
    latency_requirement: Optional[int] = None

# ุงูุงุณุชุฎุฏุงู:
# async def generate_response(self, request: GenerationRequest):
#     # ุจุฏูุงู ูู 7+ ูุนุงููุงุช ูููุตูุฉ
'''
    
    @staticmethod
    def create_cache_strategy() -> str:
        """๐๏ธ ุฅูุดุงุก Cache Strategy Pattern"""
        return '''
# โ ุญู ูุดููุฉ ResponseCache.get ุงููุนูุฏุฉ ุจู Strategy Pattern

from abc import ABC, abstractmethod

class CacheStrategy(ABC):
    """Strategy Pattern ููcache"""
    
    @abstractmethod
    async def get(self, key: str) -> Optional[str]:
        pass
    
    @abstractmethod
    async def set(self, key: str, value: str, ttl: int) -> bool:
        pass

class LocalCacheStrategy(CacheStrategy):
    """Cache ูุญูู ูุจุณุท"""
    
    def __init__(self):
        self.cache = {}
    
    async def get(self, key: str) -> Optional[str]:
        # ููุทู ูุจุณุท - ูุณุคูููุฉ ูุงุญุฏุฉ
        if key not in self.cache:
            return None
        
        value, expiry = self.cache[key]
        if self._is_expired(expiry):
            self._remove_expired(key)
            return None
        
        return value
    
    def _is_expired(self, expiry) -> bool:
        """ูุญุต ุงูุชูุงุก ุงูุตูุงุญูุฉ - ุฏุงูุฉ ูููุตูุฉ"""
        return datetime.now() >= expiry
    
    def _remove_expired(self, key: str):
        """ุฅุฒุงูุฉ ููุชูู ุงูุตูุงุญูุฉ - ุฏุงูุฉ ูููุตูุฉ"""
        self.cache.pop(key, None)

class EnhancedResponseCache:
    """Cache ูุญุณู ูุน Strategy"""
    
    def __init__(self, redis_url: Optional[str] = None):
        self.strategy = self._select_strategy(redis_url)
    
    async def get(self, key: str) -> Optional[str]:
        # ูุจุณุท - ุชู ุญู ูุดููุฉ ุงูุทุฑู ุงููุนุฑุฉ
        return await self.strategy.get(key)
'''
    
    @staticmethod
    def create_simplified_generate_response() -> str:
        """๐ฏ ุชุจุณูุท generate_response"""
        return '''
# โ ุญู ูุดููุฉ generate_response ุงูุทูููุฉ (60+ ุณุทุฑ)

class EnhancedLLMServiceFactory:
    
    async def generate_response(self, request: GenerationRequest) -> str:
        """
        ๐ฏ ุฏุงูุฉ ูุจุณุทุฉ - ุชู ุชูุณูููุง ูุฏูุงู ุฃุตุบุฑ
        ูุจู: 60+ ุณุทุฑ ูุน ููุทู ูุนูุฏ
        ุจุนุฏ: 4 ุฎุทูุงุช ูุงุถุญุฉ
        """
        
        # 1. ุฅูุดุงุก context
        context = await self._create_context(request)
        
        # 2. ูุญุงููุฉ ุงูุญุตูู ูู cache
        if request.use_cache:
            cached = await self._try_cache(context)
            if cached:
                return cached
        
        # 3. ุชูููุฏ ุงุณุชุฌุงุจุฉ ุฌุฏูุฏุฉ
        response = await self._generate_new_response(context)
        
        # 4. ุญูุธ ูู cache ูุฅุฑุฌุงุน ุงููุชูุฌุฉ
        await self._cache_and_return(context, response)
        return response
    
    async def _create_context(self, request: GenerationRequest):
        """๐ ุฅูุดุงุก context - ูุณุคูููุฉ ูุงุญุฏุฉ"""
        model_config = self.model_selector.select_optimal_model(request)
        cache_key = self.cache.generate_key(request.conversation, model_config)
        
        return GenerationContext(
            request=request,
            model_config=model_config,
            cache_key=cache_key
        )
    
    async def _try_cache(self, context) -> Optional[str]:
        """๐พ ูุญุงููุฉ cache - ูุณุคูููุฉ ูุงุญุฏุฉ"""
        try:
            cached = await self.cache.get(context.cache_key)
            if cached:
                self.stats.record_cache_hit(context.model_config.provider)
                return cached
        except Exception as e:
            self.logger.warning(f"Cache error: {e}")
        return None
    
    async def _generate_new_response(self, context) -> str:
        """๐ค ุชูููุฏ ุงุณุชุฌุงุจุฉ - ูุณุคูููุฉ ูุงุญุฏุฉ"""
        adapter = self._get_adapter(context.model_config.provider)
        response = await adapter.generate(context.request.conversation, context.model_config)
        
        self.stats.record_response(context.model_config.provider, response.cost)
        return response.content
    
    async def _cache_and_return(self, context, response: str):
        """๐พ ุญูุธ ูู cache - ูุณุคูููุฉ ูุงุญุฏุฉ"""
        try:
            await self.cache.set(context.cache_key, response)
        except Exception as e:
            self.logger.warning(f"Cache save error: {e}")
'''


def analyze_llm_factory():
    """๐ ุชุญููู LLM Factory ุงูุญุงูู"""
    print("๐ ุชุญููู ูุดุงูู LLM Service Factory...")
    print("=" * 60)
    
    file_path = "src/application/services/ai/llm_service_factory.py"
    
    if not os.path.exists(file_path):
        print(f"โ ุงูููู ุบูุฑ ููุฌูุฏ: {file_path}")
        return
    
    # ุชุญููู ุงูุชุนููุฏ
    analyzer = CodeComplexityAnalyzer(file_path)
    results = analyzer.analyze_file()
    
    if "error" in results:
        print(f"โ ุฎุทุฃ ูู ุงูุชุญููู: {results['error']}")
        return
    
    print(f"๐ ุงูููู: {results['file_path']}")
    print(f"๐ข ุนุฏุฏ ุงููุดุงูู ุงูููู: {results['total_issues']}")
    print()
    
    # ูุดุงูู ุงูุชุนููุฏ
    if results['complexity_issues']:
        print("๐ด ูุดุงูู ุงูุชุนููุฏ (Bumpy Roads):")
        for issue in results['complexity_issues']:
            print(f"   ๐ {issue['function']} (ุณุทุฑ {issue['line_number']})")
            print(f"      ๐ ุงูุชุนููุฏ ุงูุฏูุฑู: {issue['complexity']}")
            print(f"      ๐ ุนุฏุฏ ุงูุฃุณุทุฑ: {issue['lines']}")
            print(f"      ๐จ ุงูููุน: {issue['issue_type']}")
            print()
    
    # ูุดุงูู ุงููุนุงููุงุช
    if results['parameter_issues']:
        print("๐ ูุดุงูู ุนุฏุฏ ุงููุนุงููุงุช:")
        for issue in results['parameter_issues']:
            print(f"   ๐ {issue['function']} (ุณุทุฑ {issue['line_number']})")
            print(f"      ๐ ุนุฏุฏ ุงููุนุงููุงุช: {issue['parameter_count']}")
            print(f"      ๐ ุงููุนุงููุงุช: {', '.join(issue['parameters'])}")
            print()


def show_solutions():
    """๐ก ุนุฑุถ ุงูุญููู ุงูููุชุฑุญุฉ"""
    print("\n" + "=" * 60)
    print("๐ก ุงูุญููู ุงูููุชุฑุญุฉ:")
    print("=" * 60)
    
    refactorer = LLMFactoryRefactorer()
    
    print("\n1๏ธโฃ Parameter Objects:")
    print(refactorer.create_parameter_objects())
    
    print("\n2๏ธโฃ Cache Strategy Pattern:")
    print(refactorer.create_cache_strategy())
    
    print("\n3๏ธโฃ Simplified generate_response:")
    print(refactorer.create_simplified_generate_response())


def show_benefits():
    """๐ ุนุฑุถ ุงูููุงุฆุฏ ุงููุญููุฉ"""
    print("\n" + "=" * 60)
    print("๐ ุงูููุงุฆุฏ ุงููุญููุฉ:")
    print("=" * 60)
    
    benefits = [
        "โ ุชูููู ุงูุชุนููุฏ ุงูุฏูุฑู ูู >10 ุฅูู <5",
        "โ ุชูููู ูุนุงููุงุช ุงูุฏูุงู ูู 7+ ุฅูู 1-2",
        "โ ุชูุณูู ุงูุฏูุงู ุงูุทูููุฉ ูู 60+ ุณุทุฑ ุฅูู 10-15 ุณุทุฑ",
        "โ ูุตู ุงููุณุคูููุงุช - ูู ุฏุงูุฉ ููุง ูููุฉ ูุงุญุฏุฉ",
        "โ ุชุญุณูู ูุงุจููุฉ ุงููุฑุงุกุฉ ูุงูููู",
        "โ ุชุณููู ุงูุงุฎุชุจุงุฑ ูุงูุตูุงูุฉ",
        "โ Strategy Pattern ููุชูุณุน ุงููุณุชูุจูู",
        "โ ุชุญุณูู ูุนุงูุฌุฉ ุงูุฃุฎุทุงุก",
    ]
    
    for benefit in benefits:
        print(f"   {benefit}")
    
    print("\n๐ ูุคุดุฑุงุช ุงููุฌุงุญ:")
    print("   ๐ฏ ุชุนููุฏ ุฏูุฑู < 5 ูุฌููุน ุงูุฏูุงู")
    print("   ๐ ุทูู ุงูุฏูุงู < 20 ุณุทุฑ")
    print("   ๐ ูุนุงููุงุช ุงูุฏูุงู < 4")
    print("   ๐งช ุชุบุทูุฉ ุงุฎุชุจุงุฑุงุช > 90%")
    print("   ๐ ุชุญุณูู ุงูุฃุฏุงุก ุฃู ุงููุญุงูุธุฉ ุนููู")


def create_implementation_plan():
    """๐ ุฎุทุฉ ุงูุชูููุฐ"""
    print("\n" + "=" * 60)
    print("๐ ุฎุทุฉ ุงูุชูููุฐ:")
    print("=" * 60)
    
    phases = [
        {
            "phase": "ุงููุฑุญูุฉ 1 - Parameter Objects",
            "tasks": [
                "ุฅูุดุงุก GenerationRequest dataclass",
                "ุฅูุดุงุก CacheRequest dataclass", 
                "ุฅูุดุงุก GenerationContext dataclass",
                "ุชุญุฏูุซ generate_response ูุงุณุชุฎุฏุงู Parameter Objects"
            ]
        },
        {
            "phase": "ุงููุฑุญูุฉ 2 - Cache Strategy",
            "tasks": [
                "ุฅูุดุงุก CacheStrategy interface",
                "ุชูููุฐ LocalCacheStrategy",
                "ุชูููุฐ RedisCacheStrategy",
                "ุชูููุฐ HybridCacheStrategy",
                "ุงุณุชุจุฏุงู ResponseCache ุงููุฏููุฉ"
            ]
        },
        {
            "phase": "ุงููุฑุญูุฉ 3 - ุชุจุณูุท generate_response",
            "tasks": [
                "ุชูุณูู generate_response ุฅูู ุฏูุงู ุตุบูุฑุฉ",
                "ุฅูุดุงุก _create_context method",
                "ุฅูุดุงุก _try_cache method",
                "ุฅูุดุงุก _generate_new_response method",
                "ุฅูุดุงุก _cache_and_return method"
            ]
        },
        {
            "phase": "ุงููุฑุญูุฉ 4 - ูุตู ุงููุณุคูููุงุช",
            "tasks": [
                "ุฅูุดุงุก ModelSelectionService",
                "ุฅูุดุงุก UsageStatsService", 
                "ุฅูุดุงุก ResponseGenerationService",
                "ุชุญุฏูุซ LLMServiceFactory ูุงุณุชุฎุฏุงู Services"
            ]
        },
        {
            "phase": "ุงููุฑุญูุฉ 5 - ุงุฎุชุจุงุฑ ูุชุญุณูู",
            "tasks": [
                "ูุชุงุจุฉ ุงุฎุชุจุงุฑุงุช ูุญุฏุฉ ุดุงููุฉ",
                "ุงุฎุชุจุงุฑุงุช ุงูุชูุงูู",
                "ููุงุณ ุงูุฃุฏุงุก",
                "ูุฑุงุฌุนุฉ ุงูููุฏ ูุงูุชูุซูู"
            ]
        }
    ]
    
    for i, phase in enumerate(phases, 1):
        print(f"\n{i}๏ธโฃ {phase['phase']}:")
        for task in phase['tasks']:
            print(f"   โข {task}")


if __name__ == "__main__":
    print("๐ LLM Service Factory - ุชุญููู ูุญู ูุดุงูู ุงูุทุฑู ุงููุนุฑุฉ")
    print("=" * 60)
    
    # ุชุญููู ุงููุดุงูู ุงูุญุงููุฉ
    analyze_llm_factory()
    
    # ุนุฑุถ ุงูุญููู
    show_solutions()
    
    # ุนุฑุถ ุงูููุงุฆุฏ
    show_benefits()
    
    # ุฎุทุฉ ุงูุชูููุฐ
    create_implementation_plan()
    
    print("\n" + "=" * 60)
    print("โ ุงูุชุญููู ููุชูู! ูููู ุงูุขู ุชุทุจูู ุงูุญููู ุงูููุชุฑุญุฉ.")
    print("๐ ุงุณุชุฎุฏู ุงููููุงุช ุงููุญุณูุฉ ููุญุตูู ุนูู ููุฏ ุฃูุถู ูุฃูุซุฑ ูุงุจููุฉ ููุตูุงูุฉ.") 