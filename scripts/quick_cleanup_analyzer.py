#!/usr/bin/env python3
"""Ù…Ø­Ù„Ù„ Ø³Ø±ÙŠØ¹ Ù„Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªØ±ØªÙŠØ¨"""

import os
import json
import hashlib
from pathlib import Path
from collections import defaultdict
from datetime import datetime


def analyze_project():
    """ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
    print("\nğŸ§¹ Ù…Ø­Ù„Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø±ÙŠØ¹ - AI Teddy Bear")
    print("="*60)

    results = {
        "timestamp": datetime.now().isoformat(),
        "total_files": 0,
        "files_by_type": defaultdict(int),
        "empty_files": [],
        "large_files": [],
        "trash_files": [],
        "duplicates": defaultdict(list),
        "misplaced_files": []
    }

    # patterns Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ù…Ø§Ù…Ø©
    trash_patterns = ['_old.py', '_backup.py', '_temp.py', '_copy.py', '.pyc']

    # Ø¬Ù…Ø¹ ÙƒÙ„ Ù…Ù„ÙØ§Øª Python
    for root, dirs, files in os.walk('.'):
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
        dirs[:] = [d for d in dirs if d not in [
            '.git', '__pycache__', 'node_modules', '.venv', 'venv', 'backup_']]

        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                results["total_files"] += 1

                try:
                    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # Ø­Ø³Ø§Ø¨ hash
                    file_hash = hashlib.sha256(content.encode()).hexdigest()
                    results["duplicates"][file_hash].append(file_path)

                    # ÙØ­Øµ Ø§Ù„Ù…Ù„Ù
                    file_size = len(content)

                    # Ù…Ù„ÙØ§Øª ÙØ§Ø±ØºØ©
                    if file_size == 0 and '__init__.py' not in file:
                        results["empty_files"].append(file_path)
                        results["trash_files"].append(file_path)

                    # Ù…Ù„ÙØ§Øª ÙƒØ¨ÙŠØ±Ø©
                    elif file_size > 50000:  # Ø£ÙƒØ¨Ø± Ù…Ù† 50KB
                        results["large_files"].append((file_path, file_size))

                    # Ù…Ù„ÙØ§Øª Ù‚Ù…Ø§Ù…Ø©
                    if any(pattern in file for pattern in trash_patterns):
                        results["trash_files"].append(file_path)

                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹
                    if 'test' in file_path:
                        results["files_by_type"]["test"] += 1
                    elif 'service' in file_path:
                        results["files_by_type"]["service"] += 1
                    elif 'model' in file_path or 'entity' in file_path:
                        results["files_by_type"]["model"] += 1
                    elif 'config' in file_path:
                        results["files_by_type"]["config"] += 1
                    else:
                        results["files_by_type"]["other"] += 1

                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")

    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print(f"\nğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {results['total_files']}")
    print(f"Ù…Ù„ÙØ§Øª ÙØ§Ø±ØºØ©: {len(results['empty_files'])}")
    print(f"Ù…Ù„ÙØ§Øª ÙƒØ¨ÙŠØ±Ø©: {len(results['large_files'])}")
    print(f"Ù…Ù„ÙØ§Øª Ù‚Ù…Ø§Ù…Ø©: {len(set(results['trash_files']))}")

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
    exact_duplicates = []
    for file_hash, files in results["duplicates"].items():
        if len(files) > 1:
            exact_duplicates.append(files)

    print(f"Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(exact_duplicates)}")

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open('quick_cleanup_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø³Ø±ÙŠØ¹
    with open('quick_cleanup_report.md', 'w', encoding='utf-8') as f:
        f.write("# ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø±ÙŠØ¹\n\n")
        f.write(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {results['timestamp']}\n\n")

        f.write("## Ù…Ù„ÙØ§Øª Ù„Ù„Ø­Ø°Ù Ø§Ù„ÙÙˆØ±ÙŠ\n\n")
        trash_files_unique = list(set(results["trash_files"]))
        for trash_file in trash_files_unique[:20]:
            f.write(f"- `{trash_file}`\n")

        if exact_duplicates:
            f.write("\n## Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø©\n\n")
            for idx, dup_group in enumerate(exact_duplicates[:10], 1):
                f.write(f"### Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx}\n")
                for file in dup_group:
                    f.write(f"- `{file}`\n")

    print("\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: quick_cleanup_report.md")
    return results


if __name__ == "__main__":
    analyze_project()
