#!/usr/bin/env python3
"""
ğŸ” Comprehensive Project Audit Script
ÙØ­Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØ§ÙƒØªØ´Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ù„Ø«ØºØ±Ø§Øª

Lead Architect: Ø¬Ø¹ÙØ± Ø£Ø¯ÙŠØ¨ (Jaafar Adeeb)
Enterprise Grade AI Teddy Bear Project 2025
"""

import ast
import json
import logging
import os
import re
import sys
from collections import defaultdict, Counter
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class AuditIssue:
    """Ù…Ø´ÙƒÙ„Ø© ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
    severity: str  # critical, high, medium, low
    category: str  # security, quality, performance, architecture
    file_path: str
    line_number: Optional[int]
    description: str
    code_snippet: Optional[str]
    suggested_fix: Optional[str]
    rule_violated: Optional[str]

@dataclass
class FileAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯"""
    file_path: Path
    lines_count: int
    complexity_score: int
    issues: List[AuditIssue] = field(default_factory=list)
    imports: Set[str] = field(default_factory=set)
    classes: List[str] = field(default_factory=list)
    functions: List[str] = field(default_factory=list)
    dependencies: Set[str] = field(default_factory=set)

@dataclass
class ProjectAudit:
    """Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
    total_files: int
    total_issues: int
    critical_issues: int
    high_issues: int
    medium_issues: int
    low_issues: int
    file_analyses: Dict[str, FileAnalysis]
    issues_by_category: Dict[str, List[AuditIssue]]
    issues_by_severity: Dict[str, List[AuditIssue]]
    god_classes: List[str]
    circular_dependencies: List[Tuple[str, str]]
    security_risks: List[AuditIssue]
    performance_issues: List[AuditIssue]
    architecture_issues: List[AuditIssue]
    code_quality_issues: List[AuditIssue]

class ComprehensiveProjectAuditor:
    """Ù…Ø­Ù„Ù„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.audit_results = ProjectAudit(
            total_files=0,
            total_issues=0,
            critical_issues=0,
            high_issues=0,
            medium_issues=0,
            low_issues=0,
            file_analyses={},
            issues_by_category=defaultdict(list),
            issues_by_severity=defaultdict(list),
            god_classes=[],
            circular_dependencies=[],
            security_risks=[],
            performance_issues=[],
            architecture_issues=[],
            code_quality_issues=[]
        )
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        self.patterns = {
            'security': {
                'hardcoded_secrets': [
                    r'(password|secret|key|token|api_key)\s*=\s*["\'][^"\']+["\']',
                    r'os\.getenv\(["\'](password|secret|key|token|api_key)["\']\)',
                ],
                'dangerous_functions': [
                    r'eval\s*\(',
                    r'exec\s*\(',
                    r'pickle\.loads\s*\(',
                    r'subprocess\.call.*shell\s*=\s*True',
                ],
                'sql_injection': [
                    r'execute\s*\(\s*f["\'][^"\']*\{[^}]*\}',
                    r'execute\s*\(\s*["\'][^"\']*\+',
                ]
            },
            'quality': {
                'broad_exceptions': [
                    r'except\s*:',
                    r'except\s+Exception\s*:',
                ],
                'print_statements': [
                    r'print\s*\(',
                ],
                'todos': [
                    r'#\s*(TODO|FIXME|XXX|HACK)',
                ],
                'wildcard_imports': [
                    r'from\s+[\w.]+\s+import\s+\*',
                ]
            },
            'performance': {
                'large_files': 500,  # Ø£ÙƒØ«Ø± Ù…Ù† 500 Ø³Ø·Ø±
                'complex_functions': 10,  # ØªØ¹Ù‚ÙŠØ¯ Ø¯ÙˆØ±ÙŠ Ø£ÙƒØ¨Ø± Ù…Ù† 10
                'deep_nesting': 5,  # ØªØ¯Ø§Ø®Ù„ Ø£Ø¹Ù…Ù‚ Ù…Ù† 5 Ù…Ø³ØªÙˆÙŠØ§Øª
            }
        }

    def run_comprehensive_audit(self) -> ProjectAudit:
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„"""
        logger.info("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹...")
        logger.info(f"ğŸ“ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹: {self.project_root}")
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python
        python_files = self._find_python_files()
        self.audit_results.total_files = len(python_files)
        logger.info(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(python_files)} Ù…Ù„Ù Python")
        
        # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ù„Ù
        for file_path in python_files:
            try:
                analysis = self._analyze_file(file_path)
                self.audit_results.file_analyses[str(file_path)] = analysis
                
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
                for issue in analysis.issues:
                    self._categorize_issue(issue)
                    
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {file_path}: {e}")
        
        # ÙƒØ´Ù God Classes
        self._detect_god_classes()
        
        # ÙƒØ´Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©
        self._detect_circular_dependencies()
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self._calculate_statistics()
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        self._print_audit_report()
        
        return self.audit_results

    def _find_python_files(self) -> List[Path]:
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Python ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        python_files = []
        exclude_patterns = [
            '__pycache__', '.git', 'venv', '.venv', 'env', '.env',
            'node_modules', 'build', 'dist', '.pytest_cache'
        ]
        
        for file_path in self.project_root.rglob('*.py'):
            if not any(pattern in str(file_path) for pattern in exclude_patterns):
                python_files.append(file_path)
        
        return python_files

    def _analyze_file(self, file_path: Path) -> FileAnalysis:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯"""
        logger.debug(f"ğŸ” ØªØ­Ù„ÙŠÙ„ {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.splitlines()
        except Exception as e:
            logger.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
            return FileAnalysis(
                file_path=file_path,
                lines_count=0,
                complexity_score=0
            )
        
        analysis = FileAnalysis(
            file_path=file_path,
            lines_count=len(lines),
            complexity_score=0
        )
        
        # ØªØ­Ù„ÙŠÙ„ AST
        try:
            tree = ast.parse(content)
            ast_analyzer = ASTAnalyzer()
            ast_analyzer.visit(tree)
            
            analysis.complexity_score = ast_analyzer.complexity_score
            analysis.classes = ast_analyzer.classes
            analysis.functions = ast_analyzer.functions
            analysis.imports = ast_analyzer.imports
            analysis.dependencies = ast_analyzer.dependencies
            
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ AST Ù„Ù€ {file_path}: {e}")
        
        # ÙØ­Øµ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠØ©
        analysis.issues.extend(self._check_security_issues(file_path, content, lines))
        
        # ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©
        analysis.issues.extend(self._check_quality_issues(file_path, content, lines))
        
        # ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
        analysis.issues.extend(self._check_performance_issues(file_path, content, lines, analysis))
        
        # ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©
        analysis.issues.extend(self._check_architecture_issues(file_path, content, lines, analysis))
        
        return analysis

    def _check_security_issues(self, file_path: Path, content: str, lines: List[str]) -> List[AuditIssue]:
        """ÙØ­Øµ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠØ©"""
        issues = []
        
        for pattern_name, patterns in self.patterns['security'].items():
            for pattern in patterns:
                for match in re.finditer(pattern, content, re.IGNORECASE):
                    line_number = content[:match.start()].count('\n') + 1
                    line_content = lines[line_number - 1] if line_number <= len(lines) else ""
                    
                    issue = AuditIssue(
                        severity="critical" if pattern_name == "dangerous_functions" else "high",
                        category="security",
                        file_path=str(file_path),
                        line_number=line_number,
                        description=f"Ù…Ø´ÙƒÙ„Ø© Ø£Ù…Ù†ÙŠØ©: {pattern_name}",
                        code_snippet=line_content.strip(),
                        suggested_fix=self._get_security_fix(pattern_name, match.group()),
                        rule_violated=f"SECURITY_{pattern_name.upper()}"
                    )
                    issues.append(issue)
        
        return issues

    def _check_quality_issues(self, file_path: Path, content: str, lines: List[str]) -> List[AuditIssue]:
        """ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¬ÙˆØ¯Ø©"""
        issues = []
        
        for pattern_name, patterns in self.patterns['quality'].items():
            for pattern in patterns:
                for match in re.finditer(pattern, content, re.IGNORECASE):
                    line_number = content[:match.start()].count('\n') + 1
                    line_content = lines[line_number - 1] if line_number <= len(lines) else ""
                    
                    severity = "high" if pattern_name == "broad_exceptions" else "medium"
                    
                    issue = AuditIssue(
                        severity=severity,
                        category="quality",
                        file_path=str(file_path),
                        line_number=line_number,
                        description=f"Ù…Ø´ÙƒÙ„Ø© Ø¬ÙˆØ¯Ø©: {pattern_name}",
                        code_snippet=line_content.strip(),
                        suggested_fix=self._get_quality_fix(pattern_name, match.group()),
                        rule_violated=f"QUALITY_{pattern_name.upper()}"
                    )
                    issues.append(issue)
        
        return issues

    def _check_performance_issues(self, file_path: Path, content: str, lines: List[str], analysis: FileAnalysis) -> List[AuditIssue]:
        """ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        issues = []
        
        # Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹
        if analysis.lines_count > self.patterns['performance']['large_files']:
            issues.append(AuditIssue(
                severity="medium",
                category="performance",
                file_path=str(file_path),
                line_number=None,
                description=f"Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹: {analysis.lines_count} Ø³Ø·Ø±",
                code_snippet=None,
                suggested_fix="Ù‚Ø³Ù‘Ù… Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø£ØµØºØ± Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… EXTRACT CLASS pattern",
                rule_violated="PERFORMANCE_LARGE_FILE"
            ))
        
        # ØªØ¹Ù‚ÙŠØ¯ Ø¯ÙˆØ±ÙŠ Ø¹Ø§Ù„ÙŠ
        if analysis.complexity_score > self.patterns['performance']['complex_functions']:
            issues.append(AuditIssue(
                severity="medium",
                category="performance",
                file_path=str(file_path),
                line_number=None,
                description=f"ØªØ¹Ù‚ÙŠØ¯ Ø¯ÙˆØ±ÙŠ Ø¹Ø§Ù„ÙŠ: {analysis.complexity_score}",
                code_snippet=None,
                suggested_fix="Ø§Ø³ØªØ®Ø¯Ù… EXTRACT FUNCTION pattern Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯",
                rule_violated="PERFORMANCE_HIGH_COMPLEXITY"
            ))
        
        return issues

    def _check_architecture_issues(self, file_path: Path, content: str, lines: List[str], analysis: FileAnalysis) -> List[AuditIssue]:
        """ÙØ­Øµ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©"""
        issues = []
        
        # God Class detection
        if (analysis.lines_count > 300 and 
            len(analysis.classes) > 3 and 
            analysis.complexity_score > 15):
            issues.append(AuditIssue(
                severity="high",
                category="architecture",
                file_path=str(file_path),
                line_number=None,
                description="God Class Ù…Ø­ØªÙ…Ù„",
                code_snippet=None,
                suggested_fix="Ù‚Ø³Ù‘Ù… Ø§Ù„ÙƒÙ„Ø§Ø³ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ø³Ø§Øª Ø£ØµØºØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DDD patterns",
                rule_violated="ARCHITECTURE_GOD_CLASS"
            ))
        
        # Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
        if len(analysis.imports) > 20:
            issues.append(AuditIssue(
                severity="medium",
                category="architecture",
                file_path=str(file_path),
                line_number=None,
                description=f"ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª: {len(analysis.imports)}",
                code_snippet=None,
                suggested_fix="Ù‚Ù„Ù‘Ù„ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… facade pattern",
                rule_violated="ARCHITECTURE_TOO_MANY_IMPORTS"
            ))
        
        return issues

    def _detect_god_classes(self):
        """ÙƒØ´Ù God Classes"""
        for file_path, analysis in self.audit_results.file_analyses.items():
            if (analysis.lines_count > 500 or 
                (analysis.lines_count > 300 and len(analysis.classes) > 5) or
                analysis.complexity_score > 20):
                self.audit_results.god_classes.append(file_path)

    def _detect_circular_dependencies(self):
        """ÙƒØ´Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©"""
        # Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
        dependency_graph = {}
        for file_path, analysis in self.audit_results.file_analyses.items():
            dependency_graph[file_path] = analysis.dependencies
        
        # ÙƒØ´Ù Ø§Ù„Ø¯ÙˆØ±Ø§Øª
        visited = set()
        rec_stack = set()
        
        def dfs(node: str, path: List[str]):
            if node in rec_stack:
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                if len(cycle) == 2:  # Ø£Ø¨Ø³Ø· Ø¯ÙˆØ±Ø©
                    self.audit_results.circular_dependencies.append((cycle[0], cycle[1]))
                return
            
            if node in visited:
                return
            
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            for neighbor in dependency_graph.get(node, []):
                dfs(neighbor, path.copy())
            
            rec_stack.remove(node)
        
        for node in dependency_graph:
            if node not in visited:
                dfs(node, [])

    def _categorize_issue(self, issue: AuditIssue):
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©"""
        self.audit_results.issues_by_category[issue.category].append(issue)
        self.audit_results.issues_by_severity[issue.severity].append(issue)
        
        if issue.category == "security":
            self.audit_results.security_risks.append(issue)
        elif issue.category == "performance":
            self.audit_results.performance_issues.append(issue)
        elif issue.category == "architecture":
            self.audit_results.architecture_issues.append(issue)
        else:
            self.audit_results.code_quality_issues.append(issue)

    def _calculate_statistics(self):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        self.audit_results.critical_issues = len(self.audit_results.issues_by_severity.get("critical", []))
        self.audit_results.high_issues = len(self.audit_results.issues_by_severity.get("high", []))
        self.audit_results.medium_issues = len(self.audit_results.issues_by_severity.get("medium", []))
        self.audit_results.low_issues = len(self.audit_results.issues_by_severity.get("low", []))
        self.audit_results.total_issues = (
            self.audit_results.critical_issues +
            self.audit_results.high_issues +
            self.audit_results.medium_issues +
            self.audit_results.low_issues
        )

    def _get_security_fix(self, pattern_name: str, matched_code: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥ØµÙ„Ø§Ø­ Ø£Ù…Ù†ÙŠ"""
        fixes = {
            'hardcoded_secrets': "Ø§Ø³ØªØ®Ø¯Ù… secrets manager Ø£Ùˆ environment variables",
            'dangerous_functions': "Ø§Ø³ØªØ®Ø¯Ù… safe_expression_parser Ø£Ùˆ ast.literal_eval",
            'sql_injection': "Ø§Ø³ØªØ®Ø¯Ù… parameterized queries"
        }
        return fixes.get(pattern_name, "Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¯ÙˆÙŠØ§Ù‹")

    def _get_quality_fix(self, pattern_name: str, matched_code: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥ØµÙ„Ø§Ø­ Ø¬ÙˆØ¯Ø©"""
        fixes = {
            'broad_exceptions': "Ø§Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª Ù…Ø­Ø¯Ø¯Ø©",
            'print_statements': "Ø§Ø³ØªØ®Ø¯Ù… logging Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† print",
            'todos': "Ø£ÙƒÙ…Ù„ Ø§Ù„ØªÙ†ÙÙŠØ° Ø£Ùˆ Ø£Ù†Ø´Ø¦ ticket",
            'wildcard_imports': "Ø§Ø³ØªØ®Ø¯Ù… Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø­Ø¯Ø¯Ø©"
        }
        return fixes.get(pattern_name, "Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ¯ÙˆÙŠØ§Ù‹")

    def _print_audit_report(self):
        """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ­Øµ"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ” ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹")
        logger.info("="*80)
        
        logger.info(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©:")
        logger.info(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {self.audit_results.total_files}")
        logger.info(f"   âš ï¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„: {self.audit_results.total_issues}")
        logger.info(f"   ğŸš¨ Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø©: {self.audit_results.critical_issues}")
        logger.info(f"   ğŸ”´ Ù…Ø´Ø§ÙƒÙ„ Ø¹Ø§Ù„ÙŠØ©: {self.audit_results.high_issues}")
        logger.info(f"   ğŸŸ¡ Ù…Ø´Ø§ÙƒÙ„ Ù…ØªÙˆØ³Ø·Ø©: {self.audit_results.medium_issues}")
        logger.info(f"   ğŸŸ¢ Ù…Ø´Ø§ÙƒÙ„ Ù…Ù†Ø®ÙØ¶Ø©: {self.audit_results.low_issues}")
        
        logger.info(f"\nğŸ—ï¸ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©:")
        logger.info(f"   ğŸ›ï¸ God Classes: {len(self.audit_results.god_classes)}")
        logger.info(f"   ğŸ”„ ØªØ¨Ø¹ÙŠØ§Øª Ø¯Ø§Ø¦Ø±ÙŠØ©: {len(self.audit_results.circular_dependencies)}")
        
        logger.info(f"\nğŸ” Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§Ù†:")
        logger.info(f"   ğŸš¨ Ù…Ø®Ø§Ø·Ø± Ø£Ù…Ù†ÙŠØ©: {len(self.audit_results.security_risks)}")
        
        logger.info(f"\nâš¡ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡:")
        logger.info(f"   ğŸŒ Ù…Ø´Ø§ÙƒÙ„ Ø£Ø¯Ø§Ø¡: {len(self.audit_results.performance_issues)}")
        
        logger.info(f"\nğŸ“ Ù…Ø´Ø§ÙƒÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯:")
        logger.info(f"   âœï¸ Ù…Ø´Ø§ÙƒÙ„ Ø¬ÙˆØ¯Ø©: {len(self.audit_results.code_quality_issues)}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©
        if self.audit_results.critical_issues > 0:
            logger.info(f"\nğŸš¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©:")
            for issue in self.audit_results.issues_by_severity.get("critical", [])[:5]:
                logger.info(f"   ğŸ“„ {issue.file_path}:{issue.line_number} - {issue.description}")
        
        # Ø·Ø¨Ø§Ø¹Ø© God Classes
        if self.audit_results.god_classes:
            logger.info(f"\nğŸ›ï¸ God Classes Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
            for god_class in self.audit_results.god_classes[:5]:
                logger.info(f"   ğŸ“„ {god_class}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©
        if self.audit_results.circular_dependencies:
            logger.info(f"\nğŸ”„ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©:")
            for dep1, dep2 in self.audit_results.circular_dependencies[:5]:
                logger.info(f"   ğŸ“„ {dep1} â†” {dep2}")

    def save_audit_report(self, output_file: str = "audit_report.json"):
        """Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ­Øµ Ø¥Ù„Ù‰ Ù…Ù„Ù"""
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "statistics": {
                "total_files": self.audit_results.total_files,
                "total_issues": self.audit_results.total_issues,
                "critical_issues": self.audit_results.critical_issues,
                "high_issues": self.audit_results.high_issues,
                "medium_issues": self.audit_results.medium_issues,
                "low_issues": self.audit_results.low_issues,
            },
            "god_classes": self.audit_results.god_classes,
            "circular_dependencies": [
                {"file1": dep1, "file2": dep2} 
                for dep1, dep2 in self.audit_results.circular_dependencies
            ],
            "issues_by_category": {
                category: [
                    {
                        "severity": issue.severity,
                        "file_path": issue.file_path,
                        "line_number": issue.line_number,
                        "description": issue.description,
                        "suggested_fix": issue.suggested_fix,
                        "rule_violated": issue.rule_violated
                    }
                    for issue in issues
                ]
                for category, issues in self.audit_results.issues_by_category.items()
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {output_file}")


class ASTAnalyzer(ast.NodeVisitor):
    """Ù…Ø­Ù„Ù„ AST Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙˆØ§Ù„ØªØ¨Ø¹ÙŠØ§Øª"""
    
    def __init__(self):
        self.complexity_score = 0
        self.classes = []
        self.functions = []
        self.imports = set()
        self.dependencies = set()
    
    def visit_ClassDef(self, node):
        self.complexity_score += 2
        self.classes.append(node.name)
        self.generic_visit(node)
    
    def visit_FunctionDef(self, node):
        self.complexity_score += 1
        self.functions.append(node.name)
        
        # Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¯Ø§Ù„Ø©
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.ExceptHandler)):
                self.complexity_score += 1
        
        self.generic_visit(node)
    
    def visit_Import(self, node):
        for alias in node.names:
            self.imports.add(alias.name)
            self.dependencies.add(alias.name)
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node):
        if node.module:
            self.imports.add(node.module)
            self.dependencies.add(node.module)
        self.generic_visit(node)


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    logger.info("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear")
    logger.info("Lead Architect: Ø¬Ø¹ÙØ± Ø£Ø¯ÙŠØ¨ (Jaafar Adeeb)")
    logger.info("="*60)
    
    auditor = ComprehensiveProjectAuditor()
    audit_results = auditor.run_comprehensive_audit()
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    auditor.save_audit_report()
    
    # ØªÙ‚ÙŠÙŠÙ… Ø¹Ø§Ù…
    if audit_results.critical_issues > 0:
        logger.error("âŒ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´Ø§ÙƒÙ„ Ø­Ø±Ø¬Ø© ØªØ­ØªØ§Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙˆØ±ÙŠØ©!")
        sys.exit(1)
    elif audit_results.high_issues > 10:
        logger.warning("âš ï¸ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø´Ø§ÙƒÙ„ Ø¹Ø§Ù„ÙŠØ© ØªØ­ØªØ§Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø±ÙŠØ¨Ø©!")
    else:
        logger.info("âœ… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙÙŠ Ø­Ø§Ù„Ø© Ø¬ÙŠØ¯Ø©!")


if __name__ == "__main__":
    main() 