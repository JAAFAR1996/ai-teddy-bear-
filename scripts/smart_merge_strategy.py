#!/usr/bin/env python3
"""
Smart Merge Strategy
Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
"""

import os
import shutil
from pathlib import Path
from typing import Dict, List, Set
from datetime import datetime

class SmartMergeStrategy:
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.merge_plan = {
            "ai_services": {
                "target_file": "src/application/services/ai/unified_ai_service.py",
                "files_to_merge": [
                    "deprecated/services/ai_services/ai_service.py",
                    "deprecated/services/ai_services/llm_service.py", 
                    "deprecated/services/ai_services/llm_service_factory.py",
                    "deprecated/services/ai_services/main_service.py"
                ],
                "special_files": {
                    "deprecated/services/ai_services/edge_ai_integration_service.py": "src/adapters/edge/",
                    "deprecated/services/ai_services/child_domain_service.py": "src/domain/services/",
                    "deprecated/services/ai_services/email_service.py": "src/application/services/communication/",
                    "deprecated/services/ai_services/test_ai_service_integration.py": "tests/integration/"
                }
            },
            "audio_services": {
                "target_file": "src/application/services/core/unified_audio_service.py",
                "files_to_merge": [
                    "deprecated/services/audio_services/voice_service.py",
                    "deprecated/services/audio_services/voice_interaction_service.py",
                    "deprecated/services/audio_services/synthesis_service.py",
                    "deprecated/services/audio_services/transcription_service.py"
                ],
                "special_files": {
                    "deprecated/services/audio_services/azure_speech_to_text_service.py": "src/infrastructure/services/external/",
                    "deprecated/services/audio_services/speech_to_text_service.py": "src/infrastructure/services/external/",
                    "deprecated/services/audio_services/audio_service.py": "src/presentation/services/",
                    "deprecated/services/audio_services/test_voice_service.py": "tests/unit/"
                }
            },
            "cache_services": {
                "target_file": "src/infrastructure/services/data/unified_cache_service.py",
                "files_to_merge": [
                    "deprecated/services/cache_services/cache_service.py",
                    "deprecated/services/cache_services/simple_cache_service.py"
                ]
            },
            "monitoring_services": {
                "target_file": "src/infrastructure/services/monitoring/unified_monitoring_service.py",
                "files_to_merge": [
                    "deprecated/services/monitoring_services/issue_tracker_service.py",
                    "deprecated/services/monitoring_services/rate_monitor_service.py",
                    "deprecated/services/monitoring_services/simple_health_service.py"
                ]
            }
        }

    def analyze_file_content(self, file_path: Path) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù ÙˆØ§Ù„ÙƒÙ„Ø§Ø³Ø§Øª"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ÙˆØ§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            classes = []
            functions = []
            imports = []
            
            lines = content.split('\n')
            for line in lines:
                line = line.strip()
                if line.startswith('class '):
                    classes.append(line)
                elif line.startswith('def '):
                    functions.append(line)
                elif line.startswith('from ') or line.startswith('import '):
                    imports.append(line)
            
            return {
                "file_path": str(file_path),
                "content": content,
                "classes": classes,
                "functions": functions,
                "imports": imports,
                "size": len(content)
            }
        
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ {file_path}: {e}")
            return {}

    def create_unified_service(self, service_group: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Ù…ÙˆØ­Ø¯Ø© Ù…Ù† Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª"""
        group_config = self.merge_plan[service_group]
        files_to_merge = group_config["files_to_merge"]
        target_file = group_config["target_file"]
        
        print(f"ğŸ”„ Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Ù…ÙˆØ­Ø¯Ø©: {target_file}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        analyzed_files = []
        for file_path_str in files_to_merge:
            file_path = self.base_path / file_path_str
            if file_path.exists():
                analysis = self.analyze_file_content(file_path)
                if analysis:
                    analyzed_files.append(analysis)
        
        if not analyzed_files:
            return ""
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ø¯
        unified_content = self._generate_unified_content(service_group, analyzed_files)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ø¯
        target_path = self.base_path / target_file
        target_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write(unified_content)
        
        print(f"  âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: {target_file}")
        return unified_content

    def _generate_unified_content(self, service_group: str, analyzed_files: List[Dict]) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ù…ÙˆØ­Ø¯ Ù…Ù† Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        all_imports = set()
        all_classes = []
        all_functions = []
        
        for file_data in analyzed_files:
            all_imports.update(file_data.get("imports", []))
            all_classes.extend(file_data.get("classes", []))
            all_functions.extend(file_data.get("functions", []))
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„ÙƒÙ„Ø§Ø³ Ø§Ù„Ù…ÙˆØ­Ø¯
        service_name = service_group.replace('_', ' ').title().replace(' ', '')
        unified_class_name = f"Unified{service_name.replace('Services', 'Service')}"
        
        content = f'''#!/usr/bin/env python3
"""
{unified_class_name}
Ø®Ø¯Ù…Ø© Ù…ÙˆØ­Ø¯Ø© ØªÙ… Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ù† Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ù…Ù†ÙØµÙ„Ø©
ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {timestamp}
"""

{chr(10).join(sorted(all_imports))}
from typing import Dict, List, Optional, Any
from abc import ABC, abstractmethod
import logging

logger = logging.getLogger(__name__)

class {unified_class_name}:
    """
    Ø®Ø¯Ù…Ø© Ù…ÙˆØ­Ø¯Ø© ØªØ¬Ù…Ø¹ ÙˆØ¸Ø§Ø¦Ù Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù†:
    {chr(10).join(f"    - {file_data['file_path']}" for file_data in analyzed_files)}
    """
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        self.logger = logging.getLogger(self.__class__.__name__)
        self._initialize_components()
    
    def _initialize_components(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©"""
        # TODO: ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©
        pass

'''
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©
        content += f'''
    # ==========================================
    # Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    # ==========================================
'''
        
        for i, file_data in enumerate(analyzed_files):
            file_name = Path(file_data['file_path']).name
            content += f'''
    # ----- Ù…Ù† {file_name} -----
    
'''
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¯ÙˆØ§Ù„ (Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„ØªÙˆØ§ÙÙ‚)
            for func in file_data.get("functions", []):
                if not func.startswith("def __"):  # ØªØ¬Ù†Ø¨ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø®Ø§ØµØ©
                    content += f"    {func}\n"
                    content += f"        \"\"\"Ø¯Ø§Ù„Ø© Ù…Ø¯Ù…ÙˆØ¬Ø© Ù…Ù† {file_name}\"\"\"\n"
                    content += f"        # TODO: ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù† {file_name}\n"
                    content += f"        pass\n\n"
        
        content += f'''
    # ==========================================
    # Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ©
    # ==========================================
    
    def get_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        return {{
            "service_name": "{unified_class_name}",
            "status": "active",
            "components": self._get_active_components(),
            "merged_from": [
                {chr(10).join(f'                "{Path(file_data["file_path"]).name}",' for file_data in analyzed_files)}
            ]
        }}
    
    def _get_active_components(self) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©"""
        # TODO: ØªÙ†ÙÙŠØ° Ù…Ù†Ø·Ù‚ ÙØ­Øµ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        return []

# ==========================================
# Factory Pattern Ù„Ù„Ø¥Ù†Ø´Ø§Ø¡
# ==========================================

class {unified_class_name}Factory:
    """Ù…ØµÙ†Ø¹ Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© {unified_class_name}"""
    
    @staticmethod
    def create() -> {unified_class_name}:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        return {unified_class_name}()
    
    @staticmethod
    def create_with_config(config: Dict[str, Any]) -> {unified_class_name}:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ø¹ ØªÙƒÙˆÙŠÙ† Ù…Ø®ØµØµ"""
        service = {unified_class_name}()
        # TODO: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙˆÙŠÙ†
        return service

# ==========================================
# Singleton Pattern (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
# ==========================================

_instance = None

def get_{service_group}_instance() -> {unified_class_name}:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«ÙŠÙ„ ÙˆØ­ÙŠØ¯ Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø©"""
    global _instance
    if _instance is None:
        _instance = {unified_class_name}Factory.create()
    return _instance
'''
        
        return content

    def handle_special_files(self, service_group: str) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§ØµØ© (ØºÙŠØ± Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©)"""
        group_config = self.merge_plan[service_group]
        special_files = group_config.get("special_files", {})
        
        results = {"moved_files": 0, "errors": []}
        
        for source_file, target_dir in special_files.items():
            try:
                source_path = self.base_path / source_file
                target_path = self.base_path / target_dir
                
                if source_path.exists():
                    target_path.mkdir(parents=True, exist_ok=True)
                    target_file = target_path / source_path.name
                    
                    shutil.move(str(source_path), str(target_file))
                    results["moved_files"] += 1
                    print(f"  ğŸ“ Ù†Ù‚Ù„: {source_path.name} â†’ {target_dir}")
            
            except Exception as e:
                error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ù†Ù‚Ù„ {source_file}: {str(e)}"
                results["errors"].append(error_msg)
                print(f"  âŒ {error_msg}")
        
        return results

    def generate_merge_report(self, results: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ù…Ø¬"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report = f"""
# ğŸ”„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø®Ø¯Ù…Ø§Øª
**Ø§Ù„ØªØ§Ø±ÙŠØ®**: {timestamp}
**Ø§Ù„Ø£Ø¯Ø§Ø©**: SmartMergeStrategy v1.0

## ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
- **Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©**: {len([k for k, v in results.items() if v.get('unified_created')])}
- **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„Ø©**: {sum(v.get('moved_files', 0) for v in results.values())}
- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡**: {sum(len(v.get('errors', [])) for v in results.values())}

## ğŸ—ï¸ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø© Ø§Ù„Ù…Ù†Ø´Ø£Ø©

"""
        
        for service_group, result in results.items():
            if result.get('unified_created'):
                report += f"""
### {service_group.replace('_', ' ').title()}
- **Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ­Ø¯**: `{self.merge_plan[service_group]['target_file']}`
- **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©**: {len(self.merge_plan[service_group]['files_to_merge'])}
- **Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„Ø©**: {result.get('moved_files', 0)}
"""
        
        report += f"""
## ğŸ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

### 1. Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
- ÙØ­Øµ ÙƒÙ„ Ù…Ù„Ù Ù…ÙˆØ­Ø¯ ÙˆØªÙ†ÙÙŠØ° Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¤Ù‚ØªØ©
- Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙØ¹Ù„ÙŠ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
- Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ

### 2. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹
```bash
# Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø©
find src/ -name "*.py" -exec grep -l "from.*services" {{}} \\;
```

### 3. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
- Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
- Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬Ø©

### 4. Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
- Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙƒØ±Ø±
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
- ØªÙˆØ«ÙŠÙ‚ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

---
**ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø©**: SmartMergeStrategy v1.0
**Ø§Ù„ØªÙˆÙ‚ÙŠØª**: {timestamp}
"""
        
        return report

    def execute_smart_merge(self) -> Dict:
        """ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„ÙƒØ§Ù…Ù„"""
        print("=" * 60)
        print("ğŸ”„  SMART MERGE STRATEGY")
        print("ğŸ¯  MERGING UNIQUE FILES INTELLIGENTLY")
        print("=" * 60)
        
        results = {}
        
        for service_group in self.merge_plan.keys():
            print(f"\nğŸ“‹ Ù…Ø¹Ø§Ù„Ø¬Ø©: {service_group}")
            print("-" * 40)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
            unified_content = self.create_unified_service(service_group)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§ØµØ©
            special_results = self.handle_special_files(service_group)
            
            results[service_group] = {
                "unified_created": bool(unified_content),
                "unified_size": len(unified_content),
                "moved_files": special_results["moved_files"],
                "errors": special_results["errors"]
            }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_content = self.generate_merge_report(results)
        report_path = self.base_path / "deleted" / "reports" / "SMART_MERGE_REPORT.md"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ!")
        print(f"ğŸ“‹ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {report_path}")
        
        return results

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    merger = SmartMergeStrategy()
    
    try:
        results = merger.execute_smart_merge()
        print(f"\nâœ… ØªÙ… Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¯Ù…Ø¬: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 