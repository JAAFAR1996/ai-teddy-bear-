import json
import os
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple
import ast

class DeepAnalyzer:
    """ูุญูู ุนููู ููุดุฑูุน AI Teddy Bear"""
    
    def __init__(self, analysis_file: str = "project_analysis.json"):
        # ุฅุฐุง ููุง ูู ูุฌูุฏ scriptsุ ุงุณุชุฎุฏู ุงูููู ุงููุญูู
        if not os.path.exists(analysis_file) and os.path.exists(f"scripts/{analysis_file}"):
            analysis_file = f"scripts/{analysis_file}"
        elif os.path.exists(f"../{analysis_file}"):
            analysis_file = f"../{analysis_file}"
            
        with open(analysis_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
    
    def analyze_all(self):
        """ุชุดุบูู ุฌููุน ุงูุชุญูููุงุช"""
        print("๐ ุชุญููู ุนููู ููุดุฑูุน AI Teddy Bear\n")
        
        print("="*60)
        self.analyze_duplicates()
        
        print("\n" + "="*60)
        self.analyze_large_files()
        
        print("\n" + "="*60)
        self.analyze_issues()
        
        print("\n" + "="*60)
        self.analyze_structure_problems()
        
        print("\n" + "="*60)
        self.analyze_dependencies()
        
        print("\n" + "="*60)
        self.generate_cleanup_recommendations()
    
    def analyze_duplicates(self):
        """ุชุญููู ุงููููุงุช ุงูููุฑุฑุฉ"""
        print("๐ ุชุญููู ุงููููุงุช ุงูููุฑุฑุฉ")
        print("-"*40)
        
        duplicates = self.data.get('duplicate_candidates', [])
        
        if not duplicates:
            print("โ ูุง ุชูุฌุฏ ูููุงุช ููุฑุฑุฉ!")
            return
        
        # ุชุตููู ุงูุชูุฑุงุฑุงุช
        exact_duplicates = [d for d in duplicates if d['type'] == 'exact']
        functional_duplicates = [d for d in duplicates if d['type'] == 'functional']
        
        print(f"\n๐ ุฅุญุตุงุฆูุงุช ุงูุชูุฑุงุฑ:")
        print(f"  โข ุชูุฑุงุฑุงุช ูุงููุฉ: {len(exact_duplicates)} ูุฌููุนุฉ")
        print(f"  โข ุชูุฑุงุฑุงุช ูุธูููุฉ: {len(functional_duplicates)} ูุฌููุนุฉ")
        
        # ุนุฑุถ ุงูุชูุฑุงุฑุงุช ุงููุงููุฉ
        if exact_duplicates:
            print(f"\n๐ด ุงูุชูุฑุงุฑุงุช ุงููุงููุฉ (ููุณ ุงููุญุชูู ุชูุงูุงู):")
            for i, dup in enumerate(exact_duplicates[:10], 1):
                print(f"\n  {i}. ูุฌููุนุฉ (Hash: {dup['hash'][:8]}...):")
                for file in dup['files']:
                    print(f"     - {file}")
                    
                # ุงูุชุฑุงุญ ุฃู ููู ูุญุชูุธ ุจู
                best_file = self._suggest_best_duplicate(dup['files'])
                print(f"     โจ ุงูุชุฑุงุญ: ุงุญุชูุธ ุจู {best_file}")
        
        # ุนุฑุถ ุงูุชูุฑุงุฑุงุช ุงููุธูููุฉ
        if functional_duplicates:
            print(f"\n๐ก ุงูุชูุฑุงุฑุงุช ุงููุธูููุฉ (ููุณ ุงูุฏูุงู):")
            for i, dup in enumerate(functional_duplicates[:5], 1):
                print(f"\n  {i}. ุงูุฏุงูุฉ: {dup['signature']}")
                for file in dup['files']:
                    print(f"     - {file}")
    
    def analyze_large_files(self):
        """ุชุญููู ุงููููุงุช ุงููุจูุฑุฉ"""
        print("๐ฆ ุชุญููู ุงููููุงุช ุงููุจูุฑุฉ")
        print("-"*40)
        
        large_files = self.data.get('large_files', [])
        
        if not large_files:
            print("โ ูุง ุชูุฌุฏ ูููุงุช ูุจูุฑุฉ ุฌุฏุงู!")
            return
        
        # ุชุฑุชูุจ ุญุณุจ ุงูุญุฌู
        large_files.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\n๐ด ุงููููุงุช ุงููุจูุฑุฉ ({len(large_files)} ููู):")
        
        for file_path, lines in large_files[:10]:
            # ุฅูุฌุงุฏ ูุนูููุงุช ุงูููู ูู ุงูุชุญููู ุงูููุตู
            file_info = next((f for f in self.data['detailed_analysis'] 
                            if f['path'] == file_path), None)
            
            if file_info:
                print(f"\n  ๐ {file_path}")
                print(f"     โข ุงูุฃุณุทุฑ: {lines}")
                print(f"     โข ุงูููุน: {file_info['type']}")
                print(f"     โข ุงูุฃูููุฉ: {file_info['importance']}")
                print(f"     โข ุงูููุงุณุงุช: {file_info['stats']['classes']}")
                print(f"     โข ุงูุฏูุงู: {file_info['stats']['functions']}")
                
                # ุงูุชุฑุงุญุงุช ููุชูุณูู
                if lines > 500:
                    print(f"     โ๏ธ  ุงูุชุฑุงุญ: ูุณูู ูุฐุง ุงูููู ุฅูู ูููุงุช ุฃุตุบุฑ")
    
    def analyze_issues(self):
        """ุชุญููู ุงููุดุงูู ูู ุงูููุฏ"""
        print("โ๏ธ  ุชุญููู ุงููุดุงูู ุงูููุชุดูุฉ")
        print("-"*40)
        
        # ุฌูุน ุฌููุน ุงููุดุงูู
        issue_counts = defaultdict(int)
        files_with_issues = defaultdict(list)
        
        for file_info in self.data['detailed_analysis']:
            for issue in file_info.get('issues', []):
                issue_counts[issue] += 1
                files_with_issues[issue].append(file_info['path'])
        
        if not issue_counts:
            print("โ ูุง ุชูุฌุฏ ูุดุงูู ููุชุดูุฉ!")
            return
        
        # ุชุฑุชูุจ ุงููุดุงูู ุญุณุจ ุงูุชูุฑุงุฑ
        sorted_issues = sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)
        
        print(f"\n๐ ุงููุดุงูู ุงูุฃูุซุฑ ุดููุนุงู:")
        for issue, count in sorted_issues[:10]:
            print(f"\n  ๐ธ {issue}: {count} ููู")
            # ุนุฑุถ ุจุนุถ ุงูุฃูุซูุฉ
            for file in files_with_issues[issue][:3]:
                print(f"     - {file}")
            if len(files_with_issues[issue]) > 3:
                print(f"     ... ู {len(files_with_issues[issue]) - 3} ููู ุขุฎุฑ")
    
    def analyze_structure_problems(self):
        """ุชุญููู ูุดุงูู ุงููููู"""
        print("๐๏ธ ุชุญููู ูุดุงูู ูููู ุงููุดุฑูุน")
        print("-"*40)
        
        misplaced_files = []
        
        for file_info in self.data['detailed_analysis']:
            if file_info.get('suggested_location'):
                misplaced_files.append(file_info)
        
        if not misplaced_files:
            print("โ ุฌููุน ุงููููุงุช ูู ุฃูุงูููุง ุงูุตุญูุญุฉ!")
            return
        
        # ุชุตููู ุงููููุงุช ุญุณุจ ุงูููุน
        by_type = defaultdict(list)
        for file in misplaced_files:
            by_type[file['type']].append(file)
        
        print(f"\n๐ด ุงููููุงุช ูู ุฃูุงูู ุฎุงุทุฆุฉ ({len(misplaced_files)} ููู):")
        
        for file_type, files in by_type.items():
            print(f"\n  ๐ {file_type} ({len(files)} ููู):")
            for file in files[:5]:
                current = file['path']
                suggested = file['suggested_location']
                print(f"     โข {current}")
                print(f"       โก๏ธ  {suggested}")
    
    def analyze_dependencies(self):
        """ุชุญููู ุงูุชุจุนูุงุช"""
        print("๐ ุชุญููู ุงูุชุจุนูุงุช")
        print("-"*40)
        
        # ุฌูุน ุฌููุน ุงูุชุจุนูุงุช
        all_deps = defaultdict(int)
        external_deps = set()
        internal_deps = set()
        
        for file_info in self.data['detailed_analysis']:
            for dep in file_info.get('dependencies', []):
                all_deps[dep] += 1
                
                # ุชุตููู ุงูุชุจุนูุงุช
                if dep.startswith(('src', 'app', 'domain', 'infrastructure')):
                    internal_deps.add(dep)
                else:
                    external_deps.add(dep)
        
        print(f"\n๐ ุฅุญุตุงุฆูุงุช ุงูุชุจุนูุงุช:")
        print(f"  โข ุงูุชุจุนูุงุช ุงูุฎุงุฑุฌูุฉ: {len(external_deps)}")
        print(f"  โข ุงูุชุจุนูุงุช ุงูุฏุงุฎููุฉ: {len(internal_deps)}")
        
        # ุฃูุซุฑ ุงูุชุจุนูุงุช ุงุณุชุฎุฏุงูุงู
        sorted_deps = sorted(all_deps.items(), key=lambda x: x[1], reverse=True)
        
        print(f"\n๐ธ ุฃูุซุฑ ุงูุชุจุนูุงุช ุงุณุชุฎุฏุงูุงู:")
        for dep, count in sorted_deps[:10]:
            print(f"  โข {dep}: {count} ููู")
    
    def generate_cleanup_recommendations(self):
        """ุชูููุฏ ุชูุตูุงุช ุงูุชูุธูู"""
        print("๐ก ุชูุตูุงุช ุงูุชูุธูู")
        print("-"*40)
        
        recommendations = []
        
        # ุชูุตูุงุช ุจูุงุกู ุนูู ุงูุชุญููู
        duplicates = self.data.get('duplicate_candidates', [])
        large_files = self.data.get('large_files', [])
        empty_files = self.data.get('empty_files', [])
        
        # ุญุณุงุจ ุงูุชูููุฑ ุงููุญุชูู
        duplicate_files = sum(len(d['files']) - 1 for d in duplicates if d['type'] == 'exact')
        
        if duplicate_files > 0:
            recommendations.append({
                'priority': 'HIGH',
                'action': f'ุญุฐู {duplicate_files} ููู ููุฑุฑ',
                'impact': 'ุชูููุฑ ูุณุงุญุฉ ูุชูููู ุงูุชุนููุฏ'
            })
        
        if len(large_files) > 0:
            recommendations.append({
                'priority': 'MEDIUM',
                'action': f'ุชูุณูู {len(large_files)} ููู ูุจูุฑ',
                'impact': 'ุชุญุณูู ูุงุจููุฉ ุงูุตูุงูุฉ'
            })
        
        if len(empty_files) > 0:
            recommendations.append({
                'priority': 'HIGH',
                'action': f'ุญุฐู {len(empty_files)} ููู ูุงุฑุบ',
                'impact': 'ุชูุธูู ุงููุดุฑูุน'
            })
        
        # ุญุณุงุจ ุงููููุงุช ูู ุฃูุงูู ุฎุงุทุฆุฉ
        misplaced = sum(1 for f in self.data['detailed_analysis'] 
                       if f.get('suggested_location'))
        
        if misplaced > 0:
            recommendations.append({
                'priority': 'MEDIUM',
                'action': f'ููู {misplaced} ููู ุฅูู ุฃูุงูููุง ุงูุตุญูุญุฉ',
                'impact': 'ุชุญุณูู ุชูุธูู ุงููุดุฑูุน'
            })
        
        # ุนุฑุถ ุงูุชูุตูุงุช
        print("\n๐ ุฎุทุฉ ุงูุนูู ุงูููุชุฑุญุฉ:")
        
        # ุชุฑุชูุจ ุญุณุจ ุงูุฃููููุฉ
        high_priority = [r for r in recommendations if r['priority'] == 'HIGH']
        medium_priority = [r for r in recommendations if r['priority'] == 'MEDIUM']
        
        if high_priority:
            print("\n๐ด ุฃููููุฉ ุนุงููุฉ:")
            for i, rec in enumerate(high_priority, 1):
                print(f"  {i}. {rec['action']}")
                print(f"     ุงูุชุฃุซูุฑ: {rec['impact']}")
        
        if medium_priority:
            print("\n๐ก ุฃููููุฉ ูุชูุณุทุฉ:")
            for i, rec in enumerate(medium_priority, 1):
                print(f"  {i}. {rec['action']}")
                print(f"     ุงูุชุฃุซูุฑ: {rec['impact']}")
        
        # ููุฎุต ุงูุชูููุฑ ุงููุชููุน
        print("\n๐ฐ ุงูุชูููุฑ ุงููุชููุน:")
        print(f"  โข ุญุฐู {duplicate_files + len(empty_files)} ููู")
        print(f"  โข ุชุญุณูู ุชูุธูู {misplaced} ููู")
        print(f"  โข ุชูููู ุงูุชุนููุฏ ุจูุณุจุฉ ~{((duplicate_files + len(empty_files)) / self.data['total_python_files'] * 100):.1f}%")
    
    def _suggest_best_duplicate(self, files: List[str]) -> str:
        """ุงูุชุฑุงุญ ุฃูุถู ููู ูู ุงูููุฑุฑุงุช"""
        scores = {}
        
        for file in files:
            score = 0
            
            # ุชูุถูู ุงููููุงุช ูู src
            if 'src/' in file:
                score += 10
            
            # ุชูุถูู ุงููููุงุช ุงูุฃุณุงุณูุฉ
            if any(x in file for x in ['core', 'domain', 'service']):
                score += 5
            
            # ุชุฌูุจ ุงููููุงุช ุงููุฏููุฉ
            if any(x in file for x in ['old', 'backup', 'temp']):
                score -= 20
            
            # ุชูุถูู ุงููููุงุช ูู ุงููุฌูุฏุงุช ุงูููุธูุฉ
            depth = len(Path(file).parts)
            if 3 <= depth <= 5:  # ุนูู ูุซุงูู
                score += 3
            
            scores[file] = score
        
        return max(scores.items(), key=lambda x: x[1])[0]


def main():
    """ุชุดุบูู ุงูุชุญููู ุงูุนููู"""
    analyzer = DeepAnalyzer()
    analyzer.analyze_all()
    
    print("\n" + "="*60)
    print("โ ุงูุชูู ุงูุชุญููู ุงูุนููู!")
    print("\n๐ก ุงูุฎุทูุฉ ุงูุชุงููุฉ: ุดุบูู project_cleaner.py --dry-run ูููุนุงููุฉ")


if __name__ == "__main__":
    main() 