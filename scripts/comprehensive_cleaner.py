import os
import sys
import shutil
import json
import hashlib
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Optional, Set
import re
import ast

class ComprehensiveCleaner:
    """Ù…Ù†Ø¸Ù Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙ‚Ø¯Ù… Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear"""
    
    def __init__(self, analysis_file: str = "full_project_analysis.json", dry_run: bool = False):
        self.project_root = Path(".")
        self.analysis_file = analysis_file
        self.dry_run = dry_run
        self.backup_dir = f"final_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        self.cleanup_stats = {
            'deleted_files': 0,
            'deleted_dirs': 0,
            'moved_files': 0,
            'merged_files': 0,
            'fixed_issues': 0,
            'total_size_saved': 0
        }
        
        self.report = {
            'phase1_cleanup': [],  # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
            'phase2_dedup': [],    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
            'phase3_organize': [], # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…
            'phase4_fix': [],      # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
            'phase5_final': [],    # Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            'errors': [],
            'warnings': []
        }
        
        # Ù‚Ø±Ø§Ø¡Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        try:
            with open(analysis_file, 'r', encoding='utf-8') as f:
                self.analysis = json.load(f)
        except FileNotFoundError:
            print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {analysis_file}")
            sys.exit(1)
    
    def run_comprehensive_cleanup(self):
        """ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        print("ğŸ§¹ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear")
        print("="*60)
        
        if self.dry_run:
            print("âš ï¸  ÙˆØ¶Ø¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© - Ù„Ù† ÙŠØªÙ… ØªÙ†ÙÙŠØ° ØªØºÙŠÙŠØ±Ø§Øª ÙØ¹Ù„ÙŠØ©")
        else:
            print(f"ğŸ“ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {self.backup_dir}")
            os.makedirs(self.backup_dir, exist_ok=True)
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
        print("\n" + "="*60)
        print("ğŸ—‘ï¸ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©")
        print("="*60)
        self.phase1_major_cleanup()
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        print("\n" + "="*60)
        print("ğŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª")
        print("="*60)
        self.phase2_remove_duplicates()
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‡ÙŠÙƒÙ„
        print("\n" + "="*60)
        print("ğŸ“‚ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‡ÙŠÙƒÙ„")
        print("="*60)
        self.phase3_reorganize_structure()
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
        print("\n" + "="*60)
        print("ğŸ”§ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠØ© ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©")
        print("="*60)
        self.phase4_fix_issues()
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        print("\n" + "="*60)
        print("âœ¨ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        print("="*60)
        self.phase5_final_cleanup()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        print("\n" + "="*60)
        self.generate_final_report()
    
    def phase1_major_cleanup(self):
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©"""
        
        # 1. Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ backup_before_reorganization Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        backup_dir = Path("backup_before_reorganization")
        if backup_dir.exists():
            if not self.dry_run:
                shutil.rmtree(backup_dir)
            self.cleanup_stats['deleted_dirs'] += 1
            self.report['phase1_cleanup'].append({
                'action': 'delete_directory',
                'path': str(backup_dir),
                'reason': 'Old backup directory - contains duplicates'
            })
            print(f"  âœ… Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {backup_dir}")
        
        # 2. Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª __pycache__ Ùˆ .pyc
        cache_patterns = ['__pycache__', '*.pyc', '*.pyo', '*.pyd', '.pytest_cache', '.mypy_cache']
        for pattern in cache_patterns:
            for path in self.project_root.rglob(pattern):
                if path.is_file():
                    if not self.dry_run:
                        path.unlink()
                    self.cleanup_stats['deleted_files'] += 1
                elif path.is_dir():
                    if not self.dry_run:
                        shutil.rmtree(path)
                    self.cleanup_stats['deleted_dirs'] += 1
        
        # 3. Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØµÙ†ÙØ© ÙƒÙ€ trash
        trash_files = [f for f in self.analysis['detailed_analysis'] if f['importance'] == 'trash']
        for file_info in trash_files:
            file_path = Path(file_info['path'])
            if file_path.exists():
                if not self.dry_run:
                    self._backup_and_delete(file_path)
                self.cleanup_stats['deleted_files'] += 1
                self.report['phase1_cleanup'].append({
                    'action': 'delete_file',
                    'path': str(file_path),
                    'reason': 'Classified as trash'
                })
                print(f"  ğŸ—‘ï¸ Ø­Ø°Ù: {file_path}")
        
        # 4. Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ©
        for empty_file in self.analysis.get('empty_files', []):
            file_path = Path(empty_file)
            if file_path.exists():
                if not self.dry_run:
                    self._backup_and_delete(file_path)
                self.cleanup_stats['deleted_files'] += 1
                self.report['phase1_cleanup'].append({
                    'action': 'delete_file',
                    'path': str(file_path),
                    'reason': 'Empty file'
                })
                print(f"  ğŸ—‘ï¸ Ø­Ø°Ù Ù…Ù„Ù ÙØ§Ø±Øº: {file_path}")
        
        # 5. Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ§Ù„Ù…Ø¤Ù‚ØªØ©
        temp_patterns = ['*_old.py', '*_backup.py', '*_temp.py', '*_copy.py', '*.bak', '*.tmp', '*.swp']
        for pattern in temp_patterns:
            for file_path in self.project_root.rglob(pattern):
                if file_path.is_file():
                    if not self.dry_run:
                        self._backup_and_delete(file_path)
                    self.cleanup_stats['deleted_files'] += 1
                    print(f"  ğŸ—‘ï¸ Ø­Ø°Ù Ù…Ù„Ù Ù…Ø¤Ù‚Øª: {file_path}")
        
        print(f"\nâœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1 Ù…ÙƒØªÙ…Ù„Ø©: Ø­Ø°Ù {self.cleanup_stats['deleted_files']} Ù…Ù„Ù Ùˆ {self.cleanup_stats['deleted_dirs']} Ù…Ø¬Ù„Ø¯")
    
    def phase2_remove_duplicates(self):
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª"""
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        exact_duplicates = [d for d in self.analysis['duplicate_candidates'] if d['type'] == 'exact']
        
        for dup_group in exact_duplicates:
            files = [f for f in dup_group['files'] if Path(f).exists()]
            
            if len(files) > 1:
                # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù„Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡
                best_file = self._select_best_file(files)
                
                for file_path in files:
                    if file_path != best_file:
                        if not self.dry_run:
                            self._backup_and_delete(Path(file_path))
                        self.cleanup_stats['deleted_files'] += 1
                        self.cleanup_stats['merged_files'] += 1
                        self.report['phase2_dedup'].append({
                            'action': 'merge_duplicate',
                            'deleted': file_path,
                            'kept': best_file,
                            'hash': dup_group['hash'][:8]
                        })
                        print(f"  ğŸ”„ Ø¯Ù…Ø¬: {Path(file_path).name} -> {Path(best_file).name}")
        
        print(f"\nâœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2 Ù…ÙƒØªÙ…Ù„Ø©: Ø¯Ù…Ø¬ {self.cleanup_stats['merged_files']} Ù…Ù„Ù Ù…ÙƒØ±Ø±")
    
    def phase3_reorganize_structure(self):
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø¹Ø§Ø¯Ø© ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‡ÙŠÙƒÙ„"""
        
        # Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
        target_structure = {
            'src/core/': ['domain', 'services', 'interfaces'],
            'src/infrastructure/': ['persistence', 'ai_providers', 'messaging', 'monitoring', 'security'],
            'src/api/': ['rest', 'websocket', 'graphql'],
            'src/presentation/': ['ui', 'components'],
            'tests/': ['unit', 'integration', 'e2e', 'fixtures'],
            'configs/': ['development', 'staging', 'production'],
            'scripts/': ['setup', 'migration', 'maintenance', 'analysis'],
            'docs/': ['api', 'architecture', 'guides']
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        for parent, subdirs in target_structure.items():
            for subdir in subdirs:
                dir_path = self.project_root / parent / subdir
                if not self.dry_run:
                    dir_path.mkdir(parents=True, exist_ok=True)
        
        # Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ Ø£Ù…Ø§ÙƒÙ†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­Ø©
        files_to_move = []
        for file_info in self.analysis['detailed_analysis']:
            if file_info.get('suggested_location') and Path(file_info['path']).exists():
                current = Path(file_info['path'])
                suggested = Path(file_info['suggested_location'])
                
                # ØªØ¬Ù†Ø¨ Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ÙÙŠ Ø£Ù…Ø§ÙƒÙ†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­Ø©
                if not self._is_in_correct_location(current, suggested):
                    files_to_move.append((current, suggested, file_info['type']))
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ù†Ù‚Ù„
        for current, suggested, file_type in files_to_move[:50]:  # Ù†Ù‚Ù„ Ø£ÙˆÙ„ 50 Ù…Ù„Ù ÙÙ‚Ø·
            if not self.dry_run:
                self._move_file_safely(current, suggested)
            self.cleanup_stats['moved_files'] += 1
            self.report['phase3_organize'].append({
                'action': 'move_file',
                'from': str(current),
                'to': str(suggested),
                'type': file_type
            })
            print(f"  ğŸ“‚ Ù†Ù‚Ù„: {current.name} -> {suggested.parent}")
        
        print(f"\nâœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3 Ù…ÙƒØªÙ…Ù„Ø©: Ù†Ù‚Ù„ {self.cleanup_stats['moved_files']} Ù…Ù„Ù")
    
    def phase4_fix_issues(self):
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠØ© ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©"""
        
        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø°Ø§Øª Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©
        problematic_files = self.analysis.get('problematic_files', [])
        
        for file_info in problematic_files:
            file_path = Path(file_info['path'])
            if not file_path.exists():
                continue
            
            issues = file_info['issues']
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø­Ø±Ø¬Ø©
            if any('eval()' in issue or 'exec()' in issue for issue in issues):
                print(f"  âš ï¸  ØªØ­Ø°ÙŠØ± Ø£Ù…Ù†ÙŠ: {file_path.name} ÙŠØ³ØªØ®Ø¯Ù… eval/exec")
                self.report['phase4_fix'].append({
                    'action': 'security_warning',
                    'file': str(file_path),
                    'issues': [i for i in issues if 'eval' in i or 'exec' in i]
                })
            
            # Ø¥ØµÙ„Ø§Ø­ print statements
            if 'Print statements in production code' in issues:
                if not self.dry_run:
                    self._remove_print_statements(file_path)
                self.cleanup_stats['fixed_issues'] += 1
                print(f"  ğŸ”§ Ø¥Ø²Ø§Ù„Ø© print statements Ù…Ù†: {file_path.name}")
        
        print(f"\nâœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4 Ù…ÙƒØªÙ…Ù„Ø©: Ø¥ØµÙ„Ø§Ø­ {self.cleanup_stats['fixed_issues']} Ù…Ø´ÙƒÙ„Ø©")
    
    def phase5_final_cleanup(self):
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        
        if not self.dry_run:
            # 1. Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
            empty_dirs = []
            for root, dirs, files in os.walk(self.project_root, topdown=False):
                if not dirs and not files and root != str(self.project_root):
                    empty_dirs.append(root)
            
            for empty_dir in empty_dirs:
                try:
                    os.rmdir(empty_dir)
                    self.cleanup_stats['deleted_dirs'] += 1
                except:
                    pass
            
            # 2. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒÙˆØ¯
            print("  ğŸ¨ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… black...")
            os.system("black src/ tests/ scripts/ --quiet 2>nul")
            
            # 3. ØªØ±ØªÙŠØ¨ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
            print("  ğŸ“¦ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… isort...")
            os.system("isort src/ tests/ scripts/ --quiet 2>nul")
        
        print(f"\nâœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5 Ù…ÙƒØªÙ…Ù„Ø©: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    
    def _backup_and_delete(self, file_path: Path):
        """Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙˆØ­Ø°Ù Ø§Ù„Ù…Ù„Ù"""
        try:
            # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ
            backup_path = Path(self.backup_dir) / file_path.relative_to(self.project_root)
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(file_path, backup_path)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ø­ÙÙˆØ¸
            self.cleanup_stats['total_size_saved'] += file_path.stat().st_size
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù
            file_path.unlink()
        except Exception as e:
            self.report['errors'].append(f"Error deleting {file_path}: {e}")
    
    def _select_best_file(self, files: List[str]) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù…Ù† Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª"""
        scores = {}
        
        for file in files:
            score = 0
            path = Path(file)
            
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ src/
            if 'src/' in str(path):
                score += 20
            
            # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            if any(x in str(path) for x in ['core', 'domain', 'infrastructure']):
                score += 10
            
            # ØªØ¬Ù†Ø¨ Ù…Ø¬Ù„Ø¯Ø§Øª backup
            if 'backup' in str(path):
                score -= 100
            
            # ØªØ¬Ù†Ø¨ scripts Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¨Ø¯ÙŠÙ„
            if 'scripts/' in str(path):
                score -= 5
            
            # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø­Ø¯Ø«
            try:
                mtime = path.stat().st_mtime
                score += mtime / 1000000  # Ù†Ù‚Ø§Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙˆÙ‚Øª Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
            except:
                pass
            
            scores[file] = score
        
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def _is_in_correct_location(self, current: Path, suggested: Path) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„ØµØ­ÙŠØ­"""
        current_parts = current.parts
        suggested_parts = suggested.parts
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±
        for part in suggested_parts[:-1]:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            if part in current_parts:
                return True
        
        return False
    
    def _move_file_safely(self, source: Path, destination: Path):
        """Ù†Ù‚Ù„ Ù…Ù„Ù Ø¨Ø£Ù…Ø§Ù† Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù‡Ø¯Ù
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            # Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„Ù
            shutil.move(str(source), str(destination))
            
            # TODO: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
            
        except Exception as e:
            self.report['errors'].append(f"Error moving {source}: {e}")
    
    def _remove_print_statements(self, file_path: Path):
        """Ø¥Ø²Ø§Ù„Ø© print statements Ù…Ù† Ø§Ù„Ù…Ù„Ù"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Ø¥Ø²Ø§Ù„Ø© print statements Ø¨Ø³ÙŠØ·Ø©
            content = re.sub(r'^\s*print\s*\(.*?\)\s*$', '', content, flags=re.MULTILINE)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
        except Exception as e:
            self.report['errors'].append(f"Error fixing {file_path}: {e}")
    
    def generate_final_report(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        total_actions = (
            self.cleanup_stats['deleted_files'] + 
            self.cleanup_stats['deleted_dirs'] +
            self.cleanup_stats['moved_files'] +
            self.cleanup_stats['fixed_issues']
        )
        
        size_saved_mb = self.cleanup_stats['total_size_saved'] / (1024 * 1024)
        
        report_content = f"""# ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear

## ğŸ“… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ
- **Ø§Ù„ØªØ§Ø±ÙŠØ®**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ÙˆØ¶Ø¹ Ø§Ù„ØªØ´ØºÙŠÙ„**: {"ØªØ¬Ø±ÙŠØ¨ÙŠ" if self.dry_run else "ÙØ¹Ù„ÙŠ"}
- **Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ**: `{self.backup_dir}/`

## ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©

### ğŸ¯ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª: {total_actions}

| Ø§Ù„Ù†ÙˆØ¹ | Ø§Ù„Ø¹Ø¯Ø¯ |
|------|-------|
| ğŸ—‘ï¸ Ù…Ù„ÙØ§Øª Ù…Ø­Ø°ÙˆÙØ© | {self.cleanup_stats['deleted_files']} |
| ğŸ“ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ø­Ø°ÙˆÙØ© | {self.cleanup_stats['deleted_dirs']} |
| ğŸ”„ Ù…Ù„ÙØ§Øª Ù…Ø¯Ù…ÙˆØ¬Ø© | {self.cleanup_stats['merged_files']} |
| ğŸ“‚ Ù…Ù„ÙØ§Øª Ù…Ù†Ù‚ÙˆÙ„Ø© | {self.cleanup_stats['moved_files']} |
| ğŸ”§ Ù…Ø´Ø§ÙƒÙ„ Ù…ÙØµÙ„Ø­Ø© | {self.cleanup_stats['fixed_issues']} |
| ğŸ’¾ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ÙˆÙØ±Ø© | {size_saved_mb:.2f} MB |

## ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ø­Ù„

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©
- Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ `backup_before_reorganization` Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
- Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª `__pycache__` Ùˆ `.pyc`
- Ø­Ø°Ù {len([x for x in self.report['phase1_cleanup'] if x['action'] == 'delete_file'])} Ù…Ù„Ù ØºÙŠØ± Ù…Ù‡Ù…

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
- Ù…Ø¹Ø§Ù„Ø¬Ø© {self.cleanup_stats['merged_files']} Ù…Ù„Ù Ù…ÙƒØ±Ø±
- Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø£ÙØ¶Ù„ Ù†Ø³Ø®Ø© Ù…Ù† ÙƒÙ„ Ù…Ù„Ù

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ…
- Ù†Ù‚Ù„ {self.cleanup_stats['moved_files']} Ù…Ù„Ù Ø¥Ù„Ù‰ Ø£Ù…Ø§ÙƒÙ†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­Ø©
- Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ù†Ø¸Ù…

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
- Ø¥ØµÙ„Ø§Ø­ {self.cleanup_stats['fixed_issues']} Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
- ØªØ­Ø°ÙŠØ±Ø§Øª Ø£Ù…Ù†ÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… eval/exec

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
- Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
- ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… black
- ØªØ±ØªÙŠØ¨ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… isort

## âš ï¸ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡
"""
        
        if self.report['errors']:
            report_content += f"\n### âŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ({len(self.report['errors'])})\n"
            for error in self.report['errors'][:10]:
                report_content += f"- {error}\n"
        
        # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©
        security_warnings = [x for x in self.report['phase4_fix'] if x['action'] == 'security_warning']
        if security_warnings:
            report_content += f"\n### ğŸ”´ ØªØ­Ø°ÙŠØ±Ø§Øª Ø£Ù…Ù†ÙŠØ© ({len(security_warnings)})\n"
            report_content += "Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ØªØ³ØªØ®Ø¯Ù… eval/exec ÙˆÙŠØ¬Ø¨ Ù…Ø±Ø§Ø¬Ø¹ØªÙ‡Ø§:\n"
            for warning in security_warnings:
                report_content += f"- `{Path(warning['file']).name}`\n"
        
        report_content += """
## âœ… Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

1. [ ] Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
2. [ ] ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙƒØ³Ø± Ø£ÙŠ Ø´ÙŠØ¡
3. [ ] Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø°Ø§Øª Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©
4. [ ] Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ£ÙƒØ¯
5. [ ] Ø¹Ù…Ù„ commit Ù„Ù„ØªØºÙŠÙŠØ±Ø§Øª

## ğŸ’¡ Ù†ØµØ§Ø¦Ø­
- ØªÙ… Ø­ÙØ¸ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
- ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø£ÙŠ Ù…Ù„Ù Ù…Ù† Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
- Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… eval/exec ÙˆØ£Ø¹Ø¯ ÙƒØªØ§Ø¨ØªÙ‡Ø§ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø©
"""
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        with open('comprehensive_cleanup_report.md', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± JSON Ù…ÙØµÙ„
        detailed_report = {
            'metadata': {
                'date': datetime.now().isoformat(),
                'dry_run': self.dry_run,
                'backup_dir': self.backup_dir
            },
            'statistics': self.cleanup_stats,
            'actions': self.report
        }
        
        with open('comprehensive_cleanup_report.json', 'w', encoding='utf-8') as f:
            json.dump(detailed_report, f, indent=2, ensure_ascii=False)
        
        print("\n" + "="*60)
        print("âœ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§ÙƒØªÙ…Ù„!")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª: {total_actions}")
        print(f"ğŸ’¾ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ÙˆÙØ±Ø©: {size_saved_mb:.2f} MB")
        print("\nğŸ“‹ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±:")
        print("  â€¢ comprehensive_cleanup_report.md")
        print("  â€¢ comprehensive_cleanup_report.json")


def main():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù Ø§Ù„Ø´Ø§Ù…Ù„"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ØªÙ†Ø¸ÙŠÙ Ø´Ø§Ù…Ù„ Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear')
    parser.add_argument('--dry-run', action='store_true', 
                       help='ØªØ´ØºÙŠÙ„ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¯ÙˆÙ† ØªÙ†ÙÙŠØ° Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª')
    parser.add_argument('--analysis-file', default='full_project_analysis.json',
                       help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„')
    
    args = parser.parse_args()
    
    # Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡
    if not args.dry_run:
        print("="*60)
        print("âš ï¸  ØªØ­Ø°ÙŠØ± Ù…Ù‡Ù…!")
        print("="*60)
        print("Ø³ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø¨Ù€:")
        print("  â€¢ Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ backup_before_reorganization Ø¨Ø§Ù„ÙƒØ§Ù…Ù„")
        print("  â€¢ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©")
        print("  â€¢ Ù†Ù‚Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ Ø£Ù…Ø§ÙƒÙ† Ø¬Ø¯ÙŠØ¯Ø©")
        print("  â€¢ Ø¥ØµÙ„Ø§Ø­ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯")
        print("\nğŸ“ Ø³ÙŠØªÙ… Ø­ÙØ¸ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ: final_backup_[timestamp]")
        print("="*60)
        
        response = input("\nÙ‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©ØŸ Ø§ÙƒØªØ¨ 'Ù†Ø¹Ù…' Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©: ")
        if response.lower() not in ['Ù†Ø¹Ù…', 'yes']:
            print("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
            return
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù
    cleaner = ComprehensiveCleaner(
        analysis_file=args.analysis_file,
        dry_run=args.dry_run
    )
    cleaner.run_comprehensive_cleanup()


if __name__ == "__main__":
    main() 