# ğŸ¤ Ø¯Ù„ÙŠÙ„ Ø®Ø¯Ù…Ø© Ø§Ù„ØµÙˆØª - Voice Service Guide

## ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©
Ø®Ø¯Ù…Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© Ù„Ù…Ø´Ø±ÙˆØ¹ AI Teddy Bear ØªØ¯Ø¹Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ (STT) Ù…Ø¹ Ø¹Ø¯Ø© Ù…Ø²ÙˆØ¯ÙŠÙ† ÙˆØªÙ†Ø³ÙŠÙ‚Ø§Øª ØµÙˆØªÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø©ØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù…Ù† Ø£Ø¬Ù‡Ø²Ø© ESP32.

---

## ğŸ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

### âœ… **Ù…Ø²ÙˆØ¯ÙŠ STT Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…ÙŠÙ†:**
- **Whisper** (Ù…Ø­Ù„ÙŠ) - Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙˆØ§Ù„Ù…ÙØ³ØªØ­Ø³Ù†
- **Azure Speech SDK** - Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ
- **OpenAI Whisper API** - Ø¹Ø¨Ø± API
- **Mock Provider** - Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„ØªØ·ÙˆÙŠØ±

### âœ… **ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:**
- **WAV** - ØºÙŠØ± Ù…Ø¶ØºÙˆØ·
- **MP3** - Ù…Ø¶ØºÙˆØ· (Ù…ÙØ³ØªØ­Ø³Ù† Ù„Ù„Ù€ ESP32)
- **OGG** - Ù…Ø¶ØºÙˆØ· Ø¨Ø¯ÙŠÙ„
- **WEBM, M4A, FLAC** - ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©

### âœ… **Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©:**
- **ØªØ­ÙˆÙŠÙ„ ØªÙ†Ø³ÙŠÙ‚Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠ** (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pydub Ø£Ùˆ ffmpeg)
- **Ø¯Ø¹Ù… ESP32 Ù…Ø®ØµØµ** Ù…Ø¹ metadata Ø¥Ø¶Ø§ÙÙŠØ©
- **Ø¢Ù„ÙŠØ© fallback Ù‚ÙˆÙŠØ©** Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- **Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡** Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
- **Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© Ù…Ø­Ø³Ù†Ø©**

---

## ğŸ”§ Ø§Ù„ØªØ«Ø¨ÙŠØª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯

### **1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:**

```bash
# Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
pip install fastapi uvicorn pydantic

# Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª
pip install pydub wave numpy

# Whisper (Ù…Ø­Ù„ÙŠ) - Ù…ÙØ³ØªØ­Ø³Ù†
pip install openai-whisper

# Azure Speech (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
pip install azure-cognitiveservices-speech

# OpenAI API (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
pip install openai
```

### **2. ØªØ«Ø¨ÙŠØª ffmpeg (Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…):**

```bash
# Windows (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… chocolatey)
choco install ffmpeg

# macOS (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… homebrew)
brew install ffmpeg

# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# Ø£Ùˆ ØªØ­Ù…ÙŠÙ„ Ù…Ù†: https://ffmpeg.org/download.html
```

### **3. Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©:**

```bash
# Ù…Ù„Ù .env
STT_PROVIDER=whisper              # whisper, azure, openai
WHISPER_MODEL=base                # tiny, base, small, medium, large
MAX_AUDIO_DURATION=30             # Ø«ÙˆØ§Ù†ÙŠ
ENABLE_STT_FALLBACK=true          # ØªÙØ¹ÙŠÙ„ fallback

# Azure Speech (Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù…Ù‡)
AZURE_SPEECH_KEY=your_azure_key
AZURE_SPEECH_REGION=eastus
AZURE_SPEECH_LANGUAGE=ar-SA

# OpenAI API (Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù…Ù‡)
OPENAI_API_KEY=your_openai_key
```

---

## ğŸš€ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹

### **1. Ø¥Ù†Ø´Ø§Ø¡ Voice Service:**

```python
from src.application.services.voice_service import create_voice_service

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
voice_service = create_voice_service()

# Ø£Ùˆ Ø¨Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø®ØµØµØ©
from src.application.services.voice_service import VoiceService, VoiceServiceConfig, STTProvider

config = VoiceServiceConfig(
    default_provider=STTProvider.WHISPER,
    whisper_model="base",
    max_audio_duration=60,
    enable_fallback=True
)

voice_service = VoiceService(config)
```

### **2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ:**

```python
import asyncio
import base64

async def transcribe_example():
    # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù ØµÙˆØªÙŠ
    with open("audio.mp3", "rb") as f:
        audio_bytes = f.read()
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ base64 (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ
    result = await voice_service.transcribe_audio(
        audio_data=audio_base64,  # Ø£Ùˆ audio_bytes Ù…Ø¨Ø§Ø´Ø±Ø©
        format=AudioFormat.MP3,
        language="ar",
        provider=STTProvider.WHISPER
    )
    
    print(f"Ø§Ù„Ù†Øµ: {result.text}")
    print(f"Ø§Ù„Ø«Ù‚Ø©: {result.confidence:.2f}")
    print(f"Ø§Ù„Ù…Ø²ÙˆØ¯: {result.provider}")
    print(f"ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {result.processing_time_ms}ms")

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„
asyncio.run(transcribe_example())
```

### **3. Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØª ESP32:**

```python
from src.application.services.voice_service import AudioRequest

async def process_esp32_audio():
    # Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ ØµÙˆØª ESP32
    request = AudioRequest(
        audio_data="base64_encoded_mp3_data",
        format=AudioFormat.MP3,
        device_id="ESP32_TEDDY_001",
        session_id="session_123",
        language="ar",
        child_name="Ø£Ø­Ù…Ø¯",
        child_age=6
    )
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
    result = await voice_service.process_esp32_audio(request)
    
    print(f"Ø¬Ù‡Ø§Ø² ESP32: {result.metadata['device_id']}")
    print(f"Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„: {result.metadata['child_name']}")
    print(f"Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªØ´Ù: {result.text}")

asyncio.run(process_esp32_audio())
```

---

## ğŸŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… API Endpoints

### **1. Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ù† ESP32:**

```python
import requests

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
files = {
    'file': ('audio.mp3', open('audio.mp3', 'rb'), 'audio/mpeg')
}

data = {
    'device_id': 'ESP32_TEDDY_001',
    'session_id': 'session_123',
    'audio_format': 'mp3',
    'language': 'ar',
    'child_name': 'ÙØ§Ø·Ù…Ø©',
    'child_age': 5
}

# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
response = requests.post(
    'http://localhost:8000/api/voice/esp32/audio',
    files=files,
    data=data
)

if response.status_code == 200:
    result = response.json()
    print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„ØªØ­ÙˆÙŠÙ„: {result['transcription']['text']}")
    print(f"ğŸ¤– Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ: {result['ai_response']['text']}")
else:
    print(f"âŒ Ø®Ø·Ø£: {response.status_code}")
```

### **2. Ø¥Ø±Ø³Ø§Ù„ JSON Ù…Ø¨Ø§Ø´Ø±:**

```python
import requests
import base64

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ base64
with open('audio.mp3', 'rb') as f:
    audio_base64 = base64.b64encode(f.read()).decode('utf-8')

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
payload = {
    "audio_data": audio_base64,
    "format": "mp3",
    "device_id": "ESP32_TEDDY_002",
    "language": "ar",
    "child_name": "Ù…Ø­Ù…Ø¯"
}

# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
response = requests.post(
    'http://localhost:8000/api/voice/esp32/audio-json',
    json=payload,
    headers={'Content-Type': 'application/json'}
)

result = response.json()
print(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result}")
```

### **3. Ù…Ø«Ø§Ù„ ESP32 (Arduino/C++):**

```cpp
// ÙÙŠ Ù…Ù„Ù ESP32
#include <HTTPClient.h>
#include <ArduinoJson.h>

void sendAudioToServer(uint8_t* mp3_data, size_t size) {
    HTTPClient http;
    http.begin("http://your-server.com/api/voice/esp32/audio");
    
    // Ø¥Ø¹Ø¯Ø§Ø¯ multipart form data
    String boundary = "----TeddyBearBoundary";
    String body = "";
    
    // Ø¥Ø¶Ø§ÙØ© metadata
    body += "--" + boundary + "\r\n";
    body += "Content-Disposition: form-data; name=\"device_id\"\r\n\r\n";
    body += "ESP32_TEDDY_001\r\n";
    
    body += "--" + boundary + "\r\n";
    body += "Content-Disposition: form-data; name=\"audio_format\"\r\n\r\n";
    body += "mp3\r\n";
    
    body += "--" + boundary + "\r\n";
    body += "Content-Disposition: form-data; name=\"language\"\r\n\r\n";
    body += "ar\r\n";
    
    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
    body += "--" + boundary + "\r\n";
    body += "Content-Disposition: form-data; name=\"file\"; filename=\"audio.mp3\"\r\n";
    body += "Content-Type: audio/mpeg\r\n\r\n";
    
    // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©
    // ... (Ø¥Ø¶Ø§ÙØ© mp3_data Ù‡Ù†Ø§)
    
    body += "\r\n--" + boundary + "--\r\n";
    
    http.addHeader("Content-Type", "multipart/form-data; boundary=" + boundary);
    
    int response_code = http.POST(body);
    
    if (response_code == 200) {
        String response = http.getString();
        Serial.println("âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­");
        // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯...
    }
    
    http.end();
}
```

---

## âš™ï¸ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

### **1. Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Whisper:**

```python
from src.application.services.voice_service import WhisperModel

config = VoiceServiceConfig(
    whisper_model=WhisperModel.SMALL,  # Ø£Ø³Ø±Ø¹ØŒ Ø¯Ù‚Ø© Ø¬ÙŠØ¯Ø©
    # WhisperModel.TINY     -> Ø£Ø³Ø±Ø¹ Ø¬Ø¯Ø§Ù‹ØŒ Ø¯Ù‚Ø© Ø£Ù‚Ù„
    # WhisperModel.BASE     -> Ù…ØªÙˆØ§Ø²Ù† (Ø§ÙØªØ±Ø§Ø¶ÙŠ)
    # WhisperModel.MEDIUM   -> Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ØŒ Ø£Ø¨Ø·Ø£
    # WhisperModel.LARGE    -> Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø©ØŒ Ø§Ù„Ø£Ø¨Ø·Ø£
)
```

### **2. Ø¥Ø¹Ø¯Ø§Ø¯ Azure Speech:**

```python
config = VoiceServiceConfig(
    default_provider=STTProvider.AZURE,
    azure_key="your_subscription_key",
    azure_region="eastus",  # Ø£Ùˆ Ù…Ù†Ø·Ù‚ØªÙƒ
    azure_language="ar-SA"  # Ø£Ùˆ ar-EG, ar-AE, etc.
)
```

### **3. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡:**

```python
config = VoiceServiceConfig(
    max_audio_duration=60,      # Ø«ÙˆØ§Ù†ÙŠ
    supported_formats=[         # ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø©
        AudioFormat.WAV,
        AudioFormat.MP3,
        AudioFormat.OGG
    ],
    enable_fallback=True,       # ØªÙØ¹ÙŠÙ„ fallback
    temp_dir="./audio_temp"     # Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª
)
```

---

## ğŸ§ª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„ØªØ·ÙˆÙŠØ±

### **1. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:**

```bash
# Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ­Ø¯Ø©
pytest tests/unit/test_voice_service.py -v

# Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªÙƒØ§Ù…Ù„
pytest tests/integration/test_voice_api_integration.py -v

# Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø¹ Whisper Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
pytest tests/integration/test_voice_api_integration.py::TestRealServiceIntegration -v -m integration

# Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
pytest tests/ -v
```

### **2. Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹:**

```python
# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ù„Ù„Ø®Ø¯Ù…Ø©
async def quick_test():
    voice_service = create_voice_service()
    
    # ÙØ­Øµ Ø§Ù„ØµØ­Ø©
    health = await voice_service.health_check()
    print(f"Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø©: {health}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ ØµÙˆØª ÙˆÙ‡Ù…ÙŠ
    result = await voice_service.transcribe_audio(
        audio_data=b"test_audio_data",
        format=AudioFormat.WAV
    )
    
    print(f"Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {result.text}")

import asyncio
asyncio.run(quick_test())
```

### **3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡:**

```python
import time

async def performance_test():
    voice_service = create_voice_service()
    
    # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ
    with open("test_audio.mp3", "rb") as f:
        audio_data = f.read()
    
    # Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡
    start_time = time.time()
    
    result = await voice_service.transcribe_audio(
        audio_data=audio_data,
        format=AudioFormat.MP3
    )
    
    end_time = time.time()
    total_time = (end_time - start_time) * 1000
    
    print(f"â±ï¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙˆÙ‚Øª: {total_time:.1f}ms")
    print(f"ğŸµ Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª: {result.audio_duration_ms}ms")
    print(f"ğŸ“Š Ø¹Ø§Ù…Ù„ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ: {total_time / result.audio_duration_ms:.2f}x")

asyncio.run(performance_test())
```

---

## ğŸ”§ Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

### **Ù…Ø´Ø§ÙƒÙ„ Ø´Ø§Ø¦Ø¹Ø© ÙˆØ­Ù„ÙˆÙ„Ù‡Ø§:**

#### **1. Ø®Ø·Ø£ "Whisper model not available":**
```bash
# Ø§Ù„Ø­Ù„: ØªØ«Ø¨ÙŠØª Whisper
pip install openai-whisper

# Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø²ÙˆØ¯ Ø¢Ø®Ø±
export STT_PROVIDER=azure
```

#### **2. Ø®Ø·Ø£ "ffmpeg not found":**
```bash
# Windows
choco install ffmpeg

# macOS
brew install ffmpeg

# Linux
sudo apt install ffmpeg

# Ø£Ùˆ ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ
```

#### **3. Ø®Ø·Ø£ "Audio conversion failed":**
```python
# ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙˆØª
print(f"ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù„Ù: {file_format}")

# Ø¬Ø±Ø¨ ØªØ­ÙˆÙŠÙ„ ÙŠØ¯ÙˆÙŠ
from pydub import AudioSegment
audio = AudioSegment.from_file("audio.mp3")
audio.export("converted.wav", format="wav")
```

#### **4. Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡:**
```python
# Ø§Ø³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ Ø£ØµØºØ±
config.whisper_model = WhisperModel.TINY

# Ø£Ùˆ Ù‚Ù„Ù„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
# ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ 16kHz Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
```

#### **5. Ø®Ø·Ø£ "Azure Speech not configured":**
```bash
# ØªØ¹ÙŠÙŠÙ† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
export AZURE_SPEECH_KEY=your_key
export AZURE_SPEECH_REGION=eastus

# Ø£Ùˆ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
config.azure_key = "your_key"
config.azure_region = "eastus"
```

---

## ğŸ“Š Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡

### **1. Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**

```python
async def monitor_performance():
    result = await voice_service.transcribe_audio(...)
    
    # Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ù‡Ù…Ø©
    print(f"ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: {result.confidence:.2%}")
    print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {result.processing_time_ms}ms")
    print(f"ğŸµ Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª: {result.audio_duration_ms}ms")
    print(f"ğŸ“ Ù†Ø³Ø¨Ø© Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ: {result.processing_time_ms / result.audio_duration_ms:.1f}x")
    
    # metadata Ø¥Ø¶Ø§ÙÙŠØ©
    if "compression_ratio" in result.metadata:
        print(f"ğŸ“¦ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¶ØºØ·: {result.metadata['compression_ratio']:.1f}x")
```

### **2. Ø±ØµØ¯ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:**

```python
async def system_health_check():
    health = await voice_service.health_check()
    
    print("ğŸ¥ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…:")
    print(f"   Ø§Ù„Ø®Ø¯Ù…Ø©: {health['service']}")
    print(f"   Whisper: {health['dependencies']['whisper']}")
    print(f"   Azure: {health['dependencies']['azure_speech']}")
    print(f"   pydub: {health['dependencies']['pydub']}")
    
    for provider, status in health['providers'].items():
        print(f"   {provider}: {status}")
```

---

## ğŸš€ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø¥Ù†ØªØ§Ø¬

### **1. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡:**
- **Ø§Ø³ØªØ®Ø¯Ù… Whisper Base Ø£Ùˆ Small** Ù„Ù„ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø¯Ù‚Ø©
- **ÙØ¹Ù„ ffmpeg** Ù„ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ø±Ø¹ Ù„Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª
- **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¶ØºØ· MP3** Ù…Ù† ESP32 Ù„ØªÙˆÙÙŠØ± bandwidth
- **Ø±Ø§Ù‚Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©** Ø®Ø§ØµØ© Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©

### **2. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬ÙˆØ¯Ø©:**
- **Ø§Ø³ØªØ®Ø¯Ù… sample rate 16kHz** Ù„Ù„ÙƒÙ„Ø§Ù…
- **ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†** Ø¹Ù„Ù‰ ESP32
- **ÙÙ„ØªØ±Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡** Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
- **Ø§Ø³ØªØ®Ø¯Ù… Azure** Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹

### **3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:**
- **ÙØ¹Ù„ Ù†Ø¸Ø§Ù… fallback** Ø¯Ø§Ø¦Ù…Ø§Ù‹
- **Ø±Ø§Ù‚Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­** ÙˆØ§Ù„Ø«Ù‚Ø©
- **Ø³Ø¬Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡** Ù„Ù„ØªØ­Ù„ÙŠÙ„
- **Ø§Ø³ØªØ®Ø¯Ù… retry logic** Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©

### **4. Ø§Ù„Ø£Ù…Ø§Ù†:**
- **Ø´ÙØ± Ø§Ù„ØµÙˆØª** Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ù‚Ù„
- **Ø§Ø­Ù… Ù…ÙØ§ØªÙŠØ­ API** (Azure, OpenAI)
- **Ø­Ø¯Ø¯ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„ÙØ§Øª** Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø©
- **Ø±Ø§Ù‚Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯** Ù„Ù…Ù†Ø¹ DoS

---

## ğŸ“± ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

### **Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„:**

```
ESP32 Device
    â†“ (MP3 Audio)
FastAPI Endpoint (/api/voice/esp32/audio)
    â†“
Voice Service (STT)
    â†“ (Transcribed Text)
AI Service (Response Generation)
    â†“ (AI Response)
Response to ESP32
    â†“
Child Interaction
```

### **ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
```python
# Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­ÙˆÙŠÙ„
async def save_transcription(result, device_id):
    transcription_data = {
        "device_id": device_id,
        "text": result.text,
        "confidence": result.confidence,
        "provider": result.provider,
        "timestamp": datetime.now(),
        "processing_time_ms": result.processing_time_ms
    }
    
    # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    await database.save_transcription(transcription_data)
```

---

## ğŸ¯ Ø®Ø§Ø±Ø·Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©

### **Ù…ÙŠØ²Ø§Øª Ù‚Ø§Ø¯Ù…Ø©:**
- ğŸ¯ **Ø¯Ø¹Ù… Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©** (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ ÙØ±Ù†Ø³ÙŠØ©ØŒ Ø¥Ø³Ø¨Ø§Ù†ÙŠØ©)
- ğŸ”Š **ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª** Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
- ğŸ“± **Ø¯Ø¹Ù… WebRTC** Ù„Ù„ØµÙˆØª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
- ğŸ¤– **ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ LLM Ù…Ø­Ù„ÙŠØ©**
- ğŸ“Š **analytics Ù…ØªÙ‚Ø¯Ù…Ø©** Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©
- ğŸ”’ **ØªØ´ÙÙŠØ± end-to-end** Ù„Ù„Ø®ØµÙˆØµÙŠØ©

### **ØªØ­Ø³ÙŠÙ†Ø§Øª ØªÙ‚Ù†ÙŠØ©:**
- âš¡ **ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø±Ø¹Ø©** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU
- ğŸ’¾ **ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©**
- ğŸŒ **Ø¯Ø¹Ù… clustering** Ù„Ù„ØªÙˆØ³Ø¹
- ğŸ“ˆ **Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…ØªÙ‚Ø¯Ù…Ø©** Ù…Ø¹ Prometheus
- ğŸ³ **containerization** Ù…Ø­Ø³Ù†

---

**ğŸ‰ Ø®Ø¯Ù…Ø© Ø§Ù„ØµÙˆØª Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!**

Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªÙØ¹ÙŠÙ„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ Ø¨ÙƒÙØ§Ø¡Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ Ù…Ø´Ø±ÙˆØ¹ AI Teddy BearØŒ Ù…Ø¹ Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù„ØµÙˆØª Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù…Ù† ESP32 ÙˆØªÙƒØ§Ù…Ù„ Ø³Ù„Ø³ Ù…Ø¹ Ø¨Ø§Ù‚ÙŠ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…. 