# Distributed AI Processing Dependencies for AI Teddy Bear Project
# AI Team Implementation - Task 11

# Core distributed processing
ray[serve]>=2.8.0
ray[data]>=2.8.0

# AI Services
openai>=1.10.0
whisper>=1.1.10
transformers>=4.30.0
torch>=2.0.0
torchaudio>=2.0.0

# Audio processing
librosa>=0.10.0
soundfile>=0.12.0
numpy>=1.21.0
scipy>=1.10.0

# Web services and APIs
fastapi>=0.100.0
uvicorn>=0.20.0
aiohttp>=3.8.0
websockets>=11.0.0

# Data processing
pandas>=2.0.0
pyarrow>=12.0.0

# Monitoring and observability
prometheus-client>=0.17.0
structlog>=23.0.0

# Development and testing
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-mock>=3.10.0

# Optional: Advanced AI services
# elevenlabs>=0.2.0           # For TTS synthesis
# hume>=0.2.0                 # For emotion analysis
# azure-cognitiveservices-speech>=1.30.0  # For Azure Speech

# Optional: GPU acceleration
# torch[cuda]>=2.0.0          # For CUDA support
# tensorrt>=8.6.0             # For TensorRT optimization 