#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Find More Duplicates - Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø© Ø¥Ø¶Ø§ÙÙŠØ©
"""

import os
import hashlib
import json
from datetime import datetime
from collections import defaultdict
from pathlib import Path

def find_duplicates_by_content():
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø© Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
    print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø© Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰...")
    
    file_hashes = defaultdict(list)
    
    for root, dirs, files in os.walk('.'):
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if file.endswith(('.py', '.js', '.json', '.yml', '.yaml')):
                file_path = os.path.join(root, file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    if content.strip():  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ©
                        file_hash = hashlib.md5(content.encode()).hexdigest()
                        file_hashes[file_hash].append(file_path)
                        
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
    duplicates = {}
    for file_hash, files in file_hashes.items():
        if len(files) > 1:
            duplicates[file_hash] = files
    
    return duplicates

def find_duplicates_by_name():
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù… ÙÙŠ Ø£Ù…Ø§ÙƒÙ† Ù…Ø®ØªÙ„ÙØ©"""
    print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¨Ù†ÙØ³ Ø§Ù„Ø§Ø³Ù…...")
    
    name_to_files = defaultdict(list)
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if file.endswith(('.py', '.js', '.json', '.yml', '.yaml')):
                file_path = os.path.join(root, file)
                name_to_files[file].append(file_path)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
    duplicates = {}
    for filename, files in name_to_files.items():
        if len(files) > 1:
            duplicates[filename] = files
    
    return duplicates

def find_similar_config_files():
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø©"""
    print("ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø©...")
    
    config_files = []
    config_patterns = ['config', 'setting', '.env', 'constant', 'default']
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if any(pattern in file.lower() for pattern in config_patterns):
                config_files.append(os.path.join(root, file))
    
    return config_files

def analyze_init_files():
    """ØªØ­Ù„ÙŠÙ„ Ø®Ø§Øµ Ù„Ù…Ù„ÙØ§Øª __init__.py"""
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª __init__.py...")
    
    init_files = []
    empty_inits = []
    content_inits = []
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if file == '__init__.py':
                file_path = os.path.join(root, file)
                init_files.append(file_path)
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read().strip()
                    
                    if content:
                        content_inits.append({
                            'path': file_path,
                            'content': content,
                            'lines': len(content.splitlines())
                        })
                    else:
                        empty_inits.append(file_path)
                        
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
    
    return {
        'total': len(init_files),
        'empty': len(empty_inits),
        'with_content': len(content_inits),
        'empty_files': empty_inits,
        'content_files': content_inits
    }

def check_test_file_duplicates():
    """ÙØ­Øµ Ù…Ù„ÙØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("ğŸ” ÙØ­Øµ Ù…Ù„ÙØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª...")
    
    test_files = []
    
    for root, dirs, files in os.walk('.'):
        dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules', '.venv']]
        
        for file in files:
            if 'test' in file.lower() and file.endswith('.py'):
                file_path = os.path.join(root, file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    test_files.append({
                        'path': file_path,
                        'size': len(content),
                        'lines': len(content.splitlines()),
                        'hash': hashlib.md5(content.encode()).hexdigest()
                    })
                    
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª
    hash_to_tests = defaultdict(list)
    for test in test_files:
        hash_to_tests[test['hash']].append(test['path'])
    
    duplicates = {h: files for h, files in hash_to_tests.items() if len(files) > 1}
    
    return {
        'total_tests': len(test_files),
        'duplicates': duplicates,
        'all_tests': test_files
    }

def generate_duplicate_report():
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ø¹Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("ğŸ“Š ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©...")
    
    # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    content_duplicates = find_duplicates_by_content()
    name_duplicates = find_duplicates_by_name()
    config_files = find_similar_config_files()
    init_analysis = analyze_init_files()
    test_analysis = check_test_file_duplicates()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = {
        'timestamp': str(datetime.now()),
        'summary': {
            'content_duplicates': len(content_duplicates),
            'name_duplicates': len(name_duplicates),
            'config_files': len(config_files),
            'init_files_total': init_analysis['total'],
            'init_files_empty': init_analysis['empty'],
            'test_duplicates': len(test_analysis['duplicates'])
        },
        'details': {
            'content_duplicates': content_duplicates,
            'name_duplicates': name_duplicates,
            'config_files': config_files,
            'init_analysis': init_analysis,
            'test_analysis': test_analysis
        }
    }
    
    return report

def print_duplicate_summary(report):
    """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("\n" + "="*60)
    print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©")
    print("="*60)
    
    summary = report['summary']
    details = report['details']
    
    print(f"\nğŸ” Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    print(f"- Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {summary['content_duplicates']} Ù…Ø¬Ù…ÙˆØ¹Ø©")
    print(f"- Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø³Ù…: {summary['name_duplicates']} Ø§Ø³Ù…")
    print(f"- Ù…Ù„ÙØ§Øª Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {summary['config_files']} Ù…Ù„Ù")
    print(f"- Ù…Ù„ÙØ§Øª __init__.py: {summary['init_files_total']} (ÙØ§Ø±ØºØ©: {summary['init_files_empty']})")
    print(f"- Ù…ÙƒØ±Ø±Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {summary['test_duplicates']} Ù…Ø¬Ù…ÙˆØ¹Ø©")
    
    # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    if details['content_duplicates']:
        print(f"\nğŸ”„ Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ø£ÙˆÙ„ 5):")
        for i, (file_hash, files) in enumerate(list(details['content_duplicates'].items())[:5]):
            print(f"\n  Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1} ({len(files)} Ù…Ù„Ù):")
            for file in files[:3]:
                print(f"    - {file}")
            if len(files) > 3:
                print(f"    - ... Ùˆ {len(files) - 3} Ù…Ù„Ù Ø¢Ø®Ø±")
    
    # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø³Ù…
    if details['name_duplicates']:
        print(f"\nğŸ“‹ Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø³Ù… (Ø£ÙˆÙ„ 5):")
        for i, (filename, files) in enumerate(list(details['name_duplicates'].items())[:5]):
            if len(files) > 1:
                print(f"\n  {filename} ({len(files)} Ù…ÙˆÙ‚Ø¹):")
                for file in files[:3]:
                    print(f"    - {file}")
                if len(files) > 3:
                    print(f"    - ... Ùˆ {len(files) - 3} Ù…ÙˆÙ‚Ø¹ Ø¢Ø®Ø±")
    
    # Ù…Ù„ÙØ§Øª __init__.py Ø§Ù„ÙØ§Ø±ØºØ©
    if details['init_analysis']['empty_files']:
        print(f"\nğŸ“ Ù…Ù„ÙØ§Øª __init__.py ÙØ§Ø±ØºØ© (Ø£ÙˆÙ„ 10):")
        for file in details['init_analysis']['empty_files'][:10]:
            print(f"  - {file}")
        
        remaining = len(details['init_analysis']['empty_files']) - 10
        if remaining > 0:
            print(f"  - ... Ùˆ {remaining} Ù…Ù„Ù Ø¢Ø®Ø±")

def generate_cleanup_actions(report):
    """ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©"""
    actions = []
    
    details = report['details']
    
    # Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù„Ù„Ù…ÙƒØ±Ø±Ø§Øª Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    for file_hash, files in details['content_duplicates'].items():
        if len(files) > 1:
            # ØªØ­Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù„Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡
            best_file = select_best_file(files)
            
            actions.append({
                'type': 'merge_content_duplicates',
                'keep': best_file,
                'remove': [f for f in files if f != best_file],
                'reason': 'Ù†ÙØ³ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¶Ø¨Ø·'
            })
    
    # Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù„Ù…Ù„ÙØ§Øª __init__.py Ø§Ù„ÙØ§Ø±ØºØ© (Ù…Ø¹Ø¸Ù…Ù‡Ø§ ØµØ­ÙŠØ­)
    empty_inits = details['init_analysis']['empty_files']
    if len(empty_inits) > 50:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ§Ø±ØºØ©
        actions.append({
            'type': 'review_empty_inits',
            'files': empty_inits,
            'reason': 'Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ù…Ù„ÙØ§Øª __init__.py ÙØ§Ø±ØºØ© - Ù‚Ø¯ ØªÙƒÙˆÙ† Ø·Ø¨ÙŠØ¹ÙŠØ© Ø£Ùˆ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©'
        })
    
    return actions

def select_best_file(files):
    """Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ù„Ù Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"""
    # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ src/ Ø¹Ù„Ù‰ scripts/
    # ØªÙØ¶ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª Ø£Ø¹Ù…Ù‚ (Ø£ÙƒØ«Ø± ØªØ®ØµØµØ§Ù‹)
    
    ranked = []
    for file in files:
        score = 0
        
        # Ø§Ù„Ù…Ù„Ù ÙÙŠ src/
        if 'src/' in file:
            score += 10
        
        # Ù„ÙŠØ³ ÙÙŠ scripts/
        if 'scripts/' not in file:
            score += 5
        
        # Ø¹Ù…Ù‚ Ø§Ù„Ù…Ø¬Ù„Ø¯
        score += file.count('/')
        
        # Ù„ÙŠØ³ test file
        if 'test' not in file.lower():
            score += 3
        
        ranked.append((score, file))
    
    ranked.sort(reverse=True)
    return ranked[0][1]

def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    
    print("ğŸš€ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ù…ÙƒØ±Ø±Ø© Ø¥Ø¶Ø§ÙÙŠØ©...")
    
    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = generate_duplicate_report()
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ
    print_duplicate_summary(report)
    
    # ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    actions = generate_cleanup_actions(report)
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„
    report_file = f"additional_duplicates_report_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # Ø­ÙØ¸ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    actions_file = f"cleanup_actions_{timestamp}.json"
    with open(actions_file, 'w', encoding='utf-8') as f:
        json.dump(actions, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {report_file}")
    print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙÙŠ: {actions_file}")
    
    # Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©
    print(f"\nğŸ’¡ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
    if report['summary']['content_duplicates'] > 0:
        print(f"1. Ù…Ø±Ø§Ø¬Ø¹Ø© {report['summary']['content_duplicates']} Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª")
    if report['summary']['init_files_empty'] > 20:
        print(f"2. Ù…Ø±Ø§Ø¬Ø¹Ø© {report['summary']['init_files_empty']} Ù…Ù„Ù __init__.py ÙØ§Ø±Øº")
    if report['summary']['test_duplicates'] > 0:
        print(f"3. Ù…Ø±Ø§Ø¬Ø¹Ø© {report['summary']['test_duplicates']} Ù…ÙƒØ±Ø± ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª")

if __name__ == "__main__":
    main() 