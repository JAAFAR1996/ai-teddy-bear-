apiVersion: v1
kind: Namespace
metadata:
  name: ai-teddy-observability
  labels:
    name: ai-teddy-observability
    monitoring: enabled
    
---
# OpenTelemetry Collector Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: ai-teddy-observability
  labels:
    app: otel-collector
    component: observability
spec:
  replicas: 3
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
        component: observability
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8888"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.89.0
        command:
          - "/otelcol-contrib"
          - "--config=/conf/otel-collector-config.yaml"
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /conf
        - name: otel-collector-secrets
          mountPath: /etc/ssl/certs
          readOnly: true
        ports:
        - containerPort: 1777  # pprof
        - containerPort: 8888  # Prometheus metrics
        - containerPort: 8889  # Prometheus exporter
        - containerPort: 13133 # health_check
        - containerPort: 4317  # OTLP gRPC
        - containerPort: 4318  # OTLP HTTP
        - containerPort: 14250 # Jaeger gRPC
        - containerPort: 14268 # Jaeger HTTP
        - containerPort: 8006  # Fluent Forward
        - containerPort: 55679 # zpages
        env:
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 200m
            memory: 400Mi
        livenessProbe:
          httpGet:
            path: /
            port: 13133
        readinessProbe:
          httpGet:
            path: /
            port: 13133
      volumes:
      - name: otel-collector-config-vol
        configMap:
          name: observability-stack
          items:
          - key: otel-collector-config.yaml
            path: otel-collector-config.yaml
      - name: otel-collector-secrets
        secret:
          secretName: otel-collector-certs

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: ai-teddy-observability
  labels:
    app: otel-collector
    component: observability
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
spec:
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: jaeger-grpc
    port: 14250
    targetPort: 14250
    protocol: TCP
  - name: jaeger-http
    port: 14268
    targetPort: 14268
    protocol: TCP
  - name: prometheus-exporter
    port: 8889
    targetPort: 8889
    protocol: TCP
  - name: metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
  selector:
    app: otel-collector

---
# Prometheus Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
        component: observability
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.47.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus/'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--storage.tsdb.retention.time=30d'
          - '--storage.tsdb.retention.size=50GB'
          - '--web.enable-lifecycle'
          - '--web.enable-admin-api'
          - '--query.max-concurrency=50'
          - '--query.max-samples=50000000'
        ports:
        - containerPort: 9090
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 500m
            memory: 2Gi
        volumeMounts:
        - name: prometheus-config-volume
          mountPath: /etc/prometheus/
        - name: prometheus-rules-volume
          mountPath: /etc/prometheus/rules/
        - name: prometheus-storage-volume
          mountPath: /prometheus/
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          timeoutSeconds: 30
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 30
          timeoutSeconds: 30
      volumes:
      - name: prometheus-config-volume
        configMap:
          defaultMode: 420
          name: prometheus-config
      - name: prometheus-rules-volume
        configMap:
          defaultMode: 420
          name: prometheus-alert-rules
      - name: prometheus-storage-volume
        persistentVolumeClaim:
          claimName: prometheus-storage

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability
spec:
  selector:
    app: prometheus
  type: ClusterIP
  ports:
  - name: prometheus
    protocol: TCP
    port: 9090
    targetPort: 9090

---
# Grafana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: ai-teddy-observability
  labels:
    app: grafana
    component: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
        component: observability
    spec:
      securityContext:
        fsGroup: 472
        supplementalGroups:
          - 0
      containers:
      - name: grafana
        image: grafana/grafana:10.1.0
        ports:
        - containerPort: 3000
          name: http-grafana
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /robots.txt
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 2
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 3000
          timeoutSeconds: 1
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 250m
            memory: 750Mi
        volumeMounts:
        - mountPath: /var/lib/grafana
          name: grafana-pv
        - mountPath: /etc/grafana/provisioning/datasources
          name: grafana-datasources
          readOnly: false
        - mountPath: /etc/grafana/provisioning/dashboards
          name: grafana-dashboards
          readOnly: false
        - mountPath: /grafana-dashboard-definitions/0/ai-teddy-dashboards
          name: grafana-dashboard-ai-teddy
          readOnly: false
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: admin
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-credentials
              key: admin-password
        - name: GF_USERS_ALLOW_SIGN_UP
          value: "false"
        - name: GF_INSTALL_PLUGINS
          value: grafana-piechart-panel,grafana-worldmap-panel,grafana-clock-panel
      volumes:
      - name: grafana-pv
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-datasources
        configMap:
          defaultMode: 420
          name: grafana-datasources
      - name: grafana-dashboards
        configMap:
          defaultMode: 420
          name: grafana-dashboards-config
      - name: grafana-dashboard-ai-teddy
        configMap:
          defaultMode: 420
          name: grafana-dashboard-ai-teddy

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: ai-teddy-observability
  labels:
    app: grafana
    component: observability
spec:
  ports:
  - port: 3000
    protocol: TCP
    targetPort: http-grafana
  selector:
    app: grafana
  sessionAffinity: None
  type: LoadBalancer

---
# Jaeger Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: ai-teddy-observability
  labels:
    app: jaeger
    component: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
        component: observability
    spec:
      containers:
      - env:
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: :9411
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: SPAN_STORAGE_TYPE
          value: elasticsearch
        - name: ES_SERVER_URLS
          value: http://elasticsearch.observability:9200
        - name: ES_INDEX_PREFIX
          value: jaeger
        - name: JAEGER_DISABLED
          value: "false"
        image: jaegertracing/all-in-one:1.49.0
        name: jaeger
        ports:
        - containerPort: 5775
          protocol: UDP
        - containerPort: 6831
          protocol: UDP
        - containerPort: 6832
          protocol: UDP
        - containerPort: 5778
          protocol: TCP
        - containerPort: 16686
          protocol: TCP
        - containerPort: 14268
          protocol: TCP
        - containerPort: 14250
          protocol: TCP
        - containerPort: 9411
          protocol: TCP
        readinessProbe:
          httpGet:
            path: "/"
            port: 14269
          initialDelaySeconds: 5
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 200m
            memory: 512Mi

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-query
  namespace: ai-teddy-observability
  labels:
    app: jaeger
    component: query
spec:
  ports:
  - name: query-http
    port: 16686
    protocol: TCP
    targetPort: 16686
  selector:
    app: jaeger
  type: LoadBalancer

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-collector
  namespace: ai-teddy-observability
  labels:
    app: jaeger
    component: collector
spec:
  ports:
  - name: jaeger-collector-tchannel
    port: 14267
    protocol: TCP
    targetPort: 14267
  - name: jaeger-collector-http
    port: 14268
    protocol: TCP
    targetPort: 14268
  - name: jaeger-collector-grpc
    port: 14250
    protocol: TCP
    targetPort: 14250
  - name: jaeger-collector-zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  selector:
    app: jaeger
  type: ClusterIP

---
# Loki Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: ai-teddy-observability
  labels:
    app: loki
    component: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
        component: observability
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.0
        args:
        - -config.file=/etc/loki/local-config.yaml
        ports:
        - containerPort: 3100
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 200m
            memory: 512Mi
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
        - name: loki-storage
          mountPath: /loki
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
      - name: loki-storage
        persistentVolumeClaim:
          claimName: loki-storage

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: ai-teddy-observability
  labels:
    app: loki
    component: observability
spec:
  ports:
  - port: 3100
    protocol: TCP
    targetPort: 3100
    name: http
  selector:
    app: loki

---
# AlertManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: ai-teddy-observability
  labels:
    app: alertmanager
    component: observability
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
        component: observability
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        args:
          - '--config.file=/etc/alertmanager/config.yml'
          - '--storage.path=/alertmanager'
          - '--web.external-url=http://alertmanager.ai-teddy.local'
          - '--cluster.listen-address=0.0.0.0:9094'
          - '--cluster.peer=alertmanager-1.alertmanager.ai-teddy-observability.svc.cluster.local:9094'
          - '--cluster.peer=alertmanager-2.alertmanager.ai-teddy-observability.svc.cluster.local:9094'
        ports:
        - containerPort: 9093
        - containerPort: 9094
        resources:
          limits:
            cpu: 500m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager
        - name: alertmanager-storage
          mountPath: /alertmanager
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 30
          timeoutSeconds: 30
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 30
          timeoutSeconds: 30
      volumes:
      - name: alertmanager-config
        configMap:
          name: alertmanager-config
      - name: alertmanager-storage
        persistentVolumeClaim:
          claimName: alertmanager-storage

---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: ai-teddy-observability
  labels:
    app: alertmanager
    component: observability
spec:
  ports:
  - port: 9093
    protocol: TCP
    targetPort: 9093
    name: web
  - port: 9094
    protocol: TCP
    targetPort: 9094
    name: cluster
  selector:
    app: alertmanager

---
# Service Accounts
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: ai-teddy-observability
  labels:
    app: otel-collector
    component: observability

---
# ClusterRole for Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
  labels:
    app: prometheus
    component: observability
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
  labels:
    app: prometheus
    component: observability
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: ai-teddy-observability

---
# ClusterRole for OpenTelemetry Collector
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
  labels:
    app: otel-collector
    component: observability
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
  labels:
    app: otel-collector
    component: observability
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: ai-teddy-observability

---
# Persistent Volume Claims
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-pvc
  namespace: ai-teddy-observability
  labels:
    app: grafana
    component: observability
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-storage
  namespace: ai-teddy-observability
  labels:
    app: loki
    component: observability
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage
  namespace: ai-teddy-observability
  labels:
    app: alertmanager
    component: observability
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: standard

---
# Network Policies for Security
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: observability-network-policy
  namespace: ai-teddy-observability
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ai-teddy-production
    - namespaceSelector:
        matchLabels:
          name: ai-teddy-staging
    - namespaceSelector:
        matchLabels:
          name: ai-teddy-observability
    ports:
    - protocol: TCP
      port: 9090  # Prometheus
    - protocol: TCP
      port: 3000  # Grafana
    - protocol: TCP
      port: 16686 # Jaeger UI
    - protocol: TCP
      port: 3100  # Loki
    - protocol: TCP
      port: 9093  # AlertManager
    - protocol: TCP
      port: 4317  # OTLP gRPC
    - protocol: TCP
      port: 4318  # OTLP HTTP
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80

---
# HorizontalPodAutoscaler for high availability
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: otel-collector-hpa
  namespace: ai-teddy-observability
  labels:
    app: otel-collector
    component: observability
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: otel-collector
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: prometheus-hpa
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: prometheus
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

---
# Pod Disruption Budgets for high availability
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: prometheus-pdb
  namespace: ai-teddy-observability
  labels:
    app: prometheus
    component: observability
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: prometheus

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: otel-collector-pdb
  namespace: ai-teddy-observability
  labels:
    app: otel-collector
    component: observability
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: otel-collector

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: grafana-pdb
  namespace: ai-teddy-observability
  labels:
    app: grafana
    component: observability
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: grafana

---
# Additional ConfigMaps
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: ai-teddy-observability
data:
  local-config.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
    
    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    
    analytics:
      reporting_enabled: false
    
    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 50
      ingestion_burst_size_mb: 100

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: ai-teddy-observability
data:
  config.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@ai-teddy.com'
      smtp_auth_username: 'alertmanager@ai-teddy.com'
      smtp_auth_password: 'password'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'child-safety-team'
        group_wait: 5s
        repeat_interval: 5m
      - match:
          team: child-safety
        receiver: 'child-safety-team'
        group_wait: 5s
        repeat_interval: 5m
      - match:
          team: emergency-response
        receiver: 'emergency-team'
        group_wait: 1s
        repeat_interval: 1m
      - match:
          page: "true"
        receiver: 'pager-duty'
        group_wait: 5s
        repeat_interval: 5m
    
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://127.0.0.1:5001/'
    
    - name: 'child-safety-team'
      email_configs:
      - to: 'child-safety@ai-teddy.com'
        subject: 'CRITICAL: Child Safety Alert - {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Impact: {{ .Annotations.impact }}
          Action Required: {{ .Annotations.action }}
          {{ end }}
      slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'
        channel: '#child-safety-alerts'
        title: 'CRITICAL Child Safety Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        color: 'danger'
    
    - name: 'emergency-team'
      email_configs:
      - to: 'emergency@ai-teddy.com'
        subject: 'EMERGENCY: {{ .GroupLabels.alertname }}'
        body: |
          EMERGENCY RESPONSE REQUIRED
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
      pagerduty_configs:
      - routing_key: 'YOUR_PAGERDUTY_INTEGRATION_KEY'
        description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        severity: 'critical'
    
    - name: 'pager-duty'
      pagerduty_configs:
      - routing_key: 'YOUR_PAGERDUTY_INTEGRATION_KEY'
        description: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-config
  namespace: ai-teddy-observability
data:
  dashboard.yaml: |
    apiVersion: 1
    providers:
    - name: 'ai-teddy-dashboards'
      orgId: 1
      folder: 'AI Teddy Bear'
      type: file
      disableDeletion: false
      updateIntervalSeconds: 10
      allowUiUpdates: true
      options:
        path: /grafana-dashboard-definitions/0/ai-teddy-dashboards 