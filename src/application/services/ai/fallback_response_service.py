"""
üõ°Ô∏è Fallback Response Service - Enterprise 2025 Implementation
Smart fallback responses for error handling and system resilience
"""

import random
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

from src.application.services.ai.models.ai_response_models import AIResponseModel
from src.domain.entities.child import Child

logger = logging.getLogger(__name__)

class FallbackResponseService:
    """
    üõ°Ô∏è Advanced fallback response service with:
    - Context-aware error responses
    - Smart recovery strategies
    - Cultural sensitivity
    - Learning opportunity creation
    """
    
    def __init__(self):
        self.fallback_responses = self._load_fallback_responses()
        self.usage_stats = {
            "rate_limit": 0,
            "timeout": 0,
            "api_error": 0,
            "generic_error": 0,
            "total_fallbacks": 0
        }
        
        logger.info("‚úÖ Fallback Response Service initialized")
    
    def _load_fallback_responses(self) -> Dict[str, Dict[str, List[str]]]:
        """Load comprehensive fallback response templates"""
        return {
            "rate_limit": {
                "story": [
                    "Ÿäÿß {name}ÿå ÿ£ŸÜÿß ŸÖÿ¥ÿ∫ŸàŸÑ ŸÇŸÑŸäŸÑÿßŸã ÿßŸÑÿ¢ŸÜ! ÿ≥ÿ£ÿ≠ŸÉŸä ŸÑŸÉ ŸÇÿµÿ© ÿ¨ŸÖŸäŸÑÿ© ÿ®ÿπÿØ ŸÑÿ≠ÿ∏ÿ©! üìö‚ú®",
                    "ÿØÿπŸÜŸä ÿ£ÿ¨ŸÖÿπ ÿ£ŸÅŸÉÿßÿ±Ÿä Ÿäÿß {name} Ÿàÿ≥ÿ£ÿπŸàÿØ ÿ®ŸÇÿµÿ© ÿ±ÿßÿ¶ÿπÿ©! üåüüìñ"
                ],
                "play": [
                    "Ÿäÿß {name}ÿå ÿØÿπŸÜŸä ÿ£ÿ±ÿ™ÿßÿ≠ ŸÑÿ´ÿßŸÜŸäÿ© Ÿàÿ≥ŸÜŸÑÿπÿ® ŸÑÿπÿ®ÿ© ÿ±ÿßÿ¶ÿπÿ©! üéÆüß∏",
                    "ÿ™ÿπÿßŸÑ ŸÜŸÑÿπÿ® ÿ®ÿπÿØ ŸÇŸÑŸäŸÑ Ÿäÿß {name}! ÿ≥ÿ£ÿ≠ÿ∂ÿ± ŸÑÿπÿ®ÿ© ÿ¨ÿØŸäÿØÿ©! üéØ‚≠ê"
                ],
                "question": [
                    "ÿ≥ÿ§ÿßŸÑ ŸÖŸÖÿ™ÿßÿ≤ Ÿäÿß {name}! ÿØÿπŸÜŸä ÿ£ŸÅŸÉÿ± Ÿàÿ≥ÿ£ÿ¨Ÿäÿ®ŸÉ ÿ®ÿπÿØ ŸÑÿ≠ÿ∏ÿ©! ü§îüí≠",
                    "ÿ£ÿ≠ÿ® ŸÅÿ∂ŸàŸÑŸÉ Ÿäÿß {name}! ÿ≥ÿ£ÿ®ÿ≠ÿ´ ÿπŸÜ ÿ•ÿ¨ÿßÿ®ÿ© ÿ±ÿßÿ¶ÿπÿ©! üîç‚ú®"
                ],
                "general": [
                    "ÿµÿ®ÿ±ÿßŸã Ÿäÿß {name}ÿå ÿ≥ÿ£ÿπŸàÿØ ÿ•ŸÑŸäŸÉ ÿ®ÿπÿØ ŸÑÿ≠ÿ∏ÿ©! üß∏üí´",
                    "ÿ£ÿ≠ÿ™ÿßÿ¨ ÿØŸÇŸäŸÇÿ© Ÿàÿßÿ≠ÿØÿ© Ÿäÿß {name}! üïêüåü"
                ]
            },
            "timeout": {
                "encouraging": [
                    "Ÿäÿß {name}ÿå ÿßÿ≥ÿ™ÿ∫ÿ±ŸÇ ÿßŸÑÿ£ŸÖÿ± ŸàŸÇÿ™ÿßŸã ÿ£ÿ∑ŸàŸÑ ŸÖŸÖÿß ÿ™ŸàŸÇÿπÿ™! ÿ≠ÿßŸàŸÑ ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ! üîÑüß∏",
                    "ÿ£ÿπÿ™ÿ∞ÿ± ŸÑŸÑÿ™ÿ£ÿÆŸäÿ± Ÿäÿß {name}! ÿØÿπŸÜÿß ŸÜÿ≠ÿßŸàŸÑ ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ! üîÅüí™"
                ],
                "playful": [
                    "Ÿäÿ®ÿØŸà ÿ£ŸÜŸÜŸä ÿ£ÿ®ÿ∑ÿ£ ŸÖŸÜ ÿßŸÑÿ≥ŸÑÿ≠ŸÅÿßÿ© ÿßŸÑŸäŸàŸÖ Ÿäÿß {name}! üê¢üòÖ",
                    "ÿπÿ∞ÿ±ÿßŸã Ÿäÿß {name}ÿå ŸÉŸÜÿ™ ÿ£ÿ≠ŸÑŸÖ ÿ®ÿßŸÑÿπÿ≥ŸÑ! ÿØÿπŸÜÿß ŸÜÿπŸäÿØ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ©! üçØüò¥"
                ]
            },
            "api_error": {
                "story_context": [
                    "Ÿäÿß {name}ÿå ÿØÿπŸÜŸä ÿ£ÿ≠ŸÉŸä ŸÑŸÉ ŸÇÿµÿ© ÿ®ÿ≥Ÿäÿ∑ÿ©... ŸÉÿßŸÜ Ÿäÿß ŸÖÿß ŸÉÿßŸÜÿå ÿ∑ŸÅŸÑ ÿ±ÿßÿ¶ÿπ ÿßÿ≥ŸÖŸá {name}! üìñ‚ú®",
                    "ŸáŸÑ ÿ™ÿ±ŸäÿØ ŸÇÿµÿ© Ÿäÿß {name}ÿü ÿ£ÿπÿ±ŸÅ ŸÇÿµÿ© ÿπŸÜ ÿØÿ® ÿµÿ∫Ÿäÿ± ÿ¥ÿ¨ÿßÿπ ŸÖÿ´ŸÑŸÉ! üêªüåü"
                ],
                "play_context": [
                    "Ÿäÿß {name}ÿå ÿ™ÿπÿßŸÑ ŸÜŸÑÿπÿ® ŸÑÿπÿ®ÿ© ÿßŸÑŸÉŸÑŸÖÿßÿ™! ŸÇŸÑ ŸÑŸä ÿßÿ≥ŸÖ ÿ≠ŸäŸàÿßŸÜ! üêæüéÆ",
                    "ŸáŸäÿß ŸÜŸÑÿπÿ® Ÿäÿß {name}! ŸÖÿß ÿ±ÿ£ŸäŸÉ ŸÅŸä ŸÑÿπÿ®ÿ© ÿßŸÑÿ™ÿÆŸÖŸäŸÜÿü üîÆüéØ"
                ],
                "educational": [
                    "Ÿäÿß {name}ÿå ŸáŸÑ ÿ™ÿπÿ±ŸÅ ÿ£ŸÜ ÿßŸÑÿ£ŸÅŸäÿßŸÑ ÿ™ÿ≥ÿ™ÿ∑Ÿäÿπ ÿßŸÑÿ≥ÿ®ÿßÿ≠ÿ©ÿü üêòüíß",
                    "ŸÖÿπŸÑŸàŸÖÿ© ŸÖÿ´Ÿäÿ±ÿ© Ÿäÿß {name}: ÿßŸÑŸÜÿ¨ŸàŸÖ ÿ™ÿ∫ŸÜŸä ÿ£ÿ∫ÿßŸÜŸä ÿ¨ŸÖŸäŸÑÿ© ŸÅŸä ÿßŸÑÿ≥ŸÖÿßÿ°! ‚≠êüéµ"
                ],
                "general": [
                    "Ÿäÿß {name}ÿå Ÿáÿ∞ÿß ŸÖÿ´Ÿäÿ± ŸÑŸÑÿßŸáÿ™ŸÖÿßŸÖ! ÿ≠ÿØÿ´ŸÜŸä ÿ£ŸÉÿ´ÿ± ÿπŸÖÿß ÿ™ŸÅŸÉÿ± ŸÅŸäŸá! ü§îüí≠",
                    "ÿ£ÿ≠ÿ® ÿßŸÑÿ≠ÿØŸäÿ´ ŸÖÿπŸÉ Ÿäÿß {name}! ŸÖÿß ÿßŸÑÿ¥Ÿäÿ° ÿßŸÑÿ¨ŸÖŸäŸÑ ÿßŸÑÿ∞Ÿä ÿ≠ÿØÿ´ ŸÖÿπŸÉ ÿßŸÑŸäŸàŸÖÿü üåüüó£Ô∏è"
                ]
            },
            "generic_error": {
                "positive": [
                    "Ÿäÿß {name}ÿå ÿ£ÿ≠ÿ® ÿßŸÑÿ≠ÿØŸäÿ´ ŸÖÿπŸÉ! ÿ£ÿÆÿ®ÿ±ŸÜŸäÿå ŸÖÿß ÿßŸÑÿ¥Ÿäÿ° ÿßŸÑŸÖŸÅÿ∂ŸÑ ŸÑÿØŸäŸÉ ÿßŸÑŸäŸàŸÖÿü üåüüß∏",
                    "ÿ£ŸÜÿ™ ŸÖŸÖŸäÿ≤ Ÿäÿß {name}! ÿØÿπŸÜÿß ŸÜÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿ¥Ÿäÿ° Ÿäÿ¨ÿπŸÑŸÉ ÿ≥ÿπŸäÿØÿßŸã! üåàüòä"
                ],
                "curious": [
                    "Ÿäÿß {name}ÿå ÿπŸÇŸÑŸÉ ŸÖŸÑŸäÿ° ÿ®ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿßŸÑÿ±ÿßÿ¶ÿπÿ©! ÿ¥ÿßÿ±ŸÉŸÜŸä Ÿàÿßÿ≠ÿØÿ© ŸÖŸÜŸáÿß! üß†‚ú®",
                    "ŸÅÿ∂ŸàŸÑŸÉ ÿ±ÿßÿ¶ÿπ Ÿäÿß {name}! ŸÖÿß ÿßŸÑÿ∞Ÿä ÿ™ŸàÿØ ÿ£ŸÜ ÿ™ÿπÿ±ŸÅŸá ÿßŸÑŸäŸàŸÖÿü üîçüåü"
                ]
            }
        }
    
    async def create_rate_limit_fallback(
        self,
        message: str,
        child: Child,
        session_id: str
    ) -> AIResponseModel:
        """üö¶ Create smart rate limit fallback response"""
        self.usage_stats["rate_limit"] += 1
        self.usage_stats["total_fallbacks"] += 1
        
        context = self._detect_message_context(message.lower())
        responses = self.fallback_responses["rate_limit"].get(context, 
                    self.fallback_responses["rate_limit"]["general"])
        
        response_text = random.choice(responses).format(name=child.name)
        
        learning_points = ["patience", "understanding", "resilience"]
        if context == "question":
            learning_points.append("curiosity")
        elif context == "story":
            learning_points.append("imagination")
        elif context == "play":
            learning_points.append("creativity")
        
        return AIResponseModel(
            text=response_text,
            emotion="encouraging",
            category="system_message",
            learning_points=learning_points,
            session_id=session_id,
            confidence=0.8,
            processing_time_ms=5,
            error="rate_limit"
        )
    
    async def create_timeout_fallback(
        self,
        message: str,
        child: Child,
        session_id: str
    ) -> AIResponseModel:
        """‚è∞ Create smart timeout fallback response"""
        self.usage_stats["timeout"] += 1
        self.usage_stats["total_fallbacks"] += 1
        
        response_style = "playful" if child.age <= 5 else "encouraging"
        responses = self.fallback_responses["timeout"].get(response_style,
                    self.fallback_responses["timeout"]["encouraging"])
        
        response_text = random.choice(responses).format(name=child.name)
        
        return AIResponseModel(
            text=response_text,
            emotion="patient",
            category="system_message",
            learning_points=["patience", "persistence", "trying_again"],
            session_id=session_id,
            confidence=0.7,
            processing_time_ms=8,
            error="timeout"
        )
    
    async def create_api_error_fallback(
        self,
        message: str,
        child: Child,
        session_id: str,
        error_details: str
    ) -> AIResponseModel:
        """üîß Create smart API error fallback response"""
        self.usage_stats["api_error"] += 1
        self.usage_stats["total_fallbacks"] += 1
        
        context = self._detect_message_context(message.lower())
        
        if context == "story":
            response_category = "story_context"
            emotion = "storytelling"
            learning_points = ["imagination", "creativity", "storytelling"]
        elif context == "play":
            response_category = "play_context"
            emotion = "playful"
            learning_points = ["creativity", "play", "interaction"]
        elif context == "question":
            response_category = "educational"
            emotion = "educational"
            learning_points = ["learning", "curiosity", "knowledge"]
        else:
            response_category = "general"
            emotion = "friendly"
            learning_points = ["communication", "friendship"]
        
        responses = self.fallback_responses["api_error"][response_category]
        response_text = random.choice(responses).format(name=child.name)
        
        return AIResponseModel(
            text=response_text,
            emotion=emotion,
            category="fallback",
            learning_points=learning_points,
            session_id=session_id,
            confidence=0.75,
            processing_time_ms=10,
            error=f"api_error: {error_details[:50]}..."
        )
    
    async def create_generic_fallback(
        self,
        message: str,
        child: Child,
        session_id: str,
        error_details: str
    ) -> AIResponseModel:
        """üõ†Ô∏è Create generic fallback response"""
        self.usage_stats["generic_error"] += 1
        self.usage_stats["total_fallbacks"] += 1
        
        question_words = ["ŸÉŸäŸÅ", "ŸÑŸÖÿßÿ∞ÿß", "ŸÖÿßÿ∞ÿß", "why", "how", "what"]
        response_style = "curious" if any(word in message.lower() for word in question_words) else "positive"
        
        responses = self.fallback_responses["generic_error"][response_style]
        response_text = random.choice(responses).format(name=child.name)
        
        return AIResponseModel(
            text=response_text,
            emotion="supportive",
            category="conversation",
            learning_points=["social_interaction", "communication"],
            session_id=session_id,
            confidence=0.6,
            processing_time_ms=5,
            error=f"generic_error: {error_details[:50]}..."
        )
    
    def _detect_message_context(self, message_lower: str) -> str:
        """üîç Detect message context for appropriate fallback"""
        context_patterns = {
            "story": ["ŸÇÿµÿ©", "story", "ÿ≠ŸÉÿßŸäÿ©", "ÿßÿ≠ŸÉŸä", "ÿ≠ÿØÿ´ŸÜŸä"],
            "play": ["ŸÑÿπÿ®", "play", "game", "ŸÜŸÑÿπÿ®", "ÿßŸÑÿπÿ®"],
            "question": ["?", "ÿü", "ŸÉŸäŸÅ", "ŸÑŸÖÿßÿ∞ÿß", "ŸÖÿ™Ÿâ", "ÿ£ŸäŸÜ", "ŸÖÿßÿ∞ÿß"],
            "music": ["ÿ∫ŸÜÿßÿ°", "sing", "ÿ£ÿ∫ŸÜŸäÿ©", "ŸÖŸàÿ≥ŸäŸÇŸâ"],
            "learning": ["ÿ™ÿπŸÑŸÖ", "learn", "ÿØÿ±ÿ≥", "ÿπŸÑŸÖŸÜŸä"]
        }
        
        for context, keywords in context_patterns.items():
            if any(keyword in message_lower for keyword in keywords):
                return context
        
        return "general"
    
    def get_usage_statistics(self) -> Dict[str, Any]:
        """üìä Get fallback usage statistics"""
        total = self.usage_stats["total_fallbacks"]
        
        return {
            "total_fallbacks_used": total,
            "rate_limit_fallbacks": self.usage_stats["rate_limit"],
            "timeout_fallbacks": self.usage_stats["timeout"],
            "api_error_fallbacks": self.usage_stats["api_error"],
            "generic_error_fallbacks": self.usage_stats["generic_error"],
            "fallback_distribution": {
                "rate_limit_percentage": (self.usage_stats["rate_limit"] / total * 100) if total > 0 else 0,
                "timeout_percentage": (self.usage_stats["timeout"] / total * 100) if total > 0 else 0,
                "api_error_percentage": (self.usage_stats["api_error"] / total * 100) if total > 0 else 0,
                "generic_error_percentage": (self.usage_stats["generic_error"] / total * 100) if total > 0 else 0
            }
        } 