#!/usr/bin/env python3
"""
ğŸš€ Simple Usage Examples for LLM Services
Ø£Ù…Ø«Ù„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø§Øª LLM

This file demonstrates the new simplified interface for easy LLM usage.
"""

import asyncio
import sys
import os

# Add parent directory to path for standalone operation
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

try:
    from src.application.services.ai import generate_simple, LLMServiceFactory, GenerationRequest
except ImportError:
    # If running standalone, import directly
    from llm_service_factory import generate_simple, LLMServiceFactory, GenerationRequest


async def example_super_simple():
    """Ù…Ø«Ø§Ù„ ÙØ§Ø¦Ù‚ Ø§Ù„Ø¨Ø³Ø§Ø·Ø© - Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·"""
    print("ğŸš€ Super Simple Example:")
    
    # Note: This would work with real LLM providers
    print("  This would call: await generate_simple('What is the capital of France?')")
    print("  Response: Paris (simulated)")


async def example_simple_with_options():
    """Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ· Ù…Ø¹ Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"""
    print("\nğŸ¯ Simple with Options Example:")
    
    # Note: This would work with real LLM providers
    print("  This would call: await generate_simple(...)")
    print("  Response: Quantum computing explanation (simulated)")


async def example_comparison():
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    print("\nğŸ†š Interface Comparison:")
    
    # 1. Super Simple Interface (simulated)
    print("1. Super Simple:")
    print("   Result: Simulated response about Python...")
    
    # 2. Production Interface (simulated)
    print("\n2. Production Interface:")
    print("   Result: Simulated production response...")


async def main():
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø©"""
    print("ğŸ§ª Testing LLM Simplified Interface\n")
    
    try:
        await example_super_simple()
        await example_simple_with_options() 
        await example_comparison()
        
        print("\nâœ… All examples completed successfully!")
        print("Note: These are simulated responses.")
        print("With real LLM providers, you would get actual AI responses.")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 