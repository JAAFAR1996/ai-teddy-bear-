# ===================================================================
# ğŸ§¸ AI Teddy Bear - Performance Monitoring System
# Enterprise ML Performance Monitoring & Alerting
# ML Team Lead: Senior ML Engineer
# Date: January 2025
# ===================================================================

import asyncio
import logging
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import json
import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


class AlertSeverity(Enum):
    """Ù…Ø³ØªÙˆÙ‰ Ø®Ø·ÙˆØ±Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class MetricType(Enum):
    """Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³"""
    PERFORMANCE = "performance"
    SAFETY = "safety"
    SATISFACTION = "satisfaction"
    TECHNICAL = "technical"
    BUSINESS = "business"


@dataclass
class PerformanceAlert:
    """ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    alert_id: str
    timestamp: datetime
    severity: AlertSeverity
    metric_name: str
    current_value: float
    threshold_value: float
    message: str
    affected_models: List[str]
    recommended_actions: List[str]
    auto_resolved: bool = False


@dataclass
class MetricSnapshot:
    """Ù„Ù‚Ø·Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
    timestamp: datetime
    model_id: str
    metrics: Dict[str, float]
    health_score: float
    anomalies_detected: List[str]


class PerformanceMonitor:
    """Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.active_monitors: Dict[str, Dict[str, Any]] = {}
        self.metric_history: List[MetricSnapshot] = []
        self.active_alerts: List[PerformanceAlert] = []
        self.alert_rules = self._initialize_alert_rules()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ø¸Ù… Ø§Ù„ÙØ±Ø¹ÙŠØ©
        self.metrics_collector = self._initialize_metrics_collector()
        self.anomaly_detector = self._initialize_anomaly_detector()
        self.alerting_system = self._initialize_alerting_system()
        
        logger.info("ğŸ“Š Performance Monitor initialized")
    
    async def start_deployment_monitoring(self, deployment_id: str, 
                                        models: Dict[str, Any],
                                        monitoring_duration_hours: int = 48) -> None:
        """Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø´Ø±"""
        
        logger.info(f"ğŸ‘ï¸ Starting deployment monitoring for {deployment_id}")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù„Ù„Ù†Ø´Ø±
        monitoring_config = {
            'deployment_id': deployment_id,
            'models': models,
            'start_time': datetime.utcnow(),
            'duration_hours': monitoring_duration_hours,
            'check_interval_seconds': 60,
            'alert_thresholds': self._get_deployment_alert_thresholds(),
            'baseline_metrics': await self._establish_baseline_metrics(models)
        }
        
        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
        monitoring_task = asyncio.create_task(
            self._deployment_monitoring_loop(monitoring_config)
        )
        
        self.active_monitors[deployment_id] = {
            'config': monitoring_config,
            'task': monitoring_task,
            'status': 'active'
        }
    
    async def _deployment_monitoring_loop(self, config: Dict[str, Any]) -> None:
        """Ø­Ù„Ù‚Ø© Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø´Ø±"""
        
        deployment_id = config['deployment_id']
        start_time = config['start_time']
        duration = timedelta(hours=config['duration_hours'])
        check_interval = config['check_interval_seconds']
        
        logger.info(f"ğŸ”„ Starting monitoring loop for {deployment_id}")
        
        while datetime.utcnow() - start_time < duration:
            try:
                # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                current_metrics = await self._collect_current_metrics(config['models'])
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù„Ù‚Ø·Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                for model_id, metrics in current_metrics.items():
                    snapshot = MetricSnapshot(
                        timestamp=datetime.utcnow(),
                        model_id=model_id,
                        metrics=metrics,
                        health_score=await self._calculate_health_score(metrics),
                        anomalies_detected=await self._detect_anomalies(model_id, metrics)
                    )
                    
                    self.metric_history.append(snapshot)
                    
                    # ÙØ­Øµ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
                    await self._check_alert_conditions(deployment_id, snapshot, config)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                await self._cleanup_old_metrics()
                
                # Ø§Ù„Ù†ÙˆÙ… Ø­ØªÙ‰ Ø§Ù„ÙØ­Øµ Ø§Ù„ØªØ§Ù„ÙŠ
                await asyncio.sleep(check_interval)
                
            except Exception as e:
                logger.error(f"Error in monitoring loop for {deployment_id}: {str(e)}")
                await asyncio.sleep(check_interval)
        
        # Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
        await self._finalize_deployment_monitoring(deployment_id)
        logger.info(f"âœ… Monitoring completed for {deployment_id}")
    
    async def _collect_current_metrics(self, models: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
        """Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        
        current_metrics = {}
        
        for model_id, model_data in models.items():
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø©
            metrics = await self._simulate_model_metrics(model_id, model_data)
            current_metrics[model_id] = metrics
        
        return current_metrics
    
    async def _simulate_model_metrics(self, model_id: str, model_data: Any) -> Dict[str, float]:
        """Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ù‚Ø§ÙŠÙŠØ³ ÙˆØ§Ù‚Ø¹ÙŠØ© Ù…Ø¹ Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙˆØ¶ÙˆØ¶Ø§Ø¡
        base_metrics = {
            'safety_score': 0.96,
            'child_satisfaction': 0.83,
            'response_time_ms': 750,
            'accuracy': 0.87,
            'throughput_rps': 95,
            'error_rate': 0.008,
            'memory_usage_mb': 512,
            'cpu_usage_percent': 45,
            'engagement_rate': 0.79,
            'learning_effectiveness': 0.74,
            'parent_approval': 0.86
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ ÙˆØ§Ù‚Ø¹ÙŠØ©
        current_metrics = {}
        for metric, base_value in base_metrics.items():
            if metric == 'response_time_ms':
                # ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© - ØªÙˆØ²ÙŠØ¹ Ø¬Ø§Ù…Ø§
                current_metrics[metric] = max(200, np.random.gamma(2, base_value/2))
            elif metric in ['error_rate']:
                # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ - ØªÙˆØ²ÙŠØ¹ Ø£Ø³ÙŠ
                current_metrics[metric] = max(0.001, np.random.exponential(base_value))
            elif metric in ['throughput_rps']:
                # Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© - ØªÙˆØ²ÙŠØ¹ Ø¨ÙˆØ§Ø³ÙˆÙ†
                current_metrics[metric] = max(50, np.random.poisson(base_value))
            elif metric in ['memory_usage_mb']:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© - ØªÙˆØ²ÙŠØ¹ Ø·Ø¨ÙŠØ¹ÙŠ
                current_metrics[metric] = max(256, np.random.normal(base_value, base_value * 0.1))
            elif metric in ['cpu_usage_percent']:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ - ØªÙˆØ²ÙŠØ¹ Ø¨ÙŠØªØ§ Ù…Ù‚ÙŠØ³
                current_metrics[metric] = np.random.beta(3, 5) * 100
            else:
                # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¬ÙˆØ¯Ø© - ØªÙˆØ²ÙŠØ¹ Ø¨ÙŠØªØ§
                alpha = base_value * 20
                beta = (1 - base_value) * 20
                current_metrics[metric] = np.random.beta(alpha, beta)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø²Ù…Ù†ÙŠØ© Ø·ÙÙŠÙØ©
        time_factor = (datetime.utcnow().minute % 60) / 60.0
        
        # ØªØ­Ø³Ù† Ø·ÙÙŠÙ Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        current_metrics['child_satisfaction'] *= (1 + time_factor * 0.02)
        current_metrics['accuracy'] *= (1 + time_factor * 0.01)
        
        # ØªØ¯Ù‡ÙˆØ± Ø·ÙÙŠÙ Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
        current_metrics['response_time_ms'] *= (1 + time_factor * 0.05)
        current_metrics['memory_usage_mb'] *= (1 + time_factor * 0.03)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø¯ÙˆØ¯
        for metric in current_metrics:
            if metric not in ['response_time_ms', 'throughput_rps', 'memory_usage_mb', 'cpu_usage_percent']:
                current_metrics[metric] = max(0, min(1, current_metrics[metric]))
        
        return current_metrics
    
    async def _calculate_health_score(self, metrics: Dict[str, float]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©"""
        
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        weights = {
            'safety_score': 0.25,
            'child_satisfaction': 0.20,
            'accuracy': 0.15,
            'parent_approval': 0.15,
            'response_time_ms': 0.10,  # Ù…Ø¹ÙƒÙˆØ³
            'error_rate': 0.10,        # Ù…Ø¹ÙƒÙˆØ³
            'engagement_rate': 0.05
        }
        
        weighted_score = 0
        total_weight = 0
        
        for metric, weight in weights.items():
            if metric in metrics:
                value = metrics[metric]
                
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø¹ÙƒÙˆØ³Ø©
                if metric == 'response_time_ms':
                    # ØªØ­ÙˆÙŠÙ„ ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ Ø¯Ø±Ø¬Ø© (Ø£Ù‚Ù„ = Ø£ÙØ¶Ù„)
                    normalized_value = max(0, 1 - (value - 500) / 1500)  # 500-2000ms range
                elif metric == 'error_rate':
                    # ØªØ­ÙˆÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¥Ù„Ù‰ Ø¯Ø±Ø¬Ø© (Ø£Ù‚Ù„ = Ø£ÙØ¶Ù„)
                    normalized_value = max(0, 1 - value / 0.1)  # 0-10% range
                else:
                    normalized_value = value
                
                weighted_score += normalized_value * weight
                total_weight += weight
        
        return weighted_score / total_weight if total_weight > 0 else 0.5
    
    async def _detect_anomalies(self, model_id: str, metrics: Dict[str, float]) -> List[str]:
        """ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° ÙÙŠ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
        
        anomalies = []
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        historical_data = [
            snapshot for snapshot in self.metric_history[-100:]  # Ø¢Ø®Ø± 100 Ù‚ÙŠØ§Ø³
            if snapshot.model_id == model_id
        ]
        
        if len(historical_data) < 10:
            return anomalies  # Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©
        
        # ÙØ­Øµ ÙƒÙ„ Ù…Ù‚ÙŠØ§Ø³ Ù„Ù„Ø´Ø°ÙˆØ°
        for metric_name, current_value in metrics.items():
            historical_values = [
                snapshot.metrics.get(metric_name, 0) 
                for snapshot in historical_data
            ]
            
            if len(historical_values) >= 10:
                mean_value = np.mean(historical_values)
                std_value = np.std(historical_values)
                
                # ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© 3-sigma
                if std_value > 0:
                    z_score = abs(current_value - mean_value) / std_value
                    
                    if z_score > 3:
                        anomalies.append(f"{metric_name}_anomaly")
                        logger.warning(f"ğŸš¨ Anomaly detected in {model_id}.{metric_name}: {current_value:.3f} (z-score: {z_score:.2f})")
                
                # ÙØ­Øµ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…ÙØ§Ø¬Ø¦Ø©
                if len(historical_values) >= 20:
                    recent_values = historical_values[-10:]
                    older_values = historical_values[-20:-10]
                    
                    recent_mean = np.mean(recent_values)
                    older_mean = np.mean(older_values)
                    
                    if older_mean > 0:
                        change_percentage = abs(recent_mean - older_mean) / older_mean
                        
                        if change_percentage > 0.2:  # ØªØºÙŠÙŠØ± Ø£ÙƒØ«Ø± Ù…Ù† 20%
                            anomalies.append(f"{metric_name}_trend_change")
                            logger.info(f"ğŸ“ˆ Trend change detected in {model_id}.{metric_name}: {change_percentage:.1%}")
        
        return anomalies
    
    async def _check_alert_conditions(self, deployment_id: str, 
                                    snapshot: MetricSnapshot,
                                    config: Dict[str, Any]) -> None:
        """ÙØ­Øµ Ø´Ø±ÙˆØ· Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        
        alert_thresholds = config['alert_thresholds']
        
        for rule_name, rule_config in self.alert_rules.items():
            if await self._evaluate_alert_rule(rule_name, rule_config, snapshot, alert_thresholds):
                await self._trigger_alert(deployment_id, rule_name, rule_config, snapshot)
    
    async def _evaluate_alert_rule(self, rule_name: str, 
                                 rule_config: Dict[str, Any],
                                 snapshot: MetricSnapshot,
                                 thresholds: Dict[str, float]) -> bool:
        """ØªÙ‚ÙŠÙŠÙ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        
        metric_name = rule_config['metric']
        condition = rule_config['condition']
        threshold = thresholds.get(metric_name, rule_config.get('default_threshold', 0))
        
        current_value = snapshot.metrics.get(metric_name, 0)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø±Ø·
        if condition == 'less_than':
            return current_value < threshold
        elif condition == 'greater_than':
            return current_value > threshold
        elif condition == 'equals':
            return abs(current_value - threshold) < 0.001
        elif condition == 'anomaly':
            return metric_name + '_anomaly' in snapshot.anomalies_detected
        
        return False
    
    async def _trigger_alert(self, deployment_id: str, 
                           rule_name: str,
                           rule_config: Dict[str, Any],
                           snapshot: MetricSnapshot) -> None:
        """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        
        # ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ Ù…ÙƒØ±Ø±
        existing_alert = self._find_existing_alert(rule_name, snapshot.model_id)
        if existing_alert and not existing_alert.auto_resolved:
            return  # ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ†Ø¨ÙŠÙ‡ Ø¬Ø¯ÙŠØ¯
        alert = PerformanceAlert(
            alert_id=f"alert_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}_{rule_name}",
            timestamp=datetime.utcnow(),
            severity=AlertSeverity(rule_config['severity']),
            metric_name=rule_config['metric'],
            current_value=snapshot.metrics.get(rule_config['metric'], 0),
            threshold_value=rule_config.get('default_threshold', 0),
            message=rule_config['message'].format(
                model_id=snapshot.model_id,
                current_value=snapshot.metrics.get(rule_config['metric'], 0),
                threshold=rule_config.get('default_threshold', 0)
            ),
            affected_models=[snapshot.model_id],
            recommended_actions=rule_config.get('actions', [])
        )
        
        self.active_alerts.append(alert)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡
        await self._send_alert(deployment_id, alert)
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­Ù„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        if rule_config.get('auto_resolve', False):
            await self._attempt_auto_resolution(alert, snapshot)
    
    def _find_existing_alert(self, rule_name: str, model_id: str) -> Optional[PerformanceAlert]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªÙ†Ø¨ÙŠÙ‡ Ù…ÙˆØ¬ÙˆØ¯"""
        
        for alert in self.active_alerts:
            if (rule_name in alert.alert_id and 
                model_id in alert.affected_models and 
                not alert.auto_resolved):
                return alert
        
        return None
    
    async def _send_alert(self, deployment_id: str, alert: PerformanceAlert) -> None:
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        
        severity_emoji = {
            AlertSeverity.LOW: "ğŸŸ¡",
            AlertSeverity.MEDIUM: "ğŸŸ ", 
            AlertSeverity.HIGH: "ğŸ”´",
            AlertSeverity.CRITICAL: "ğŸš¨"
        }
        
        logger.warning(f"{severity_emoji[alert.severity]} ALERT [{alert.severity.value.upper()}] "
                      f"Deployment: {deployment_id} | {alert.message}")
        
        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø¹Ø¨Ø±:
        # - Slack/Teams
        # - Email
        # - PagerDuty
        # - SMS Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø©
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡
        await self._notify_stakeholders(deployment_id, alert)
    
    async def _notify_stakeholders(self, deployment_id: str, alert: PerformanceAlert) -> None:
        """Ø¥Ø´Ø¹Ø§Ø± Ø£ØµØ­Ø§Ø¨ Ø§Ù„Ù…ØµÙ„Ø­Ø©"""
        
        notification_channels = []
        
        if alert.severity == AlertSeverity.CRITICAL:
            notification_channels = ['email', 'sms', 'pagerduty', 'slack']
        elif alert.severity == AlertSeverity.HIGH:
            notification_channels = ['email', 'slack']
        else:
            notification_channels = ['slack']
        
        logger.info(f"ğŸ“¢ Notifying stakeholders via {notification_channels} for alert {alert.alert_id}")
    
    async def _attempt_auto_resolution(self, alert: PerformanceAlert, snapshot: MetricSnapshot) -> None:
        """Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­Ù„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        
        resolved = False
        
        # Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø­Ù„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
        if 'response_time' in alert.metric_name:
            resolved = await self._auto_resolve_response_time_issue(alert, snapshot)
        elif 'memory' in alert.metric_name:
            resolved = await self._auto_resolve_memory_issue(alert, snapshot)
        elif 'error_rate' in alert.metric_name:
            resolved = await self._auto_resolve_error_rate_issue(alert, snapshot)
        
        if resolved:
            alert.auto_resolved = True
            logger.info(f"âœ… Auto-resolved alert {alert.alert_id}")
    
    async def _auto_resolve_response_time_issue(self, alert: PerformanceAlert, snapshot: MetricSnapshot) -> bool:
        """Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        logger.info(f"ğŸ”§ Attempting auto-resolution for response time issue in {snapshot.model_id}")
        
        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬:
        # - Ø²ÙŠØ§Ø¯Ø© Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø­ÙˆØ³Ø¨Ø©
        # - ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
        # - ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ø­Ù…Ø§Ù„
        
        return np.random.choice([True, False], p=[0.7, 0.3])  # Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ø¬Ø§Ø­ 70%
    
    async def _auto_resolve_memory_issue(self, alert: PerformanceAlert, snapshot: MetricSnapshot) -> bool:
        """Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        
        logger.info(f"ğŸ”§ Attempting auto-resolution for memory issue in {snapshot.model_id}")
        
        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬:
        # - ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        # - Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©
        # - Ø²ÙŠØ§Ø¯Ø© Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        
        return np.random.choice([True, False], p=[0.6, 0.4])  # Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ø¬Ø§Ø­ 60%
    
    async def _auto_resolve_error_rate_issue(self, alert: PerformanceAlert, snapshot: MetricSnapshot) -> bool:
        """Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
        
        logger.info(f"ğŸ”§ Attempting auto-resolution for error rate issue in {snapshot.model_id}")
        
        # ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬:
        # - Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ø·Ù„Ø©
        # - ØªØ­Ø¯ÙŠØ« Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©
        # - ØªØµØ­ÙŠØ­ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø§ØªØµØ§Ù„
        
        return np.random.choice([True, False], p=[0.5, 0.5])  # Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ø¬Ø§Ø­ 50%
    
    async def _establish_baseline_metrics(self, models: Dict[str, Any]) -> Dict[str, Dict[str, float]]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø³Ø§Ø³ÙŠØ©"""
        
        baseline_metrics = {}
        
        for model_id, model_data in models.items():
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙƒØ£Ø³Ø§Ø³
            if hasattr(model_data, 'final_metrics'):
                baseline_metrics[model_id] = model_data.final_metrics
            else:
                # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                baseline_metrics[model_id] = {
                    'safety_score': 0.95,
                    'child_satisfaction': 0.80,
                    'accuracy': 0.85,
                    'response_time_ms': 1000,
                    'error_rate': 0.01
                }
        
        return baseline_metrics
    
    def _get_deployment_alert_thresholds(self) -> Dict[str, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹ØªØ¨Ø§Øª ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ù†Ø´Ø±"""
        
        return {
            'safety_score': 0.95,
            'child_satisfaction': 0.75,
            'accuracy': 0.80,
            'response_time_ms': 2000,
            'error_rate': 0.02,
            'memory_usage_mb': 1024,
            'cpu_usage_percent': 80,
            'throughput_rps': 50
        }
    
    def _initialize_alert_rules(self) -> Dict[str, Dict[str, Any]]:
        """ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        
        return {
            'safety_score_critical': {
                'metric': 'safety_score',
                'condition': 'less_than',
                'default_threshold': 0.95,
                'severity': 'critical',
                'message': 'CRITICAL: Safety score for {model_id} dropped to {current_value:.3f} (threshold: {threshold})',
                'actions': ['immediate_rollback', 'escalate_to_safety_team'],
                'auto_resolve': False
            },
            'child_satisfaction_low': {
                'metric': 'child_satisfaction',
                'condition': 'less_than',
                'default_threshold': 0.75,
                'severity': 'high',
                'message': 'Child satisfaction for {model_id} is low: {current_value:.3f} (threshold: {threshold})',
                'actions': ['review_conversation_quality', 'check_personalization'],
                'auto_resolve': False
            },
            'response_time_high': {
                'metric': 'response_time_ms',
                'condition': 'greater_than',
                'default_threshold': 2000,
                'severity': 'medium',
                'message': 'Response time for {model_id} is high: {current_value:.0f}ms (threshold: {threshold}ms)',
                'actions': ['scale_up_resources', 'optimize_model'],
                'auto_resolve': True
            },
            'error_rate_high': {
                'metric': 'error_rate',
                'condition': 'greater_than',
                'default_threshold': 0.02,
                'severity': 'high',
                'message': 'Error rate for {model_id} is high: {current_value:.3f} (threshold: {threshold})',
                'actions': ['check_model_health', 'review_recent_changes'],
                'auto_resolve': True
            },
            'memory_usage_high': {
                'metric': 'memory_usage_mb',
                'condition': 'greater_than',
                'default_threshold': 1024,
                'severity': 'medium',
                'message': 'Memory usage for {model_id} is high: {current_value:.0f}MB (threshold: {threshold}MB)',
                'actions': ['increase_memory_limits', 'optimize_memory_usage'],
                'auto_resolve': True
            },
            'anomaly_detected': {
                'metric': 'any',
                'condition': 'anomaly',
                'default_threshold': 0,
                'severity': 'medium',
                'message': 'Anomaly detected in {model_id} metrics',
                'actions': ['investigate_anomaly', 'compare_with_baseline'],
                'auto_resolve': False
            }
        }
    
    def _initialize_metrics_collector(self) -> Dict[str, Any]:
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ø§Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
        return {
            'collection_interval_seconds': 60,
            'metrics_retention_hours': 168,  # Ø£Ø³Ø¨ÙˆØ¹
            'aggregation_enabled': True
        }
    
    def _initialize_anomaly_detector(self) -> Dict[str, Any]:
        """ØªÙ‡ÙŠØ¦Ø© ÙƒØ§Ø´Ù Ø§Ù„Ø´Ø°ÙˆØ°"""
        return {
            'algorithm': 'statistical',
            'sensitivity': 0.95,
            'min_data_points': 10
        }
    
    def _initialize_alerting_system(self) -> Dict[str, Any]:
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡"""
        return {
            'channels': ['slack', 'email', 'pagerduty'],
            'rate_limiting': True,
            'escalation_enabled': True
        }
    
    async def _cleanup_old_metrics(self) -> None:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 1000 Ù‚ÙŠØ§Ø³ ÙÙ‚Ø·
        if len(self.metric_history) > 1000:
            self.metric_history = self.metric_history[-1000:]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø§Ù„Ù…Ø­Ù„ÙˆÙ„Ø©
        cutoff_time = datetime.utcnow() - timedelta(hours=24)
        self.active_alerts = [
            alert for alert in self.active_alerts
            if alert.timestamp > cutoff_time or not alert.auto_resolved
        ]
    
    async def _finalize_deployment_monitoring(self, deployment_id: str) -> None:
        """Ø¥Ù†Ù‡Ø§Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø´Ø±"""
        
        if deployment_id in self.active_monitors:
            monitor_info = self.active_monitors[deployment_id]
            monitor_info['status'] = 'completed'
            monitor_info['end_time'] = datetime.utcnow()
            
            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ
            final_report = await self._generate_monitoring_report(deployment_id)
            logger.info(f"ğŸ“Š Generated final monitoring report for {deployment_id}")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
            del self.active_monitors[deployment_id]
    
    async def _generate_monitoring_report(self, deployment_id: str) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"""
        
        monitor_info = self.active_monitors.get(deployment_id, {})
        config = monitor_info.get('config', {})
        
        # Ø¬Ù…Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
        monitoring_stats = {
            'deployment_id': deployment_id,
            'monitoring_duration_hours': config.get('duration_hours', 0),
            'total_metrics_collected': len([
                snapshot for snapshot in self.metric_history
                if any(model_id in snapshot.model_id for model_id in config.get('models', {}).keys())
            ]),
            'alerts_triggered': len([
                alert for alert in self.active_alerts
                if deployment_id in alert.alert_id
            ]),
            'anomalies_detected': sum(
                len(snapshot.anomalies_detected) for snapshot in self.metric_history
                if any(model_id in snapshot.model_id for model_id in config.get('models', {}).keys())
            ),
            'auto_resolutions': len([
                alert for alert in self.active_alerts
                if deployment_id in alert.alert_id and alert.auto_resolved
            ])
        }
        
        return monitoring_stats 