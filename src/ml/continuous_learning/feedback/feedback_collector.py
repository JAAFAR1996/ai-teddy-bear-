# ===================================================================
# ğŸ§¸ AI Teddy Bear - Feedback Collection System
# Enterprise ML Feedback Collection & Analysis
# ML Team Lead: Senior ML Engineer
# Date: January 2025
# ===================================================================

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import numpy as np

logger = logging.getLogger(__name__)


class FeedbackType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"""

    CHILD_INTERACTION = "child_interaction"
    PARENT_FEEDBACK = "parent_feedback"
    LEARNING_OUTCOME = "learning_outcome"
    SAFETY_INCIDENT = "safety_incident"
    ENGAGEMENT_METRIC = "engagement_metric"
    SATISFACTION_RATING = "satisfaction_rating"


@dataclass
class FeedbackData:
    """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"""

    feedback_id: str
    child_id: str
    feedback_type: FeedbackType
    timestamp: datetime
    content: Dict[str, Any]
    sentiment_score: float
    safety_score: float
    engagement_level: float
    learning_effectiveness: float
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class InteractionFeedback:
    """ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„ØªÙØ§Ø¹Ù„"""

    conversation_id: str
    child_age: int
    interaction_duration: float
    response_quality: float
    child_satisfaction: float
    educational_value: float
    safety_compliance: bool
    topics_discussed: List[str]
    emotions_detected: List[str]


class FeedbackCollector:
    """Ø¬Ø§Ù…Ø¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø´Ø§Ù…Ù„"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.feedback_buffer: List[FeedbackData] = []
        self.collection_stats = {
            "total_collected": 0,
            "by_type": {},
            "average_sentiment": 0.0,
            "safety_incidents": 0,
            "high_engagement_sessions": 0,
        }

        logger.info("ğŸ“Š Feedback Collector initialized")

    async def collect_daily_feedback(self) -> Dict[str, Any]:
        """Ø¬Ù…Ø¹ Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±"""

        logger.info("ğŸ” Starting daily feedback collection...")

        # Ø¬Ù…Ø¹ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø© Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
        collection_tasks = [
            self._collect_child_interactions(),
            self._collect_parent_feedback(),
            self._collect_learning_outcomes(),
            self._collect_safety_metrics(),
            self._collect_engagement_data(),
            self._collect_satisfaction_ratings(),
        ]

        results = await asyncio.gather(*collection_tasks, return_exceptions=True)

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        all_feedback = {
            "child_interactions": (
                results[0] if not isinstance(results[0], Exception) else []
            ),
            "parent_feedback": (
                results[1] if not isinstance(results[1], Exception) else []
            ),
            "learning_outcomes": (
                results[2] if not isinstance(results[2], Exception) else []
            ),
            "safety_metrics": (
                results[3] if not isinstance(results[3], Exception) else []
            ),
            "engagement_data": (
                results[4] if not isinstance(results[4], Exception) else []
            ),
            "satisfaction_ratings": (
                results[5] if not isinstance(results[5], Exception) else []
            ),
        }

        # ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        processed_feedback = await self._process_and_filter_feedback(all_feedback)

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        await self._update_collection_stats(processed_feedback)

        logger.info(
            f"âœ… Collected {len(processed_feedback.get('all_items', []))} feedback items"
        )

        return processed_feedback

    async def _collect_child_interactions(self) -> List[InteractionFeedback]:
        """Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØ§Ø¹Ù„ Ø§Ù„Ø£Ø·ÙØ§Ù„"""

        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        interactions = []

        # Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØ§Ø¹Ù„ Ù…Ø­Ø§ÙƒØ§Ø©
        for i in range(50):  # 50 ØªÙØ§Ø¹Ù„ ÙŠÙˆÙ…ÙŠ
            interaction = InteractionFeedback(
                conversation_id=f"conv_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                child_age=np.random.choice([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),
                interaction_duration=np.random.normal(5.0, 2.0),  # 5 Ø¯Ù‚Ø§Ø¦Ù‚ Ù…ØªÙˆØ³Ø·
                response_quality=np.random.beta(8, 2),  # Ù…Ù†Ø­Ø§Ø² Ù†Ø­Ùˆ Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
                child_satisfaction=np.random.beta(7, 2),
                educational_value=np.random.beta(6, 3),
                safety_compliance=np.random.choice([True, False], p=[0.98, 0.02]),
                topics_discussed=np.random.choice(
                    [
                        ["animals", "nature"],
                        ["math", "counting"],
                        ["stories", "imagination"],
                        ["colors", "shapes"],
                        ["music", "songs"],
                        ["games", "puzzles"],
                    ]
                ),
                emotions_detected=np.random.choice(
                    [
                        ["happy", "excited"],
                        ["curious", "engaged"],
                        ["calm", "content"],
                        ["surprised", "delighted"],
                        ["focused", "attentive"],
                    ]
                ),
            )
            interactions.append(interaction)

        logger.info(f"ğŸ“± Collected {len(interactions)} child interactions")
        return interactions

    async def _collect_parent_feedback(self) -> List[Dict[str, Any]]:
        """Ø¬Ù…Ø¹ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡"""

        parent_feedback = []

        # Ù…Ø­Ø§ÙƒØ§Ø© ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡
        for i in range(15):  # 15 ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ø¯ÙŠ ÙŠÙˆÙ…ÙŠ
            feedback = {
                "feedback_id": f"parent_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                "parent_id": f"parent_{i % 10}",
                "child_age": np.random.choice([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),
                "overall_satisfaction": np.random.beta(8, 2),
                "safety_confidence": np.random.beta(9, 1),
                "educational_value": np.random.beta(7, 2),
                "ease_of_use": np.random.beta(8, 2),
                "child_enjoyment": np.random.beta(8, 2),
                "would_recommend": np.random.choice([True, False], p=[0.9, 0.1]),
                "concerns": np.random.choice(
                    [
                        [],
                        ["screen_time"],
                        ["content_appropriateness"],
                        ["response_speed"],
                        ["variety_of_content"],
                    ],
                    p=[0.7, 0.1, 0.1, 0.05, 0.05],
                ),
                "suggestions": np.random.choice(
                    [
                        [],
                        ["more_educational_games"],
                        ["longer_conversations"],
                        ["more_personalization"],
                        ["better_voice_recognition"],
                    ],
                    p=[0.6, 0.15, 0.1, 0.1, 0.05],
                ),
                "timestamp": datetime.now() - timedelta(hours=np.random.randint(0, 24)),
            }
            parent_feedback.append(feedback)

        logger.info(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Collected {len(parent_feedback)} parent feedback items")
        return parent_feedback

    async def _collect_learning_outcomes(self) -> List[Dict[str, Any]]:
        """Ø¬Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù…"""

        learning_outcomes = []

        # Ù…Ø­Ø§ÙƒØ§Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù…
        for i in range(30):  # 30 Ù†ØªÙŠØ¬Ø© ØªØ¹Ù„Ù… ÙŠÙˆÙ…ÙŠØ©
            outcome = {
                "outcome_id": f"learning_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                "child_id": f"child_{i % 20}",
                "learning_objective": np.random.choice(
                    [
                        "number_recognition",
                        "letter_recognition",
                        "color_identification",
                        "shape_recognition",
                        "vocabulary_expansion",
                        "story_comprehension",
                        "emotional_recognition",
                        "social_skills",
                        "problem_solving",
                    ]
                ),
                "achievement_level": np.random.beta(6, 3),  # 0-1 scale
                "time_to_complete": np.random.normal(3.0, 1.0),  # minutes
                "attempts_needed": np.random.poisson(2) + 1,
                "engagement_during_learning": np.random.beta(7, 2),
                "retention_after_24h": np.random.beta(5, 3),
                "difficulty_level": np.random.choice(
                    ["easy", "medium", "hard"], p=[0.4, 0.4, 0.2]
                ),
                "learning_style_match": np.random.beta(6, 3),
                "timestamp": datetime.now() - timedelta(hours=np.random.randint(0, 24)),
            }
            learning_outcomes.append(outcome)

        logger.info(f"ğŸ“ Collected {len(learning_outcomes)} learning outcomes")
        return learning_outcomes

    async def _collect_safety_metrics(self) -> List[Dict[str, Any]]:
        """Ø¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ù…Ø§Ù†"""

        safety_metrics = []

        # Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ù…Ø§Ù†
        for i in range(100):  # 100 ÙØ­Øµ Ø£Ù…Ø§Ù† ÙŠÙˆÙ…ÙŠ
            metric = {
                "metric_id": f"safety_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                "interaction_id": f"interaction_{i}",
                "content_appropriateness": np.random.beta(20, 1),  # Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹
                "language_safety": np.random.beta(20, 1),
                "emotional_safety": np.random.beta(15, 2),
                "privacy_compliance": np.random.choice([True, False], p=[0.999, 0.001]),
                "parental_control_respected": np.random.choice(
                    [True, False], p=[0.995, 0.005]
                ),
                "age_appropriateness": np.random.beta(18, 2),
                "harmful_content_detected": np.random.choice(
                    [False, True], p=[0.998, 0.002]
                ),
                "safety_flags": [] if np.random.random() > 0.02 else ["mild_language"],
                "auto_correction_applied": np.random.choice(
                    [False, True], p=[0.95, 0.05]
                ),
                "timestamp": datetime.now() - timedelta(hours=np.random.randint(0, 24)),
            }
            safety_metrics.append(metric)

        logger.info(f"ğŸ›¡ï¸ Collected {len(safety_metrics)} safety metrics")
        return safety_metrics

    async def _collect_engagement_data(self) -> List[Dict[str, Any]]:
        """Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©"""

        engagement_data = []

        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
        for i in range(75):  # 75 Ø¬Ù„Ø³Ø© Ù…Ø´Ø§Ø±ÙƒØ© ÙŠÙˆÙ…ÙŠØ©
            engagement = {
                "engagement_id": f"engagement_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                "session_id": f"session_{i}",
                "child_age": np.random.choice([3, 4, 5, 6, 7, 8, 9, 10, 11, 12]),
                "session_duration": np.random.exponential(4.0),  # Ø¯Ù‚Ø§Ø¦Ù‚
                "interaction_frequency": np.random.poisson(15),  # ØªÙØ§Ø¹Ù„Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
                "attention_span": np.random.beta(5, 3),
                "response_enthusiasm": np.random.beta(6, 3),
                "question_asking_rate": np.random.poisson(3),
                "follow_up_engagement": np.random.beta(4, 4),
                "topic_switching_frequency": np.random.poisson(2),
                "emotional_engagement": np.random.beta(7, 2),
                "learning_momentum": np.random.beta(6, 3),
                "session_completion": np.random.choice([True, False], p=[0.85, 0.15]),
                "return_likelihood": np.random.beta(8, 2),
                "timestamp": datetime.now() - timedelta(hours=np.random.randint(0, 24)),
            }
            engagement_data.append(engagement)

        logger.info(f"ğŸ¯ Collected {len(engagement_data)} engagement metrics")
        return engagement_data

    async def _collect_satisfaction_ratings(self) -> List[Dict[str, Any]]:
        """Ø¬Ù…Ø¹ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø±Ø¶Ø§"""

        satisfaction_ratings = []

        # Ù…Ø­Ø§ÙƒØ§Ø© ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø±Ø¶Ø§
        for i in range(40):  # 40 ØªÙ‚ÙŠÙŠÙ… Ø±Ø¶Ø§ ÙŠÙˆÙ…ÙŠ
            rating = {
                "rating_id": f"satisfaction_{datetime.now().strftime('%Y%m%d')}_{i:03d}",
                "child_id": f"child_{i % 25}",
                "overall_satisfaction": np.random.beta(8, 2),
                "content_quality": np.random.beta(7, 2),
                "interaction_naturalness": np.random.beta(6, 3),
                "response_helpfulness": np.random.beta(7, 2),
                "entertainment_value": np.random.beta(8, 2),
                "educational_benefit": np.random.beta(6, 3),
                "ease_of_interaction": np.random.beta(8, 2),
                "voice_quality": np.random.beta(7, 2),
                "personalization_level": np.random.beta(5, 4),
                "safety_feeling": np.random.beta(9, 1),
                "would_use_again": np.random.choice([True, False], p=[0.9, 0.1]),
                "favorite_features": np.random.choice(
                    [["stories"], ["games"], ["learning"], ["music"], ["conversations"]]
                ),
                "improvement_suggestions": np.random.choice(
                    [
                        [],
                        ["faster_responses"],
                        ["more_topics"],
                        ["better_understanding"],
                        ["more_games"],
                        ["longer_stories"],
                    ],
                    p=[0.6, 0.1, 0.1, 0.1, 0.05, 0.05],
                ),
                "timestamp": datetime.now() - timedelta(hours=np.random.randint(0, 24)),
            }
            satisfaction_ratings.append(rating)

        logger.info(f"â­ Collected {len(satisfaction_ratings)} satisfaction ratings")
        return satisfaction_ratings

    async def _process_and_filter_feedback(
        self, raw_feedback: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØµÙÙŠØ© Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©"""

        processed = {
            "collection_date": datetime.now(),
            "total_items": 0,
            "quality_score": 0.0,
            "safety_incidents": 0,
            "high_satisfaction_rate": 0.0,
            "learning_effectiveness": 0.0,
            "engagement_score": 0.0,
            "parent_satisfaction": 0.0,
            "areas_for_improvement": [],
            "positive_trends": [],
            "all_items": [],
        }

        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ø±Ø§Ø¬Ø¹Ø©
        all_items = []

        # ØªÙØ§Ø¹Ù„Ø§Øª Ø§Ù„Ø£Ø·ÙØ§Ù„
        child_interactions = raw_feedback.get("child_interactions", [])
        for interaction in child_interactions:
            if (
                hasattr(interaction, "safety_compliance")
                and interaction.safety_compliance
            ):
                all_items.append(
                    {
                        "type": "child_interaction",
                        "data": interaction,
                        "quality_score": interaction.response_quality,
                        "safety_score": 1.0 if interaction.safety_compliance else 0.0,
                        "satisfaction": interaction.child_satisfaction,
                    }
                )

        # ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡
        parent_feedback = raw_feedback.get("parent_feedback", [])
        for feedback in parent_feedback:
            all_items.append(
                {
                    "type": "parent_feedback",
                    "data": feedback,
                    "quality_score": feedback["overall_satisfaction"],
                    "safety_score": feedback["safety_confidence"],
                    "satisfaction": feedback["overall_satisfaction"],
                }
            )

        # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¹Ù„Ù…
        learning_outcomes = raw_feedback.get("learning_outcomes", [])
        for outcome in learning_outcomes:
            all_items.append(
                {
                    "type": "learning_outcome",
                    "data": outcome,
                    "quality_score": outcome["achievement_level"],
                    "safety_score": 1.0,  # Learning outcomes are inherently safe
                    "satisfaction": outcome["engagement_during_learning"],
                }
            )

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        if all_items:
            processed["total_items"] = len(all_items)
            processed["quality_score"] = np.mean(
                [item["quality_score"] for item in all_items]
            )
            processed["safety_incidents"] = sum(
                1 for item in all_items if item["safety_score"] < 0.95
            )
            processed["high_satisfaction_rate"] = sum(
                1 for item in all_items if item["satisfaction"] > 0.8
            ) / len(all_items)

            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø­Ø¯Ø¯Ø©
            learning_items = [
                item for item in all_items if item["type"] == "learning_outcome"
            ]
            if learning_items:
                processed["learning_effectiveness"] = np.mean(
                    [item["quality_score"] for item in learning_items]
                )

            engagement_items = [
                item for item in all_items if item["type"] == "child_interaction"
            ]
            if engagement_items:
                processed["engagement_score"] = np.mean(
                    [item["satisfaction"] for item in engagement_items]
                )

            parent_items = [
                item for item in all_items if item["type"] == "parent_feedback"
            ]
            if parent_items:
                processed["parent_satisfaction"] = np.mean(
                    [item["satisfaction"] for item in parent_items]
                )

        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
        processed["areas_for_improvement"] = await self._identify_improvement_areas(
            all_items
        )
        processed["positive_trends"] = await self._identify_positive_trends(all_items)

        processed["all_items"] = all_items

        return processed

    async def _identify_improvement_areas(
        self, feedback_items: List[Dict]
    ) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"""

        improvement_areas = []

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹ÙŠÙØ©
        low_quality_items = [
            item for item in feedback_items if item["quality_score"] < 0.7
        ]
        if len(low_quality_items) > len(feedback_items) * 0.1:  # Ø£ÙƒØ«Ø± Ù…Ù† 10%
            improvement_areas.append("response_quality")

        safety_issues = [item for item in feedback_items if item["safety_score"] < 0.95]
        if safety_issues:
            improvement_areas.append("safety_enhancement")

        low_satisfaction = [
            item for item in feedback_items if item["satisfaction"] < 0.7
        ]
        if len(low_satisfaction) > len(feedback_items) * 0.15:  # Ø£ÙƒØ«Ø± Ù…Ù† 15%
            improvement_areas.append("user_satisfaction")

        # ØªØ­Ù„ÙŠÙ„ ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ø¢Ø¨Ø§Ø¡
        parent_items = [
            item for item in feedback_items if item["type"] == "parent_feedback"
        ]
        if parent_items:
            avg_parent_satisfaction = np.mean(
                [item["satisfaction"] for item in parent_items]
            )
            if avg_parent_satisfaction < 0.8:
                improvement_areas.append("parent_experience")

        return improvement_areas

    async def _identify_positive_trends(self, feedback_items: List[Dict]) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©"""

        positive_trends = []

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆÙŠØ©
        high_quality_rate = sum(
            1 for item in feedback_items if item["quality_score"] > 0.8
        ) / len(feedback_items)
        if high_quality_rate > 0.8:
            positive_trends.append("high_response_quality")

        high_safety_rate = sum(
            1 for item in feedback_items if item["safety_score"] > 0.95
        ) / len(feedback_items)
        if high_safety_rate > 0.98:
            positive_trends.append("excellent_safety_compliance")

        high_satisfaction_rate = sum(
            1 for item in feedback_items if item["satisfaction"] > 0.8
        ) / len(feedback_items)
        if high_satisfaction_rate > 0.85:
            positive_trends.append("high_user_satisfaction")

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù…
        learning_items = [
            item for item in feedback_items if item["type"] == "learning_outcome"
        ]
        if learning_items:
            avg_learning_effectiveness = np.mean(
                [item["quality_score"] for item in learning_items]
            )
            if avg_learning_effectiveness > 0.75:
                positive_trends.append("effective_learning_outcomes")

        return positive_trends

    async def _update_collection_stats(
        self, processed_feedback: Dict[str, Any]
    ) -> None:
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù…Ø¹"""

        self.collection_stats["total_collected"] += processed_feedback["total_items"]
        self.collection_stats["average_sentiment"] = processed_feedback["quality_score"]
        self.collection_stats["safety_incidents"] += processed_feedback[
            "safety_incidents"
        ]

        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        for item in processed_feedback["all_items"]:
            item_type = item["type"]
            if item_type not in self.collection_stats["by_type"]:
                self.collection_stats["by_type"][item_type] = 0
            self.collection_stats["by_type"][item_type] += 1

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
        high_engagement = sum(
            1 for item in processed_feedback["all_items"] if item["satisfaction"] > 0.8
        )
        self.collection_stats["high_engagement_sessions"] += high_engagement

        logger.info(
            f"ğŸ“ˆ Updated collection stats: {self.collection_stats['total_collected']} total items collected"
        )
