from typing import Any, Dict, List, Optional
from dataclasses import dataclass

#!/usr/bin/env python3
"""
ğŸ¤ Enhanced HUME AI Integration - 2025 Edition
ØªÙƒØ§Ù…Ù„ HUME AI Ù…Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø«Ù„Ø§Ø«:
1. Ù…Ø¹Ø§ÙŠØ±Ø© Ø¯Ù‚Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
2. Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
3. ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
"""

import asyncio
import json
import logging
import os
import statistics
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Union

import numpy as np
import uuid
import random
import time
import openai
import soundfile as sf
from hume import AsyncHumeClient, HumeClient
from pydantic import BaseModel, Field

# HUME AI imports
try:
    import librosa
    import soundfile as sf
    from hume import AsyncHumeClient, HumeClient

    HUME_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… HUME AI SDK available")
except ImportError as e:
    HUME_AVAILABLE = False
    logging.warning(f"âš ï¸ HUME AI SDK not available: {e}")

logger = logging.getLogger(__name__)


class Language(Enum):
    ARABIC = "ar"
    ENGLISH = "en"
    AUTO_DETECT = "auto"


@dataclass
class CalibrationConfig:
    confidence_threshold: float = 0.7
    language_weights: Dict[str, float] = None

    def __post_init__(self):
        if not self.language_weights:
            self.language_weights = {
                "ar": 1.0,  # Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - ÙˆØ²Ù† ÙƒØ§Ù…Ù„
                "en": 0.9,  # Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© - ÙˆØ²Ù† Ø¹Ø§Ù„ÙŠ
                "auto": 0.8,  # ÙƒØ´Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ - ÙˆØ²Ù† Ù…ØªÙˆØ³Ø·
            }


@dataclass
class ComprehensiveReportData:
    device_id: str
    start_date: datetime
    end_date: datetime
    historical_sessions: List
    processed_data: Dict
    trends_analysis: Dict
    insights: Dict
    include_detailed_analysis: bool


class EnhancedHumeIntegration:
    """ğŸ­ Enhanced Hume AI Integration with 2025 Standards"""

    def __init__(self, api_key: Optional[str] = None):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ HUME AI"""
        self.logger = logging.getLogger(__name__)
        self.api_key = api_key or os.getenv("HUME_API_KEY")
        if not self.api_key:
            self.logger.warning("âš ï¸ HUME API Key not found - using demo mode")
            self.api_key = "demo_key"

        self.config = CalibrationConfig()

        # Initialize HUME clients
        if HUME_AVAILABLE and self.api_key != "demo_key":
            try:
                self.client = HumeClient(api_key=self.api_key)
                self.async_client = AsyncHumeClient(api_key=self.api_key)
                self.logger.info("âœ… HUME AI clients initialized successfully")
            except Exception as e:
                self.logger.error(f"âš ï¸ HUME client initialization failed: {e}")
                self.client = None
                self.async_client = None
        else:
            self.client = None
            self.async_client = None
            self.logger.info("ğŸ”„ Running in mock mode for development")

        openai.api_key = os.getenv("OPENAI_API_KEY")

    # ==================== TASK 1: CALIBRATION ====================

    def _run_calibration_tests(
        self, test_samples: List[Dict], confidence_threshold: float
    ) -> (List[Dict], float):
        """Runs the calibration tests on the provided samples."""
        results = []
        total_processing_time = 0
        for i, sample in enumerate(test_samples, 1):
            self.logger.debug(
                f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙŠÙ†Ø© {i}/{len(test_samples)}: {sample['name']}"
            )
            start_time = datetime.now()
            emotion_data = self._analyze_calibration_sample(sample)
            processing_time = (datetime.now() - start_time).total_seconds()
            total_processing_time += processing_time

            confidence = emotion_data.get("confidence", 0.0)
            results.append(
                {
                    "sample": sample["name"],
                    "expected": sample["expected_emotion"],
                    "detected": emotion_data.get(
                        "dominant_emotion",
                        "unknown"),
                    "confidence": confidence,
                    "passes_threshold": confidence >= confidence_threshold,
                    "processing_time": processing_time,
                })
            self.logger.info(
                f"   Ù†ØªÙŠØ¬Ø©: {emotion_data.get('dominant_emotion')} ({confidence:.2f})"
            )
        return results, total_processing_time

    def _calculate_calibration_metrics(
        self, results: List[Dict], total_processing_time: float
    ) -> Dict:
        """Calculates and returns the calibration metrics."""
        success_rate = sum(
            1 for r in results if r["passes_threshold"]) / len(results)
        avg_confidence = statistics.mean([r["confidence"] for r in results])
        avg_processing_time = total_processing_time / len(results)
        accuracy = sum(
            1 for r in results if r["detected"] == r["expected"]) / len(results)

        return {
            "success_rate": success_rate,
            "accuracy": accuracy,
            "average_confidence": avg_confidence,
            "average_processing_time": avg_processing_time,
        }

    def calibrate_hume(
            self, confidence_threshold: float = 0.7) -> Dict[str, float]:
        """
        ğŸ¯ Ù…Ø¹Ø§ÙŠØ±Ø© Ø¯Ù‚Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        """
        self.logger.info(
            f"ğŸ¯ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§ÙŠØ±Ø© HUME Ù…Ø¹ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©: {confidence_threshold}")
        try:
            test_samples = self._create_calibration_samples()
            self.logger.info(f"ğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(test_samples)} Ø¹ÙŠÙ†Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")

            results, total_processing_time = self._run_calibration_tests(
                test_samples, confidence_threshold
            )
            metrics = self._calculate_calibration_metrics(
                results, total_processing_time
            )

            old_threshold = self.config.confidence_threshold
            self.config.confidence_threshold = confidence_threshold

            recommendation = self._generate_calibration_recommendation(
                metrics["success_rate"],
                metrics["average_confidence"],
                metrics["accuracy"],
            )

            calibration_result = {
                "timestamp": datetime.now().isoformat(),
                "threshold_old": old_threshold,
                "threshold_new": confidence_threshold,
                "samples_tested": len(test_samples),
                **metrics,
                "recommendation": recommendation,
                "detailed_results": results,
            }

            self.logger.info(
                f"âœ… Ù…Ø¹Ø§ÙŠØ±Ø© Ù…ÙƒØªÙ…Ù„Ø©: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {metrics['success_rate']:.1%}, Ø¯Ù‚Ø© Ø§Ù„ØªØ¹Ø±Ù: {metrics['accuracy']:.1%}"
            )
            return calibration_result

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø©: {e}")
            return {"error": str(e), "status": "failed"}

    def _create_calibration_samples(self) -> List[Dict]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø§Øª Ù…Ø¹Ø§ÙŠØ±Ø© Ù…ØªÙ†ÙˆØ¹Ø©"""
        samples = []

        # Ù…Ø´Ø§Ø¹Ø± Ù…Ø®ØªÙ„ÙØ© Ù…Ø¹ ØªØ±Ø¯Ø¯Ø§Øª ÙˆØ®ØµØ§Ø¦Øµ Ù…Ù…ÙŠØ²Ø©
        emotions_config = [
            ("joy", 440, 0.8, "high"),  # ÙØ±Ø­ - ØªØ±Ø¯Ø¯ Ø¹Ø§Ù„ÙŠØŒ Ø·Ø§Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
            ("sadness", 220, 0.3, "low"),  # Ø­Ø²Ù† - ØªØ±Ø¯Ø¯ Ù…Ù†Ø®ÙØ¶ØŒ Ø·Ø§Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©
            ("anger", 300, 0.9, "intense"),  # ØºØ¶Ø¨ - ØªØ±Ø¯Ø¯ Ù…ØªÙˆØ³Ø·ØŒ Ø·Ø§Ù‚Ø© Ù…ÙƒØ«ÙØ©
            ("calm", 260, 0.4, "stable"),  # Ù‡Ø¯ÙˆØ¡ - ØªØ±Ø¯Ø¯ Ù…Ù†Ø®ÙØ¶ØŒ Ø·Ø§Ù‚Ø© Ù…Ø³ØªÙ‚Ø±Ø©
            ("excitement", 500, 0.95, "very_high"),  # Ø¥Ø«Ø§Ø±Ø© - ØªØ±Ø¯Ø¯ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹
        ]

        for emotion, freq, energy, pattern in emotions_config:
            try:
                filename = f"calibration_{emotion}.wav"

                # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµÙˆØª
                duration = 3.0
                sample_rate = 16000
                t = np.linspace(0, duration, int(sample_rate * duration))

                # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙˆØ¬Ø© Ø£Ø³Ø§Ø³ÙŠØ©
                base_wave = energy * 0.3 * np.sin(2 * np.pi * freq * t)

                # Ø¥Ø¶Ø§ÙØ© Ø®ØµØ§Ø¦Øµ Ø¹Ø§Ø·ÙÙŠØ©
                if pattern == "high":
                    # ÙØ±Ø­ - ØªØ±Ø¯Ø¯ Ù…ØªØ²Ø§ÙŠØ¯
                    modulation = 1 + 0.1 * np.sin(2 * np.pi * 2 * t)
                    audio = base_wave * modulation
                elif pattern == "low":
                    # Ø­Ø²Ù† - ØªØ±Ø¯Ø¯ Ù…ØªÙ†Ø§Ù‚Øµ
                    fade = 1 - 0.3 * (t / duration)
                    audio = base_wave * fade
                elif pattern == "intense":
                    # ØºØ¶Ø¨ - ØªÙ‚Ù„Ø¨Ø§Øª Ø­Ø§Ø¯Ø©
                    spikes = 1 + 0.2 * np.sin(2 * np.pi * 8 * t)
                    audio = base_wave * spikes
                elif pattern == "stable":
                    # Ù‡Ø¯ÙˆØ¡ - Ø«Ø§Ø¨Øª ÙˆÙ…Ø³ØªÙ‚Ø±
                    audio = base_wave * 0.8
                else:  # very_high
                    # Ø¥Ø«Ø§Ø±Ø© - ØªØ°Ø¨Ø°Ø¨ Ø³Ø±ÙŠØ¹
                    excitement = 1 + 0.15 * np.sin(2 * np.pi * 5 * t)
                    audio = base_wave * excitement

                # Ø¥Ø¶Ø§ÙØ© ØªØ´ÙˆÙŠØ´ Ø·Ø¨ÙŠØ¹ÙŠ
                noise = 0.03 * np.random.random(len(audio))
                audio = audio + noise

                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØª
                audio = audio / np.max(np.abs(audio)) * 0.8

                # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
                sf.write(filename, audio, sample_rate)

                samples.append(
                    {
                        "name": emotion,
                        "file": filename,
                        "expected_emotion": emotion,
                        "frequency": freq,
                        "energy_level": energy,
                        "pattern": pattern,
                    }
                )

                self.logger.info(f"   âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø©: {filename}")

            except Exception as e:
                self.logger.error(f"Error: {e}")
                self.logger.error(f"   âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø© {emotion}: {e}")

        return samples

    def _analyze_calibration_sample(self, sample: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø¹ÙŠÙ†Ø© Ù…Ø¹Ø§ÙŠØ±Ø© ÙˆØ§Ø­Ø¯Ø©"""
        if HUME_AVAILABLE and self.client:
            try:
                return self._real_hume_analysis(sample["file"])
            except Exception as e:
                self.logger.error(
                    f"âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ: {e}")
                return self._mock_analysis_enhanced(sample)
        else:
            return self._mock_analysis_enhanced(sample)

    def _mock_analysis_enhanced(self, sample: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø­Ø³Ù† Ù„Ù„Ù…Ø¹Ø§ÙŠØ±Ø©"""
        import random

        expected = sample["expected_emotion"]

        # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù‚Ø¹ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹ÙŠÙ†Ø©
        base_emotions = {
            "joy": random.uniform(0.2, 0.4),
            "sadness": random.uniform(0.1, 0.3),
            "anger": random.uniform(0.1, 0.3),
            "calm": random.uniform(0.2, 0.4),
            "excitement": random.uniform(0.1, 0.3),
            "fear": random.uniform(0.05, 0.2),
            "surprise": random.uniform(0.05, 0.2),
        }

        # Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù…Ù‡ÙŠÙ…Ù†Ø© Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªÙ†ÙˆØ¹ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ
        confidence_range = {
            "joy": (0.75, 0.92),
            "sadness": (0.70, 0.88),
            "anger": (0.73, 0.90),
            "calm": (0.68, 0.85),
            "excitement": (0.78, 0.95),
        }

        if expected in confidence_range:
            min_conf, max_conf = confidence_range[expected]
            base_emotions[expected] = random.uniform(min_conf, max_conf)

        # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„ØªØ´ÙˆÙŠØ´ Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠ
        for emotion in base_emotions:
            if emotion != expected:
                # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø±Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
                base_emotions[emotion] *= random.uniform(0.7, 0.9)

        dominant_emotion = max(base_emotions, key=base_emotions.get)
        confidence = base_emotions[dominant_emotion]

        return {
            "emotions": base_emotions,
            "dominant_emotion": dominant_emotion,
            "confidence": confidence,
            "analysis_method": "enhanced_mock",
        }

    def _generate_calibration_recommendation(
        self, success_rate: float, avg_confidence: float, accuracy: float
    ) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""

        recommendation_rules = [
            (
                lambda r: r["success_rate"] >= 0.9
                and r["accuracy"] >= 0.8
                and r["avg_confidence"] >= 0.8,
                "Ù…Ù…ØªØ§Ø²: Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø­Ø§ÙŠØ¯ Ø¨Ø´ÙƒÙ„ Ù…Ø«Ø§Ù„ÙŠ",
            ),
            (
                lambda r: r["success_rate"] >= 0.8 and r["accuracy"] >= 0.7,
                "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹: Ø£Ø¯Ø§Ø¡ Ù‚ÙˆÙŠ Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© ØªØ­Ø³ÙŠÙ†Ø§Øª Ø·ÙÙŠÙØ©",
            ),
            (
                lambda r: r["success_rate"] >= 0.7 and r["accuracy"] >= 0.6,
                "Ø¬ÙŠØ¯: Ø£Ø¯Ø§Ø¡ Ù…Ù‚Ø¨ÙˆÙ„ØŒ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø®ÙÙŠÙØ© ÙÙŠ Ø§Ù„Ø¹ØªØ¨Ø©",
            ),
            (
                lambda r: r["success_rate"] >= 0.5,
                "Ù…ØªÙˆØ³Ø·: Ø§Ø¹ØªØ¨Ø± ØªÙ‚Ù„ÙŠÙ„ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø© Ø£Ùˆ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
            ),
            (
                lambda r: r["accuracy"] < 0.5,
                "Ø¶Ø¹ÙŠÙ: Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¯Ù‚Ø© Ø§Ù„ØªØ¹Ø±ÙØŒ Ø±Ø§Ø¬Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨",
            ),
        ]

        metrics = {
            "success_rate": success_rate,
            "avg_confidence": avg_confidence,
            "accuracy": accuracy,
        }
        for rule, recommendation in recommendation_rules:
            if rule(metrics):
                return recommendation

        return "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†: Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ù…Ù†Ø®ÙØ¶Ø©"

    # ==================== TASK 2: MULTI-LANGUAGE ====================

    async def analyze_emotion_multilang(
        self,
        audio_file: Union[str, bytes],
        lang: str = "auto",
        udid: str = "UNKNOWN",
        child_name: str = "Ø·ÙÙ„",
        child_age: int = 6,
    ) -> Dict:
        """
        ğŸŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©

        Args:
            audio_file: Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ø£Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            lang: Ø§Ù„Ù„ØºØ© ("ar", "en", "auto")
            udid: Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù‡Ø§Ø²
            child_name: Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„
            child_age: Ø¹Ù…Ø± Ø§Ù„Ø·ÙÙ„

        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù„ØºÙˆÙŠ
        """
        self.logger.info(f"ğŸŒ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª")
        self.logger.info(f"   Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©: {lang}")
        self.logger.info(f"   Ø§Ù„Ø·ÙÙ„: {child_name} ({child_age} Ø³Ù†ÙˆØ§Øª)")

        try:
            start_time = datetime.now()

            audio_path = await self._prepare_audio_file(audio_file)

            detected_lang = (
                lang
                if lang != "auto"
                else await self._detect_language_advanced(audio_path)
            )
            self.logger.debug(f"ğŸ” ØªÙ… ÙƒØ´Ù Ø§Ù„Ù„ØºØ©: {detected_lang}")

            language_config = self._get_language_specific_config(detected_lang)
            self.logger.info(f"âš™ï¸ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª {detected_lang}")

            analysis_result = (
                await self._hume_analysis_with_language(
                    audio_path, language_config, detected_lang
                )
                if HUME_AVAILABLE and self.client
                else self._mock_multilang_analysis(detected_lang, child_age)
            )

            calibrated_result = self._apply_language_calibration(
                analysis_result, detected_lang, child_age
            )

            processing_time = (datetime.now() - start_time).total_seconds()

            request_info = {
                "udid": udid,
                "child_name": child_name,
                "child_age": child_age,
                "lang": lang,
            }
            final_result = self._build_final_response(
                calibrated_result, detected_lang, request_info, processing_time
            )

            self.logger.info(
                f"âœ… ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØªÙ…Ù„: Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {detected_lang}, Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©: {final_result['dominant_emotion']}"
            )

            return final_result

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "detected_language": lang if lang != "auto" else "ar",
            }

    async def _detect_language_advanced(self, audio_path: str) -> str:
        """ÙƒØ´Ù Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù…Ù† Ø§Ù„ØµÙˆØª"""
        try:
            self.logger.debug("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØªÙŠØ© Ù„ÙƒØ´Ù Ø§Ù„Ù„ØºØ©...")

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
            y, sr = librosa.load(audio_path, sr=16000)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø·ÙŠÙÙŠØ©
            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            avg_centroid = np.mean(spectral_centroid)
            avg_rolloff = np.mean(spectral_rolloff)
            mfcc_mean = np.mean(mfcc, axis=1)

            # Ù‚ÙˆØ§Ø¹Ø¯ ÙƒØ´Ù Ù…Ø­Ø³Ù†Ø© (ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡Ø§ Ø¨Ù€ ML)
            arabic_score = 0
            english_score = 0

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø·ÙŠÙÙŠ
            if avg_centroid < 2000:
                arabic_score += 2
            else:
                english_score += 2

            # ØªØ­Ù„ÙŠÙ„ Rolloff
            if avg_rolloff < 4000:
                arabic_score += 1
            else:
                english_score += 1

            # ØªØ­Ù„ÙŠÙ„ MFCC patterns (Ù…Ø¨Ø³Ø·)
            if np.std(mfcc_mean) > 15:
                english_score += 1  # Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¹Ø§Ø¯Ø© Ø£ÙƒØ«Ø± ØªÙ†ÙˆØ¹Ø§Ù‹
            else:
                arabic_score += 1

            # Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±
            if arabic_score > english_score:
                detected = "ar"
                confidence = arabic_score / (arabic_score + english_score)
            else:
                detected = "en"
                confidence = english_score / (arabic_score + english_score)

            self.logger.info(
                f"   Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù: {detected} (Ø«Ù‚Ø©: {confidence:.2f})")
            self.logger.info(f"   Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ: {avg_centroid:.0f} Hz")
            self.logger.info(f"   Rolloff: {avg_rolloff:.0f} Hz")

            return detected

        except Exception as e:
            self.logger.error(f"âš ï¸ ÙØ´Ù„ ÙƒØ´Ù Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…: {e}")
            return "ar"  # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©

    def _get_language_specific_config(self, language: str) -> Dict:
        """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª HUME Ø®Ø§ØµØ© Ø¨ÙƒÙ„ Ù„ØºØ©"""
        base_config = {"prosody": {}, "language": {}}

        if language == "ar":
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            base_config.update(
                {
                    "prosody": {
                        "granularity": "word",
                        "identify_speakers": False,
                        "language_context": "arabic",
                    },
                    "language": {
                        "granularity": "word",
                        "detect_language": True},
                })
            self.logger.info("   ğŸ“ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: granularity=word")

        elif language == "en":
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            base_config.update(
                {
                    "prosody": {
                        "granularity": "utterance",
                        "identify_speakers": False,
                        "language_context": "english",
                    }
                }
            )
            self.logger.info(
                "   ğŸ“ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©: granularity=utterance")

        return base_config

    def _apply_language_calibration(
        self, analysis_result: Dict, language: str, child_age: int
    ) -> Dict:
        """ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§ÙŠØ±Ø© Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„Ø¹Ù…Ø±"""

        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù„ØºØ©
        language_weight = self.config.language_weights.get(language, 0.8)

        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ©
        original_confidence = analysis_result.get("confidence", 0.5)
        adjusted_confidence = original_confidence * language_weight

        # ØªØ¹Ø¯ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
        original_emotions = analysis_result.get("emotions", {})
        adjusted_emotions = {}

        for emotion, score in original_emotions.items():
            # ØªØ·Ø¨ÙŠÙ‚ ÙˆØ²Ù† Ø§Ù„Ù„ØºØ©
            language_adjusted = score * language_weight

            # ØªØ·Ø¨ÙŠÙ‚ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¹Ù…Ø±
            age_factor = self._get_age_adjustment_factor(emotion, child_age)
            age_adjusted = language_adjusted * age_factor

            # ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø©
            if age_adjusted >= self.config.confidence_threshold:
                adjusted_emotions[emotion] = min(age_adjusted, 1.0)
            else:
                # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¶Ø¹ÙŠÙØ© Ø§Ù„Ø«Ù‚Ø©
                adjusted_emotions[emotion] = age_adjusted * 0.75

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        if adjusted_emotions:
            dominant_emotion = max(
                adjusted_emotions,
                key=adjusted_emotions.get)
            final_confidence = adjusted_emotions[dominant_emotion]
        else:
            dominant_emotion = "calm"
            final_confidence = 0.5
            adjusted_emotions = {"calm": 0.5}

        self.logger.info(f"   ğŸ”§ Ù…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„Ù„ØºØ©:")
        self.logger.info(f"      ÙˆØ²Ù† {language}: {language_weight}")
        self.logger.info(f"      Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: {original_confidence:.2f}")
        self.logger.info(f"      Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©: {final_confidence:.2f}")

        return {
            "emotions": adjusted_emotions,
            "dominant_emotion": dominant_emotion,
            "confidence": final_confidence,
            "language_weight_applied": language_weight,
            "energy_level": analysis_result.get("energy_level", 0.5),
            "voice_quality": analysis_result.get("voice_quality", 0.7),
        }

    def _get_age_adjustment_factor(self, emotion: str, age: int) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ø±"""
        # Ù…Ø¹Ø§ÙŠÙŠØ± ØªØ·ÙˆÙŠØ±ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…Ø±
        age_factors = {
            3: {"joy": 1.2, "curiosity": 1.1, "fear": 0.9, "anger": 0.8},
            4: {"joy": 1.1, "curiosity": 1.2, "playfulness": 1.1, "fear": 0.9},
            5: {"curiosity": 1.2, "excitement": 1.1, "joy": 1.0, "calm": 0.9},
            6: {"curiosity": 1.1, "excitement": 1.0, "joy": 1.0, "calm": 1.0},
            7: {"curiosity": 1.0, "excitement": 1.0, "confidence": 1.1},
            8: {"confidence": 1.1, "curiosity": 1.0, "social": 1.1},
        }

        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø¹Ù…Ø±
        closest_age = min(age_factors.keys(), key=lambda x: abs(x - age))
        factors = age_factors[closest_age]

        return factors.get(emotion, 1.0)  # Ø§ÙØªØ±Ø§Ø¶ÙŠ = 1.0 (Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„)

    def _calculate_language_confidence(self, language: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© ÙƒØ´Ù Ø§Ù„Ù„ØºØ©"""
        confidence_map = {
            "ar": 0.95,  # Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            "en": 0.90,  # Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            "auto": 0.75,  # Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© Ù„Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        }
        return confidence_map.get(language, 0.70)

    def _get_language_specific_recommendations(
        self, result: Dict, language: str, age: int
    ) -> List[str]:
        """Generates language-specific recommendations."""
        recommendations = []
        dominant = result["dominant_emotion"]
        confidence = result["confidence"]

        if language == "ar":
            if dominant == "curiosity" and age >= 5:
                recommendations.append(
                    "ÙØ¶ÙˆÙ„ Ø¹Ø§Ù„ÙŠ - ÙˆÙ‚Øª Ù…Ù…ØªØ§Ø² Ù„Ù„Ù‚ØµØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©")
            elif dominant == "joy" and confidence > 0.8:
                recommendations.append("ÙØ±Ø­ ÙˆØ§Ø¶Ø­ - Ø§Ù„Ø·ÙÙ„ ÙŠØ³ØªØ¬ÙŠØ¨ Ø¬ÙŠØ¯Ø§Ù‹ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©")
        elif language == "en":
            if dominant == "excitement" and age >= 6:
                recommendations.append(
                    "Excitement detected - good time for English learning games"
                )
            elif confidence < 0.6:
                recommendations.append(
                    "Consider Arabic support for better emotional expression"
                )
        return recommendations

    def _assess_developmental_stage(self, result: Dict, age: int) -> str:
        """Assesses the developmental stage based on emotion and age."""
        dominant = result["dominant_emotion"]
        confidence = result["confidence"]
        if age <= 4 and dominant in ["curiosity", "joy"]:
            return "excellent"
        if age >= 5 and dominant in ["confidence", "excitement"]:
            return "excellent"
        if confidence < 0.5:
            return "needs_attention"
        return "normal"

    def _generate_language_insights(
        self, result: Dict, language: str, age: int
    ) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¤Ù‰ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù„ØºØ©"""
        recommendations = self._get_language_specific_recommendations(
            result, language, age
        )
        developmental_stage = self._assess_developmental_stage(result, age)

        return {
            "language_appropriateness": "good",
            "developmental_stage": developmental_stage,
            "recommendations": recommendations,
        }

    async def _prepare_audio_file(self, audio_file: Union[str, bytes]) -> str:
        """Ensures the audio data is in a file format for processing."""
        if isinstance(audio_file, bytes):
            # Create a temporary file for byte data
            temp_path = f"temp_audio_{uuid.uuid4().hex}.wav"
            sf.write(
                temp_path,
                np.frombuffer(
                    audio_file,
                    dtype=np.int16),
                16000)
            return temp_path
        return audio_file

    def _build_final_response(
        self,
        result: Dict,
        detected_lang: str,
        request_info: Dict,
        processing_time: float,
    ) -> Dict:
        """Constructs the final response dictionary."""
        return {
            "timestamp": datetime.now().isoformat(),
            "udid": request_info["udid"],
            "child_name": request_info["child_name"],
            "child_age": request_info["child_age"],
            "input_language": request_info["lang"],
            "detected_language": detected_lang,
            "language_confidence": self._calculate_language_confidence(detected_lang),
            "emotions": result["emotions"],
            "dominant_emotion": result["dominant_emotion"],
            "confidence": result["confidence"],
            "energy_level": result.get(
                "energy_level",
                0.5),
            "voice_quality": result.get(
                "voice_quality",
                0.7),
            "processing_time": processing_time,
            "language_specific_insights": self._generate_language_insights(
                result,
                detected_lang,
                request_info["child_age"]),
            "calibration_applied": True,
        }

    # ==================== TASK 3: HISTORICAL DATA ====================

    def _build_comprehensive_report(self, report_data: ComprehensiveReportData) -> Dict:
        """Builds the comprehensive historical data report."""
        return {
            "metadata": {
                "device_id": report_data.device_id,
                "analysis_period": {
                    "start": report_data.start_date.isoformat(),
                    "end": report_data.end_date.isoformat(),
                    "total_days": (report_data.end_date - report_data.start_date).days,
                    "generated_at": datetime.now().isoformat(),
                },
                "data_quality": {
                    "sessions_found": len(report_data.historical_sessions),
                    "data_completeness": report_data.processed_data["data_quality_score"],
                    "confidence_level": report_data.processed_data["overall_confidence"],
                },
            },
            "summary_statistics": {
                "total_sessions": len(report_data.historical_sessions),
                "average_sessions_per_day": len(report_data.historical_sessions)
                / max((report_data.end_date - report_data.start_date).days, 1),
                "total_interaction_time": report_data.processed_data["total_duration"],
                "average_session_duration": report_data.processed_data["avg_session_duration"],
                "most_common_emotion": report_data.processed_data["dominant_emotion"],
                "emotional_stability_score": report_data.processed_data["stability_score"],
                "language_distribution": report_data.processed_data["language_stats"],
            },
            "detailed_analysis": (
                report_data.processed_data["daily_breakdown"] if report_data.include_detailed_analysis else {
                }
            ),
            "trends_and_patterns": {
                "emotional_trends": report_data.trends_analysis["emotion_trends"],
                "temporal_patterns": report_data.trends_analysis["time_patterns"],
                "language_usage_trends": report_data.trends_analysis["language_trends"],
                "development_indicators": report_data.trends_analysis["development_trends"],
            },
            "insights_and_recommendations": {
                "key_insights": report_data.insights["key_findings"],
                "emotional_health_assessment": report_data.insights["emotional_health"],
                "developmental_assessment": report_data.insights["development_status"],
                "parental_recommendations": report_data.insights["recommendations"],
                "areas_of_concern": report_data.insights["concerns"],
                "positive_highlights": report_data.insights["highlights"],
            },
            "hume_integration_metrics": {
                "analysis_accuracy": report_data.processed_data.get("hume_accuracy", 0.85),
                "language_detection_success": report_data.processed_data.get(
                    "lang_detection_success", 0.90
                ),
                "calibration_effectiveness": self._assess_calibration_effectiveness(
                    report_data.processed_data
                ),
                "data_processing_notes": report_data.processed_data.get("processing_notes", []),
            },
        }

    async def merge_historical_data(
        self,
        device_id: str,
        start_date: datetime,
        end_date: datetime,
        include_detailed_analysis: bool = True,
    ) -> Dict:
        """
        ğŸ“Š ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ HUME

        Args:
            device_id: Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù‡Ø§Ø²
            start_date: ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            end_date: ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
            include_detailed_analysis: ØªØ¶Ù…ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ

        Returns:
            ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ø¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙˆØ§Ù„Ø±Ø¤Ù‰
        """
        self.logger.info(f"ğŸ“Š Ø¨Ø¯Ø¡ ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©")
        self.logger.info(f"   Ø§Ù„Ø¬Ù‡Ø§Ø²: {device_id}")
        self.logger.info(
            f"   Ø§Ù„ÙØªØ±Ø©: {start_date.date()} Ø¥Ù„Ù‰ {end_date.date()}")
        self.logger.info(f"   Ø§Ù„Ù…Ø¯Ø©: {(end_date - start_date).days} ÙŠÙˆÙ…")

        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
            historical_sessions = await self._fetch_historical_sessions_advanced(
                device_id, start_date, end_date
            )

            if not historical_sessions:
                return {
                    "error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©",
                    "sessions_found": 0,
                    "device_id": device_id,
                }

            self.logger.info(f"ğŸ“¦ ØªÙ… Ø¬Ù„Ø¨ {len(historical_sessions)} Ø¬Ù„Ø³Ø©")

            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            processed_data = await self._process_historical_sessions_advanced(
                historical_sessions, include_detailed_analysis
            )

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª ÙˆØ§Ù„Ø£Ù†Ù…Ø§Ø·
            trends_analysis = await self._analyze_historical_trends_advanced(
                processed_data, device_id
            )

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
            insights = await self._generate_historical_insights_advanced(
                processed_data, trends_analysis
            )

            report_data = ComprehensiveReportData(
                device_id=device_id,
                start_date=start_date,
                end_date=end_date,
                historical_sessions=historical_sessions,
                processed_data=processed_data,
                trends_analysis=trends_analysis,
                insights=insights,
                include_detailed_analysis=include_detailed_analysis,
            )
            comprehensive_report = self._build_comprehensive_report(
                report_data)

            await self._save_historical_report(device_id, comprehensive_report)

            self.logger.info(
                f"âœ… ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ: Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {len(historical_sessions)}, Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©: {processed_data['dominant_emotion']}"
            )

            return comprehensive_report

        except Exception as e:
            self.logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©: {e}")
            return {
                "error": str(e),
                "status": "failed",
                "device_id": device_id}

    # Helper methods for historical data analysis
    async def _fetch_historical_sessions_advanced(
        self, device_id: str, start_date: datetime, end_date: datetime
    ) -> List[Dict]:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø³Ù†Ø©"""

        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¬Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        sessions = []
        current_date = start_date

        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø­Ø³Ø¨ Ø§Ù„ÙŠÙˆÙ…
        emotion_patterns = [
            ["joy", "curiosity", "excitement"],  # Ø£ÙŠØ§Ù… Ù†Ø´Ø·Ø©
            ["calm", "joy", "curiosity"],  # Ø£ÙŠØ§Ù… Ù‡Ø§Ø¯Ø¦Ø©
            ["curiosity", "excitement", "joy"],  # Ø£ÙŠØ§Ù… ØªØ¹Ù„ÙŠÙ…ÙŠØ©
            ["calm", "sadness", "joy"],  # Ø£ÙŠØ§Ù… Ù…Ø®ØªÙ„Ø·Ø©
            ["excitement", "joy", "playfulness"],  # Ø£ÙŠØ§Ù… Ù…Ø±Ø­Ø©
        ]

        pattern_index = 0

        while current_date <= end_date:
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª (1-4 Ø¬Ù„Ø³Ø§Øª ÙŠÙˆÙ…ÙŠØ§Ù‹)
            sessions_count = np.random.choice(
                [1, 2, 3, 4], p=[0.2, 0.4, 0.3, 0.1])

            daily_pattern = emotion_patterns[pattern_index % len(
                emotion_patterns)]

            for session_num in range(sessions_count):
                # ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø¬Ù„Ø³Ø© (Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø§Ø³ØªÙŠÙ‚Ø§Ø¸)
                hour = np.random.choice(
                    [9, 10, 14, 16, 18, 19], p=[0.1, 0.2, 0.2, 0.2, 0.2, 0.1]
                )
                minute = np.random.randint(0, 60)

                session_time = current_date.replace(hour=hour, minute=minute)

                # Ø§Ø®ØªÙŠØ§Ø± Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ
                primary_emotion = np.random.choice(daily_pattern)

                # Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                emotions = self._generate_realistic_emotion_distribution(
                    primary_emotion
                )

                # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
                session = {
                    "session_id": f"{device_id}_{current_date.strftime('%Y%m%d')}_{session_num:02d}",
                    "device_id": device_id,
                    "timestamp": session_time,
                    # 5-45 Ø«Ø§Ù†ÙŠØ©
                    "audio_duration": np.random.uniform(5.0, 45.0),
                    "language_detected": np.random.choice(["ar", "en"], p=[0.7, 0.3]),
                    "emotions": emotions,
                    "dominant_emotion": primary_emotion,
                    "confidence": emotions[primary_emotion],
                    "voice_quality": np.random.uniform(0.6, 0.95),
                    "energy_level": np.random.uniform(0.3, 0.9),
                    "processing_method": (
                        "hume_ai" if np.random.random() > 0.1 else "fallback"
                    ),
                    "child_age_at_time": 6,  # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
                    "interaction_context": np.random.choice(
                        ["free_play", "educational",
                            "bedtime", "wake_up", "meal_time"]
                    ),
                }

                sessions.append(session)

            current_date += timedelta(days=1)
            pattern_index += 1

        self.logger.info(f"   ğŸ’¾ ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(sessions)} Ø¬Ù„Ø³Ø© Ù…Ø­Ø§ÙƒØ§Ø©")
        return sessions

    def _generate_realistic_emotion_distribution(
        self, primary_emotion: str
    ) -> Dict[str, float]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØ²ÙŠØ¹ ÙˆØ§Ù‚Ø¹ÙŠ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        import random

        # Ù…Ø´Ø§Ø¹Ø± Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø¹ Ù†Ù‚Ø§Ø· Ø£ÙˆÙ„ÙŠØ©
        base_emotions = {
            "joy": 0.1,
            "sadness": 0.05,
            "anger": 0.05,
            "fear": 0.05,
            "curiosity": 0.15,
            "excitement": 0.1,
            "calm": 0.1,
            "playfulness": 0.08,
            "surprise": 0.06,
            "confidence": 0.08,
        }

        # Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù‡ÙŠÙ…Ù†Ø©
        base_emotions[primary_emotion] = random.uniform(0.65, 0.88)

        # Ø¥Ø¶Ø§ÙØ© Ù…Ø´Ø§Ø¹Ø± Ø«Ø§Ù†ÙˆÙŠØ© Ù…Ø±ØªØ¨Ø·Ø©
        emotion_correlations = {
            "joy": ["excitement", "playfulness", "confidence"],
            "curiosity": ["excitement", "surprise", "confidence"],
            "excitement": ["joy", "curiosity", "playfulness"],
            "calm": ["confidence", "joy"],
            "sadness": ["calm", "fear"],
            "playfulness": ["joy", "excitement", "surprise"],
        }

        if primary_emotion in emotion_correlations:
            # Ø£Ø®Ø° Ø£ÙˆÙ„ 2
            for secondary in emotion_correlations[primary_emotion][:2]:
                if secondary in base_emotions:
                    base_emotions[secondary] = random.uniform(0.15, 0.35)

        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…
        total = sum(base_emotions.values())
        normalized_emotions = {k: v / total for k, v in base_emotions.items()}

        # Ø­Ø°Ù Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¶Ø¹ÙŠÙØ© Ø¬Ø¯Ø§Ù‹
        return {k: v for k, v in normalized_emotions.items() if v >= 0.05}

    # Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù...
    # Adding remaining methods for historical data integration...
