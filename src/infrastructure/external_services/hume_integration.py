from dotenv import load_dotenv
from database import db_manager
from pathlib import Path
import os
import json
import asyncio
import structlog
import logging
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

#!/usr/bin/env python3
"""
ğŸ¤ HUME AI Integration Script
Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ HUME AI: Batch Ùˆ Stream
"""

logger = structlog.get_logger(__name__)


# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª HUME AI
try:
    from hume import AsyncHumeClient, HumeClient

    HUME_AVAILABLE = True
    logger.info("âœ… HUME AI SDK loaded successfully")
except ImportError:
    HUME_AVAILABLE = False
    logger.error("âŒ HUME AI SDK not available. Install with: pip install hume")


class HumeIntegration:
    """
    ğŸ­ HUME AI Integration Class
    ÙŠØ¯Ø¹Ù… Ù†Ù…ÙˆØ°Ø¬ÙŠ Batch Ùˆ Stream Ù„Ù„ØªØ­Ù„ÙŠÙ„
    """

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("HUME_API_KEY")

        if not self.api_key:
            raise ValueError(
                "âŒ HUME API Key not found! Set HUME_API_KEY environment variable"
            )

        logger.info(f"ğŸ”‘ HUME API Key loaded: {self.api_key[:8]}...")

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
        if HUME_AVAILABLE:
            self.client = HumeClient(api_key=self.api_key)
            self.async_client = AsyncHumeClient(api_key=self.api_key)
            logger.info("âœ… HUME Clients initialized")
        else:
            self.client = None
            self.async_client = None
            logger.warning("âš ï¸ HUME Clients not available")

    def _validate_file_paths(self, file_paths: List[str]) -> List[str]:
        """Validates a list of file paths, returning only the existing ones."""
        valid_files = []
        for file_path in file_paths:
            if Path(file_path).exists():
                valid_files.append(file_path)
                self.logger.info(f"  âœ… {file_path}")
            else:
                self.logger.error(f"  âŒ File not found: {file_path}")
        return valid_files

    def _submit_and_wait_for_job(self, valid_files: List[str]) -> Dict:
        """Submits a job to the Hume API and waits for it to complete."""
        self.logger.info("ğŸ“¤ Submitting batch job to HUME...")
        job = self.client.expression_measurement.batch.submit_job(
            urls=valid_files, configs=[{"prosody": {}}, {"face": {}}]
        )
        self.logger.info(f"ğŸ“‹ Job ID: {job.job_id}")
        self.logger.info("â³ Waiting for analysis to complete...")

        job = self.client.expression_measurement.batch.get_job_details(
            job.job_id)
        while job.state not in ["COMPLETED", "FAILED"]:
            self.logger.info("â³ Still processing...")
            import time

            time.sleep(5)
            job = self.client.expression_measurement.batch.get_job_details(
                job.job_id)

        return job

    def _process_job_results(self, job: Any, session_record: Any) -> Dict:
        """Processes the results of a completed Hume job."""
        if job.state == "FAILED":
            return {
                "status": "error",
                "mode": "batch",
                "error": "HUME job failed"}

        self.logger.info("ğŸ“¥ Downloading predictions...")
        predictions = self.client.expression_measurement.batch.get_job_predictions(
            job.job_id)

        emotions_data = self._extract_emotions_from_predictions(predictions)
        if emotions_data and session_record:
            self.logger.info("ğŸ’¾ Saving emotions to database...")
            db_manager.save_emotions(session_record.id, emotions_data)
            db_manager.update_session_status(session_record.id, "success")

        output_file = "batch_predictions.json"
        with open(output_file, "w") as f:
            json.dump(predictions, f, indent=2)

        return {
            "status": "success",
            "mode": "batch",
            "session_id": session_record.id if session_record else None,
            "output_file": output_file,
            "job_id": job.job_id,
            "emotions_saved": len(emotions_data) if emotions_data else 0,
            "results": predictions,
        }

    # ==================== BATCH MODE ====================

    def analyze_batch(
        self,
        file_paths: List[str],
        udid: str = "TEST_ESP32",
        child_name: str = "Ø·ÙÙ„ Ø§Ø®ØªØ¨Ø§Ø±",
        child_age: int = 6,
    ) -> Dict[str, Any]:
        """
        ğŸ”„ Ù†Ù…Ø· Batch - ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (HUME v0.9.0) Ù…Ø¹ Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Args:
            file_paths: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
            udid: Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù‡Ø§Ø²
            child_name: Ø§Ø³Ù… Ø§Ù„Ø·ÙÙ„
            child_age: Ø¹Ù…Ø± Ø§Ù„Ø·ÙÙ„

        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù…Ù„Ù JSON ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if not HUME_AVAILABLE or not self.client:
            return {"error": "HUME SDK not available"}

        session_record = None

        try:
            logger.info(
                f"ğŸ”„ Starting Batch Analysis... Analyzing {len(file_paths)} files."
            )

            valid_files = self._validate_file_paths(file_paths)
            if not valid_files:
                return {"error": "No valid files found"}

            session_record = db_manager.save_session(
                udid=udid,
                child_name=child_name,
                child_age=child_age,
                mode="batch",
                audio_file=valid_files[0],
            )

            job = self._submit_and_wait_for_job(valid_files)
            final_result = self._process_job_results(job, session_record)

            logger.info("âœ… Batch analysis completed successfully!")
            return {**final_result, "files_analyzed": len(valid_files)}

        except Exception as e:
            logger.error(f"âŒ Batch analysis failed: {e}")

            # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if session_record:
                db_manager.update_session_status(
                    session_record.id, "error", str(e))

            return {
                "status": "error",
                "mode": "batch",
                "session_id": session_record.id if session_record else None,
                "error": str(e),
            }

    # ==================== STREAM MODE ====================

    def _validate_stream_file(self, audio_path: str) -> bool:
        """Validates the existence of the audio file for stream analysis."""
        if not Path(audio_path).exists():
            self.logger.error(f"File not found: {audio_path}")
            return False
        return True

    async def _process_stream_results(
        self, result: Dict, session_record: Any
    ) -> Dict[str, Any]:
        """Processes the results of a stream analysis job."""
        emotions_data = self._extract_emotions_from_predictions(result)
        if emotions_data and session_record:
            self.logger.info("ğŸ’¾ Saving emotions to database...")
            db_manager.save_emotions(session_record.id, emotions_data)
            db_manager.update_session_status(session_record.id, "success")

        return {
            "status": "success",
            "mode": "stream",
            "session_id": session_record.id if session_record else None,
            "emotions_saved": len(emotions_data) if emotions_data else 0,
            "results": result,
        }

    async def analyze_stream(
        self,
        audio_path: str,
        udid: str = "TEST_ESP32",
        child_name: str = "Ø·ÙÙ„ Ø§Ø®ØªØ¨Ø§Ø±",
        child_age: int = 6,
    ) -> Dict[str, Any]:
        """
        âš¡ Ù†Ù…Ø· Stream - ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±ÙŠ Ù„Ù…Ù„Ù ÙˆØ§Ø­Ø¯ (HUME v0.9.0) Ù…Ø¹ Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if not HUME_AVAILABLE or not self.async_client:
            return {"error": "HUME SDK not available"}

        session_record = None
        try:
            self.logger.info(
                f"âš¡ Starting Stream Analysis... Audio file: {audio_path}")

            if not self._validate_stream_file(audio_path):
                return {
                    "status": "error",
                    "mode": "stream",
                    "error": f"File not found: {audio_path}",
                }

            session_record = db_manager.save_session(
                udid=udid,
                child_name=child_name,
                child_age=child_age,
                mode="stream",
                audio_file=audio_path,
            )

            self.logger.info("ğŸ”— Connecting to HUME Stream...")
            socket = await self.async_client.expression_measurement.stream.connect(
                config={"prosody": {}}
            )

            self.logger.info("ğŸ“¤ Sending audio file...")
            with open(audio_path, "rb") as audio_file_obj:
                audio_data = audio_file_obj.read()
                result = await socket.send_bytes(audio_data)

            await socket.close()

            final_result = await self._process_stream_results(result, session_record)

            self.logger.info("âœ… Stream analysis completed!")
            return {**final_result, "file": audio_path}

        except Exception as e:
            self.logger.error(f"âŒ Stream analysis failed: {e}")
            if session_record:
                db_manager.update_session_status(
                    session_record.id, "error", str(e))
            return {
                "status": "error",
                "mode": "stream",
                "session_id": session_record.id if session_record else None,
                "error": str(e),
            }

    # ==================== HELPER METHODS ====================

    def _extract_from_batch(self, predictions: List) -> List[Dict[str, Any]]:
        """Extracts emotions from a batch prediction."""
        emotions_data = []
        if predictions:
            first_file = predictions[0]
            if "models" in first_file and "prosody" in first_file["models"]:
                prosody = first_file["models"]["prosody"]
                if "grouped_predictions" in prosody and prosody["grouped_predictions"]:
                    grouped = prosody["grouped_predictions"][0]
                    if "predictions" in grouped:
                        for prediction in grouped["predictions"]:
                            emotions_data.append(
                                {
                                    "name": prediction.get("name", "unknown"),
                                    "score": float(prediction.get("score", 0.0)),
                                    "confidence": (
                                        float(prediction.get("confidence", 0.0))
                                        if prediction.get("confidence")
                                        else None
                                    ),
                                }
                            )
        return emotions_data

    def _extract_from_stream(self, predictions: Dict) -> List[Dict[str, Any]]:
        """Extracts emotions from a stream prediction."""
        emotions_data = []
        if "prosody" in predictions:
            prosody_data = predictions["prosody"]
            if "predictions" in prosody_data:
                for prediction in prosody_data["predictions"]:
                    emotions_data.append(
                        {
                            "name": prediction.get("name", "unknown"),
                            "score": float(prediction.get("score", 0.0)),
                            "confidence": (
                                float(prediction.get("confidence", 0.0))
                                if prediction.get("confidence")
                                else None
                            ),
                        }
                    )
        return emotions_data

    def _extract_emotions_from_predictions(
        self, predictions: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        ğŸ­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ù†ØªØ§Ø¦Ø¬ HUME Ù„Ø­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        emotions_data = []
        try:
            if isinstance(predictions, list):
                emotions_data = self._extract_from_batch(predictions)
            elif isinstance(predictions, dict):
                emotions_data = self._extract_from_stream(predictions)

            self.logger.info(
                f"ğŸ­ Extracted {len(emotions_data)} emotions from predictions"
            )

        except Exception as e:
            self.logger.error(f"âŒ Error extracting emotions: {e}")

        return emotions_data

    def _get_summary_from_stream(self, stream_results: Dict) -> Dict:
        """Extracts an emotion summary from a stream result."""
        if "prosody" in stream_results:
            prosody_data = stream_results["prosody"]
            emotions = {
                p.get("name", "unknown"): p.get("score", 0.0)
                for p in prosody_data.get("predictions", [])
            }
            if emotions:
                sorted_emotions = sorted(
                    emotions.items(), key=lambda x: x[1], reverse=True
                )
                return {
                    "dominant_emotion": sorted_emotions[0],
                    "all_emotions": emotions,
                    "top_3_emotions": sorted_emotions[:3],
                }
        return {}

    def _get_summary_from_batch(self, batch_results: List) -> Dict:
        """Extracts an emotion summary from a batch result."""
        summary = {"files_count": len(batch_results), "analysis_types": []}
        if batch_results:
            first_file = batch_results[0]
            if "models" in first_file:
                models = first_file["models"]
                summary["analysis_types"] = list(models.keys())
                if "prosody" in models:
                    prosody = models["prosody"]
                    if (
                        "grouped_predictions" in prosody
                        and prosody["grouped_predictions"]
                    ):
                        predictions = prosody["grouped_predictions"][0].get(
                            "predictions", []
                        )
                        emotions = {p["name"]: p["score"] for p in predictions}
                        if emotions:
                            sorted_emotions = sorted(
                                emotions.items(), key=lambda x: x[1], reverse=True)
                            summary.update(
                                {
                                    "dominant_emotion": sorted_emotions[0],
                                    "all_emotions": emotions,
                                    "top_3_emotions": sorted_emotions[:3],
                                }
                            )
        return summary

    def extract_emotions_summary(
            self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            mode = results.get("mode")
            if mode == "stream":
                return self._get_summary_from_stream(
                    results.get("results", {}))
            elif mode == "batch":
                return self._get_summary_from_batch(results.get("results", []))

            return {"error": "Could not extract emotion summary"}

        except Exception as e:
            return {"error": f"Summary extraction failed: {e}"}

    def create_sample_files(self) -> Any:
        """
        ğŸµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        """
        try:
            import numpy as np
            import soundfile as sf

            logger.info("ğŸµ Creating sample audio files...")

            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            sample_rate = 16000
            duration = 3

            samples = [
                ("sample_happy.wav", 440),  # Ù†ØºÙ…Ø© Ø³Ø¹ÙŠØ¯Ø©
                ("sample_sad.wav", 220),  # Ù†ØºÙ…Ø© Ø­Ø²ÙŠÙ†Ø©
                ("sample_excited.wav", 660),  # Ù†ØºÙ…Ø© Ù…ØªØ­Ù…Ø³Ø©
            ]

            created_files = []

            for filename, frequency in samples:
                t = np.linspace(0, duration, sample_rate * duration)
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø© Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©
                audio = 0.3 * np.sin(2 * np.pi * frequency * t)

                # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„ØªØ´ÙˆÙŠØ´ Ù„Ø¬Ø¹Ù„Ù‡Ø§ Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
                noise = 0.05 * np.random.random(len(audio))
                audio = audio + noise

                sf.write(filename, audio, sample_rate)
                created_files.append(filename)
                logger.info(f"  âœ… Created: {filename}")

            return created_files

        except Exception as e:
            logger.error(f"âŒ Failed to create sample files: {e}")
            return []


# ==================== TESTING FUNCTIONS ====================


async def test_stream_mode():
    """
    ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Stream
    """
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ§ª TESTING STREAM MODE")
    logger.info("=" * 50)

    try:
        hume = HumeIntegration()

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_files = hume.create_sample_files()

        if sample_files:
            audio_file = sample_files[0]  # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù

            # ØªØ­Ù„ÙŠÙ„ Stream
            result = await hume.analyze_stream(audio_file)

            logger.info(f"\nğŸ“Š Stream Results:")
            logger.info(f"Status: {result.get('status')}")

            if result.get("status") == "success":
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                logger.info(f"\nğŸ­ Emotions Summary:")
                logger.info(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                logger.error(f"Error: {result.get('error')}")

            return result
        else:
            logger.error("âŒ No sample files available for testing")

    except Exception as e:
        logger.error(f"âŒ Stream test failed: {e}")


def test_batch_mode() -> Any:
    """
    ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Batch
    """
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ§ª TESTING BATCH MODE")
    logger.info("=" * 50)

    try:
        hume = HumeIntegration()

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        sample_files = hume.create_sample_files()

        if sample_files:
            # ØªØ­Ù„ÙŠÙ„ Batch
            result = hume.analyze_batch(sample_files)

            logger.info(f"\nğŸ“Š Batch Results:")
            logger.info(f"Status: {result.get('status')}")
            logger.info(f"Files analyzed: {result.get('files_analyzed')}")

            if result.get("status") == "success":
                logger.info(f"Output file: {result.get('output_file')}")

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                logger.info(f"\nğŸ­ Emotions Summary:")
                logger.info(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                logger.error(f"Error: {result.get('error')}")

            return result
        else:
            logger.error("âŒ No sample files available for testing")

    except Exception as e:
        logger.error(f"âŒ Batch test failed: {e}")


async def run_all_tests():
    """
    ğŸ§ª ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    """
    logger.info("ğŸ¤ HUME AI Integration Testing")
    logger.info("=" * 60)

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† API Key
    api_key = os.getenv("HUME_API_KEY")
    if not api_key:
        logger.error("âŒ HUME_API_KEY not set!")
        logger.info(
            "ğŸ’¡ Set it with: export HUME_API_KEY='your_hume_api_key_here'")
        return

    logger.info(f"ğŸ”‘ API Key: {api_key[:8]}...")

    # Ø§Ø®ØªØ¨Ø§Ø± Stream Mode
    await test_stream_mode()

    # Ø§Ø®ØªØ¨Ø§Ø± Batch Mode
    test_batch_mode()

    logger.info("\n" + "=" * 60)
    logger.info("âœ… All tests completed!")
    logger.info("ğŸ“ Check 'batch_predictions.json' for detailed results")


if __name__ == "__main__":
    # ØªØ¹ÙŠÙŠÙ† API Key Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    if not os.getenv("HUME_API_KEY"):
        logger.warning(
            "âš ï¸ HUME_API_KEY not set - using default for testing only")
        os.environ["HUME_API_KEY"] = "test_key_only_for_development"

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    asyncio.run(run_all_tests())
