import logging

logger = logging.getLogger(__name__)

"""
ğŸ”§ AI Teddy Bear - Phase 2: Services Consolidation
Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: ØªÙˆØ­ÙŠØ¯ ÙˆØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø®Ø¯Ù…Ø§Øª

Ø§Ù„Ù‡Ø¯Ù: Ø¯Ù…Ø¬ 19 Ù…Ø¬Ù„Ø¯ services ÙÙŠ 6 Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ù†Ø¸Ù…Ø©
Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: 68% ØªÙ‚Ù„ÙŠÙ„ ÙÙŠ ØªØ¹Ù‚ÙŠØ¯ Services
"""
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List


class ServicesConsolidator:

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.src_path = self.project_root / "src"
        self.new_services_structure = {
            "ai_services": {
                "path": "src/application/services/ai",
                "patterns": [
                    "ai",
                    "openai",
                    "gpt",
                    "llm",
                    "claude",
                    "gemini",
                    "hume",
                    "emotion",
                    "analysis",
                ],
            },
            "audio_services": {
                "path": "src/application/services/audio",
                "patterns": [
                    "audio",
                    "voice",
                    "speech",
                    "tts",
                    "stt",
                    "sound",
                    "microphone",
                    "speaker",
                ],
            },
            "child_services": {
                "path": "src/application/services/child",
                "patterns": [
                    "child",
                    "kid",
                    "interaction",
                    "learning",
                    "progress",
                    "education",
                ],
            },
            "parent_services": {
                "path": "src/application/services/parent",
                "patterns": [
                    "parent",
                    "dashboard",
                    "control",
                    "report",
                    "monitor",
                    "auth",
                ],
            },
            "device_services": {
                "path": "src/application/services/device",
                "patterns": [
                    "device",
                    "esp32",
                    "hardware",
                    "teddy",
                    "simulator",
                    "connection",
                ],
            },
            "core_services": {
                "path": "src/application/services/core",
                "patterns": [
                    "notification",
                    "messaging",
                    "security",
                    "validation",
                    "utils",
                    "common",
                ],
            },
        }

    def analyze_current_services(self) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        logger.info("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©...")
        services_analysis = {
            "total_service_files": 0,
            "service_directories": [],
            "files_by_category": {
                category: [] for category in self.new_services_structure.keys()
            },
            "unclassified_files": [],
            "complexity_metrics": {},
        }
        for root, dirs, files in os.walk(self.src_path):
            for d in dirs:
                if "service" in d.lower():
                    services_analysis["service_directories"].append(
                        os.path.join(root, d)
                    )
            for file in files:
                if file.endswith(".py") and "service" in file.lower():
                    file_path = Path(root) / file
                    services_analysis["total_service_files"] += 1
                    classified = False
                    for category, config in self.new_services_structure.items():
                        if any(
                            pattern in file.lower() for pattern in config["patterns"]
                        ):
                            services_analysis["files_by_category"][category].append(
                                str(file_path)
                            )
                            classified = True
                            break
                    if not classified:
                        services_analysis["unclassified_files"].append(str(file_path))
        services_analysis["complexity_metrics"] = {
            "current_service_dirs": len(services_analysis["service_directories"]),
            "target_service_dirs": len(self.new_services_structure),
            "complexity_reduction": f"{len(services_analysis['service_directories'])} â†’ {len(self.new_services_structure)} ({(len(services_analysis['service_directories']) - len(self.new_services_structure)) / len(services_analysis['service_directories']) * 100:.0f}% ØªØ­Ø³Ù†)",
            "files_distribution": {
                cat: len(files)
                for cat, files in services_analysis["files_by_category"].items()
            },
        }
        return services_analysis

    def create_new_service_directories(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
        logger.info("ğŸ—ï¸ Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯...")
        for category, config in self.new_services_structure.items():
            target_dir = Path(config["path"])
            target_dir.mkdir(parents=True, exist_ok=True)
            init_file = target_dir / "__init__.py"
            if not init_file.exists():
                init_content = f"""""\"
{category.replace('_', ' ').title()} Package
{config['path'].split('/')[-1]} services for AI Teddy Bear
""\"

# TODO: Add service imports after consolidation
"""
                init_file.write_text(init_content, encoding="utf-8")
            logger.info(f"  âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: {config['path']}")

    def consolidate_ai_services(self, files: List[str]) -> Dict:
        """ØªÙˆØ­ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        logger.info("ğŸ¤– ØªÙˆØ­ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...")
        target_dir = Path(self.new_services_structure["ai_services"]["path"])
        consolidation_results = {"moved": 0, "errors": 0, "conflicts": []}
        for file_path in files:
            try:
                src_file = Path(file_path)
                if src_file.exists():
                    target_file = target_dir / src_file.name
                    if target_file.exists():
                        counter = 1
                        while target_file.exists():
                            name_parts = (src_file.stem, counter, src_file.suffix)
                            target_file = (
                                target_dir
                                / f"{name_parts[0]}_v{name_parts[1]}{name_parts[2]}"
                            )
                            counter += 1
                        consolidation_results["conflicts"].append(str(src_file))
                    shutil.move(str(src_file), str(target_file))
                    consolidation_results["moved"] += 1
                    logger.info(f"  âœ… Ù†ÙÙ‚Ù„: {src_file.name}")
            except Exception as e:
                consolidation_results["errors"] += 1
                logger.info(f"  âŒ Ø®Ø·Ø£ ÙÙŠ Ù†Ù‚Ù„ {file_path}: {e}")
        return consolidation_results

    def consolidate_audio_services(self, files: List[str]) -> Dict:
        """ØªÙˆØ­ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØµÙˆØª"""
        logger.info("ğŸµ ØªÙˆØ­ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØµÙˆØª...")
        target_dir = Path(self.new_services_structure["audio_services"]["path"])
        results = {"moved": 0, "errors": 0, "conflicts": []}
        for file_path in files:
            try:
                src_file = Path(file_path)
                if src_file.exists():
                    target_file = target_dir / src_file.name
                    if target_file.exists():
                        target_file = (
                            target_dir
                            / f"{src_file.stem}_consolidated{src_file.suffix}"
                        )
                        results["conflicts"].append(str(src_file))
                    shutil.move(str(src_file), str(target_file))
                    results["moved"] += 1
                    logger.info(f"  âœ… Ù†ÙÙ‚Ù„: {src_file.name}")
            except Exception as e:
                results["errors"] += 1
                logger.info(f"  âŒ Ø®Ø·Ø£: {e}")
        return results

    def consolidate_category_services(self, category: str, files: List[str]) -> Dict:
        """ØªÙˆØ­ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª ÙØ¦Ø© Ù…Ø¹ÙŠÙ†Ø©"""
        logger.info(f"ğŸ“¦ ØªÙˆØ­ÙŠØ¯ {category.replace('_', ' ')}...")
        target_dir = Path(self.new_services_structure[category]["path"])
        results = {"moved": 0, "errors": 0, "conflicts": []}
        for file_path in files:
            try:
                src_file = Path(file_path)
                if src_file.exists():
                    target_file = target_dir / src_file.name
                    if target_file.exists():
                        target_file = (
                            target_dir / f"{src_file.stem}_migrated{src_file.suffix}"
                        )
                        results["conflicts"].append(str(src_file))
                    shutil.move(str(src_file), str(target_file))
                    results["moved"] += 1
                    logger.info(f"  âœ… {src_file.name}")
            except Exception as e:
                results["errors"] += 1
                logger.info(f"  âŒ Ø®Ø·Ø£: {e}")
        return results

    def execute_consolidation(self, analysis: Dict) -> Dict:
        """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙˆØ­ÙŠØ¯"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª...")
        results = {
            "timestamp": datetime.now().isoformat(),
            "categories_processed": {},
            "total_moved": 0,
            "total_errors": 0,
            "summary": {},
        }
        self.create_new_service_directories()
        for category, files in analysis["files_by_category"].items():
            if files:
                category_results = self.consolidate_category_services(category, files)
                results["categories_processed"][category] = category_results
                results["total_moved"] += category_results["moved"]
                results["total_errors"] += category_results["errors"]
        if analysis["unclassified_files"]:
            logger.info("ğŸ“‚ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…ØµÙ†ÙØ©...")
            unclassified_results = self.consolidate_category_services(
                "core_services", analysis["unclassified_files"]
            )
            results["categories_processed"]["unclassified"] = unclassified_results
            results["total_moved"] += unclassified_results["moved"]
            results["total_errors"] += unclassified_results["errors"]
        results["summary"] = {
            "services_reorganized": results["total_moved"],
            "errors_encountered": results["total_errors"],
            "structure_improvement": analysis["complexity_metrics"][
                "complexity_reduction"
            ],
            "new_structure": list(self.new_services_structure.keys()),
        }
        return results

    def generate_phase2_report(self, analysis: Dict, results: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©"""
        report = f"""
# ğŸ”§ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© - ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª

## Ø§Ù„ÙˆØ¶Ø¹ Ù‚Ø¨Ù„ Ø§Ù„ØªÙˆØ­ÙŠØ¯:
- Ù…Ø¬Ù„Ø¯Ø§Øª Services: {analysis['complexity_metrics']['current_service_dirs']}
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {analysis['total_service_files']}
- Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©: {analysis['complexity_metrics']['files_distribution']}

## Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø­Ù‚Ù‚Ø©:
- {analysis['complexity_metrics']['complexity_reduction']}
- Ù…Ù„ÙØ§Øª ØªÙ… Ù†Ù‚Ù„Ù‡Ø§: {results['total_moved']}
- Ø£Ø®Ø·Ø§Ø¡: {results['total_errors']}

## Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯:
{chr(10).join(f"- {cat}: {config['path']}" for cat, config in self.new_services_structure.items())}

## Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:
{chr(10).join(f"- {cat}: {res['moved']} Ù…Ù„Ù" for cat, res in results['categories_processed'].items())}

## Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:
âœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªÙ… (Ù†Ù‚Ù„ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª)
âœ… Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: ØªÙ… (ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª)
â³ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Infrastructure
â³ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©: ØªØ­Ø¯ÙŠØ« Imports

## Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
1. Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
2. ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø© (Infrastructure)
3. ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ imports
4. Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Ø¸Ø§Ù…

ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        return report


def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©"""
    logger.info("ğŸ”§ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© - ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª!")
    logger.info("=" * 60)
    consolidator = ServicesConsolidator()
    try:
        analysis = consolidator.analyze_current_services()
        logger.info("\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        logger.info(
            f"- Ù…Ø¬Ù„Ø¯Ø§Øª Services Ø­Ø§Ù„ÙŠØ§Ù‹: {analysis['complexity_metrics']['current_service_dirs']}"
        )
        logger.info(
            f"- Ù…Ø¬Ù„Ø¯Ø§Øª Services Ù…Ø³ØªÙ‡Ø¯ÙØ©: {analysis['complexity_metrics']['target_service_dirs']}"
        )
        logger.info(
            f"- Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {analysis['complexity_metrics']['complexity_reduction']}"
        )
        logger.info(f"- Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {analysis['total_service_files']}")
        response = input("\nğŸš€ Ù‡Ù„ ØªØ±ÙŠØ¯ Ø¨Ø¯Ø¡ ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø®Ø¯Ù…Ø§ØªØŸ (y/n): ")
        if response.lower() == "y":
            results = consolidator.execute_consolidation(analysis)
            report = consolidator.generate_phase2_report(analysis, results)
            report_file = "phase_2_services_consolidation_report.md"
            with open(report_file, "w", encoding="utf-8") as f:
                f.write(report)
            logger.info("\nâœ… ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
            logger.info(f"ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ ÙÙŠ: {report_file}")
            logger.info(f"ğŸ¯ Ù…Ù„ÙØ§Øª ØªÙ… Ù†Ù‚Ù„Ù‡Ø§: {results['total_moved']}")
            logger.info(
                f"ğŸš€ Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ù…Ø­Ù‚Ù‚: {analysis['complexity_metrics']['complexity_reduction']}"
            )
        else:
            logger.info("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
    except Exception as e:
        logger.info(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°: {e}")


if __name__ == "__main__":
    main()
