from typing import Dict, List, Any, Optional

import logging

logger = logging.getLogger(__name__)

#!/usr/bin/env python3
"""
ğŸ¤ HUME AI Integration Script - FIXED Version
Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ HUME AI: Batch Ùˆ Stream
"""
import structlog
logger = structlog.get_logger(__name__)


import os
import asyncio
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª HUME AI
try:
    from hume import HumeClient, AsyncHumeClient
    HUME_AVAILABLE = True
    logger.info("âœ… HUME AI SDK loaded successfully")
except ImportError:
    HUME_AVAILABLE = False
    logger.error("âŒ HUME AI SDK not available. Install with: pip install hume")

class HumeIntegrationFixed:
    """
    ğŸ­ HUME AI Integration Class - FIXED for v0.9.0
    ÙŠØ¯Ø¹Ù… Ù†Ù…ÙˆØ°Ø¬ÙŠ Batch Ùˆ Stream Ù„Ù„ØªØ­Ù„ÙŠÙ„
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("HUME_API_KEY")
        
        if not self.api_key:
            raise ValueError("âŒ HUME API Key not found! Set HUME_API_KEY environment variable")
        
        logger.info(f"ğŸ”‘ HUME API Key loaded: {self.api_key[:8]}...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
        if HUME_AVAILABLE:
            self.client = HumeClient(api_key=self.api_key)
            self.async_client = AsyncHumeClient(api_key=self.api_key)
            logger.info("âœ… HUME Clients initialized")
        else:
            self.client = None
            self.async_client = None
            logger.warning("âš ï¸ HUME Clients not available")
    
    # ==================== BATCH MODE ====================
    
    def analyze_batch(self, file_paths: List[str]) -> Dict[str, Any]:
        """
        ğŸ”„ Ù†Ù…Ø· Batch - ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© (FIXED for HUME v0.9.0)
        """
        if not HUME_AVAILABLE or not self.client:
            return {"error": "HUME SDK not available"}
        
        try:
            logger.info("ğŸ”„ Starting Batch Analysis...")
            logger.info(f"ğŸ“ Files to analyze: {len(file_paths)}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
            valid_files = []
            for file_path in file_paths:
                if Path(file_path).exists():
                    valid_files.append(file_path)
                    logger.info(f"  âœ… {file_path}")
                else:
                    logger.error(f"  âŒ File not found: {file_path}")
            
            if not valid_files:
                return {"error": "No valid files found"}
            
            logger.info("ğŸ“¤ Submitting batch job to HUME...")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„Ù€ batch
            job = self.client.expression_measurement.batch.start_inference_job_from_local_file(
                file=valid_files[0],  # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù ÙƒÙ…Ø«Ø§Ù„
                configs=[
                    {"prosody": {}},  # ØªØ­Ù„ÙŠÙ„ Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª
                ]
            )
            
            logger.info(f"ğŸ“‹ Job ID: {job.job_id}")
            logger.info("â³ Waiting for analysis to complete...")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            import time
            max_wait = 30  # 30 Ø«Ø§Ù†ÙŠØ© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
            wait_time = 0
            
            while wait_time < max_wait:
                job_details = self.client.expression_measurement.batch.get_job_details(job.job_id)
                
                if hasattr(job_details, 'state'):
                    if job_details.state == "COMPLETED":
                        break
                    elif job_details.state == "FAILED":
                        return {
                            "status": "error",
                            "mode": "batch",
                            "error": "HUME job failed"
                        }
                
                logger.info("â³ Still processing...")
                time.sleep(3)
                wait_time += 3
            
            if wait_time >= max_wait:
                return {
                    "status": "error",
                    "mode": "batch",
                    "error": "Analysis timeout"
                }
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            logger.info("ğŸ“¥ Downloading predictions...")
            predictions = self.client.expression_measurement.batch.get_job_predictions(job.job_id)
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù
            output_file = "batch_predictions.json"
            with open(output_file, 'w') as f:
                json.dump(predictions, f, indent=2)
            
            logger.info("âœ… Batch analysis completed successfully!")
            
            return {
                "status": "success",
                "mode": "batch",
                "files_analyzed": len(valid_files),
                "output_file": output_file,
                "job_id": job.job_id,
                "results": predictions
            }
            
        except Exception as e:
    logger.error(f"Error: {e}")f"âŒ Batch analysis failed: {e}")
            return {
                "status": "error",
                "mode": "batch",
                "error": str(e)
            }
    
    # ==================== STREAM MODE ====================
    
    async def analyze_stream(self, audio_path: str) -> Dict[str, Any]:
        """
        âš¡ Ù†Ù…Ø· Stream - ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±ÙŠ Ù„Ù…Ù„Ù ÙˆØ§Ø­Ø¯ (FIXED for HUME v0.9.0)
        """
        if not HUME_AVAILABLE or not self.async_client:
            return {"error": "HUME SDK not available"}
        
        try:
            logger.info("âš¡ Starting Stream Analysis...")
            logger.info(f"ğŸµ Audio file: {audio_path}")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
            if not Path(audio_path).exists():
                return {
                    "status": "error",
                    "mode": "stream",
                    "error": f"File not found: {audio_path}"
                }
            
            logger.info("ğŸ”— Connecting to HUME Stream...")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù„Ù„Ù€ stream
            socket = await self.async_client.expression_measurement.stream.connect()
            
            logger.info("ğŸ“¤ Sending audio file...")
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡
            with open(audio_path, 'rb') as audio_file:
                audio_data = audio_file.read()
                result = await socket.send_bytes(audio_data)
            
            await socket.close()
            
            logger.info("âœ… Stream analysis completed!")
            
            return {
                "status": "success", 
                "mode": "stream",
                "file": audio_path,
                "results": result
            }
                
        except Exception as e:
    logger.error(f"Error: {e}")f"âŒ Stream analysis failed: {e}")
            logger.error(f"   Error details: {type(e).__name__}: {e}")
            return {
                "status": "error",
                "mode": "stream", 
                "error": str(e)
            }
    
    # ==================== HELPER METHODS ====================
    
    def extract_emotions_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        """
        try:
            # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù„Ù†ØªØ§Ø¦Ø¬
            return {
                "analysis_completed": True,
                "mode": results.get("mode", "unknown"),
                "status": results.get("status", "unknown"),
                "file": results.get("file", "unknown"),
                "message": "ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… HUME AI"
            }
            
        except Exception as e:
            return {"error": f"Summary extraction failed: {e}"}
    
    def create_sample_files(self) -> Any:
        """
        ğŸµ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        """
        try:
            import numpy as np
            import soundfile as sf
            
            logger.info("ğŸµ Creating sample audio files...")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            sample_rate = 16000
            duration = 3
            
            samples = [
                ("sample_happy.wav", 440),    # Ù†ØºÙ…Ø© Ø³Ø¹ÙŠØ¯Ø©
                ("sample_sad.wav", 220),      # Ù†ØºÙ…Ø© Ø­Ø²ÙŠÙ†Ø©
                ("sample_excited.wav", 660)   # Ù†ØºÙ…Ø© Ù…ØªØ­Ù…Ø³Ø©
            ]
            
            created_files = []
            
            for filename, frequency in samples:
                t = np.linspace(0, duration, sample_rate * duration)
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØºÙ…Ø© Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©
                audio = 0.3 * np.sin(2 * np.pi * frequency * t)
                
                # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„ØªØ´ÙˆÙŠØ´ Ù„Ø¬Ø¹Ù„Ù‡Ø§ Ø£ÙƒØ«Ø± ÙˆØ§Ù‚Ø¹ÙŠØ©
                noise = 0.05 * np.random.random(len(audio))
                audio = audio + noise
                
                sf.write(filename, audio, sample_rate)
                created_files.append(filename)
                logger.info(f"  âœ… Created: {filename}")
            
            return created_files
            
        except Exception as e:
    logger.error(f"Error: {e}")f"âŒ Failed to create sample files: {e}")
            return []


# ==================== TESTING FUNCTIONS ====================

async def test_stream_mode():
    """ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Stream"""
    logger.info("\n" + "="*50)
    logger.info("ğŸ§ª TESTING STREAM MODE")
    logger.info("="*50)
    
    try:
        hume = HumeIntegrationFixed()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_files = hume.create_sample_files()
        
        if sample_files:
            audio_file = sample_files[0]  # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù…Ù„Ù
            
            # ØªØ­Ù„ÙŠÙ„ Stream
            result = await hume.analyze_stream(audio_file)
            
            logger.info(f"\nğŸ“Š Stream Results:")
            logger.info(f"Status: {result.get('status')}")
            
            if result.get('status') == 'success':
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                logger.info(f"\nğŸ­ Analysis Summary:")
                logger.info(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                logger.error(f"Error: {result.get('error')}")
            
            return result
        else:
            logger.error("âŒ No sample files available for testing")
            
    except Exception as e:
    logger.error(f"Error: {e}")f"âŒ Stream test failed: {e}")

def test_batch_mode() -> Any:
    """ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù…Ø· Batch"""
    logger.info("\n" + "="*50)
    logger.info("ğŸ§ª TESTING BATCH MODE")
    logger.info("="*50)
    
    try:
        hume = HumeIntegrationFixed()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        sample_files = hume.create_sample_files()
        
        if sample_files:
            # ØªØ­Ù„ÙŠÙ„ Batch
            result = hume.analyze_batch(sample_files)
            
            logger.info(f"\nğŸ“Š Batch Results:")
            logger.info(f"Status: {result.get('status')}")
            logger.info(f"Files analyzed: {result.get('files_analyzed')}")
            logger.info(f"Job ID: {result.get('job_id')}")
            
            if result.get('status') == 'success':
                logger.info(f"Output file: {result.get('output_file')}")
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                summary = hume.extract_emotions_summary(result)
                logger.info(f"\nğŸ­ Analysis Summary:")
                logger.info(json.dumps(summary, indent=2, ensure_ascii=False))
            else:
                logger.error(f"Error: {result.get('error')}")
            
            return result
        else:
            logger.error("âŒ No sample files available for testing")
            
    except Exception as e:
    logger.error(f"Error: {e}")f"âŒ Batch test failed: {e}")

async def run_all_tests():
    """ğŸ§ª ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    logger.info("ğŸ¤ HUME AI Integration Testing - FIXED VERSION")
    logger.info("="*60)
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† API Key
    api_key = os.getenv("HUME_API_KEY")
    if not api_key:
        logger.error("âŒ HUME_API_KEY not set!")
        logger.info("ğŸ’¡ Set it with: export HUME_API_KEY='xmkFxYNrKdHjhY6RiEA0JT46C2xAo4YsdiujXqtg5fd1C99Q'")
        return
    
    logger.info(f"ğŸ”‘ API Key: {api_key[:8]}...")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Stream Mode
    await test_stream_mode()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Batch Mode
    test_batch_mode()
    
    logger.info("\n" + "="*60)
    logger.info("âœ… All tests completed!")
    logger.info("ğŸ“ Check 'batch_predictions.json' for detailed results")

if __name__ == "__main__":
    # ØªØ¹ÙŠÙŠÙ† API Key Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    if not os.getenv("HUME_API_KEY"):
        os.environ["HUME_API_KEY"] = "xmkFxYNrKdHjhY6RiEA0JT46C2xAo4YsdiujXqtg5fd1C99Q"
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    asyncio.run(run_all_tests()) 